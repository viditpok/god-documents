{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1774c216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew, kurtosis\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f5ba729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "plt.rcParams[\"figure.dpi\"] = 150\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "df65f39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CRYPTO_LIST = [\"BTC\", \"ETH\", \"LTC\", \"BCH\"]\n",
    "MARKET_CHOICES = [\n",
    "    [\"FIAT\"],\n",
    "    [\"EQUITY\"],\n",
    "    [\"GOLD\"],\n",
    "    [\"ENERGY\"],\n",
    "    [\"FIAT\", \"EQUITY\"],\n",
    "    [\"FIAT\", \"GOLD\"],\n",
    "    [\"FIAT\", \"EQUITY\", \"GOLD\", \"ENERGY\"],\n",
    "]\n",
    "BASELINE_WINDOW = 12\n",
    "BASELINE_EPOCHS = 25\n",
    "BASELINE_HIDDEN = 4\n",
    "BASELINE_LR = 0.001\n",
    "BASELINE_ACT = \"tanh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b9eceb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_prices():\n",
    "    base_path = \"data\"\n",
    "    files = {\n",
    "        \"BTC\": \"CBBTCUSD.csv\",\n",
    "        \"ETH\": \"CBETHUSD.csv\",\n",
    "        \"LTC\": \"CBLTCUSD.csv\",\n",
    "        \"BCH\": \"CBBCHUSD.csv\",\n",
    "        \"FIAT\": \"DTWEXBGS.csv\",\n",
    "        \"EQUITY\": \"CRSP.csv\",\n",
    "        \"GOLD\": \"NASDAQQGLDI.csv\",\n",
    "        \"ENERGY\": \"VDE.csv\",\n",
    "    }\n",
    "\n",
    "    dfs = {}\n",
    "\n",
    "    for name, filename in files.items():\n",
    "        path = os.path.join(base_path, filename)\n",
    "        df = pd.read_csv(path)\n",
    "        df.columns = [c.lower().strip() for c in df.columns]\n",
    "\n",
    "        date_col = None\n",
    "        for col in df.columns:\n",
    "            if \"date\" in col:\n",
    "                date_col = col\n",
    "                break\n",
    "        if date_col is None:\n",
    "            raise ValueError(f\"No date column found in {filename}\")\n",
    "\n",
    "        df[date_col] = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "        df = df.dropna(subset=[date_col])\n",
    "        df = df.sort_values(date_col)\n",
    "\n",
    "        num_cols = [c for c in df.columns if c != date_col]\n",
    "        if len(num_cols) == 0:\n",
    "            raise ValueError(f\"No price/value column found in {filename}\")\n",
    "        price_col = num_cols[0]\n",
    "\n",
    "        df = df.resample(\"M\", on=date_col).last()\n",
    "\n",
    "        df[name] = np.log(df[price_col]).diff()\n",
    "\n",
    "        dfs[name] = df[[name]]\n",
    "\n",
    "    data = pd.concat(dfs.values(), axis=1).dropna()\n",
    "    data.index.name = \"Date\"\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def split_sets(dates, X, y, ids):\n",
    "    mask_train = (dates >= \"2015-01-01\") & (dates <= \"2019-12-31\")\n",
    "    mask_val = (dates >= \"2020-01-01\") & (dates <= \"2021-12-31\")\n",
    "    mask_test = (dates >= \"2022-01-01\") & (dates <= \"2025-10-31\")\n",
    "\n",
    "    def subset(mask):\n",
    "        idx = np.array(mask)\n",
    "        return X[idx], y[idx], [ids[i] for i, v in enumerate(mask) if v]\n",
    "\n",
    "    return subset(mask_train), subset(mask_val), subset(mask_test)\n",
    "\n",
    "\n",
    "def p(msg):\n",
    "    print(msg, flush=True)\n",
    "\n",
    "\n",
    "def make_panel(data, market_assets, w):\n",
    "    X, y, ids = [], [], []\n",
    "    for crypto in [\"BTC\", \"ETH\", \"LTC\", \"BCH\"]:\n",
    "        for t in range(w, len(data) - 1):\n",
    "            past_crypto = data[crypto].iloc[t - w : t].values\n",
    "            past_mkts = data[market_assets].iloc[t - w : t].values.flatten()\n",
    "            X.append(np.concatenate([past_crypto, past_mkts]))\n",
    "            y.append(data[crypto].iloc[t + 1])\n",
    "            ids.append((data.index[t + 1], crypto))\n",
    "    return np.array(X), np.array(y), ids\n",
    "\n",
    "\n",
    "def build_panel_for_market(data, market_assets, w):\n",
    "    X, y, ids = make_panel(data, market_assets, w)\n",
    "\n",
    "    dates = pd.to_datetime([d for d, _ in ids])\n",
    "    (Xtr, ytr, ids_tr), (Xval, yval, ids_val), (Xte, yte, ids_te) = split_sets(\n",
    "        dates, X, y, ids\n",
    "    )\n",
    "    return {\n",
    "        \"market_assets\": market_assets,\n",
    "        \"w\": w,\n",
    "        \"Xtr\": Xtr,\n",
    "        \"ytr\": ytr,\n",
    "        \"ids_tr\": ids_tr,\n",
    "        \"Xval\": Xval,\n",
    "        \"yval\": yval,\n",
    "        \"ids_val\": ids_val,\n",
    "        \"Xte\": Xte,\n",
    "        \"yte\": yte,\n",
    "        \"ids_te\": ids_te,\n",
    "    }\n",
    "\n",
    "\n",
    "def predict_betas_df(model, X, ids, asset_label):\n",
    "    if len(X) == 0:\n",
    "        return pd.DataFrame(columns=[\"Date\", \"Crypto\", \"Asset\", \"Beta\"])\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_t = torch.tensor(X, dtype=torch.float32)\n",
    "        betas = model(X_t).cpu().numpy().ravel()\n",
    "    out = pd.DataFrame(\n",
    "        {\n",
    "            \"Date\": pd.to_datetime([d for d, _ in ids]),\n",
    "            \"Crypto\": [c for _, c in ids],\n",
    "            \"Asset\": asset_label,\n",
    "            \"Beta\": betas,\n",
    "        }\n",
    "    )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e2041e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralBetaNet(nn.Module):\n",
    "    def __init__(self, in_dim, hidden, activation):\n",
    "        super().__init__()\n",
    "        act = {\n",
    "            \"linear\": nn.Identity(),\n",
    "            \"sigmoid\": nn.Sigmoid(),\n",
    "            \"tanh\": nn.Tanh(),\n",
    "            \"relu\": nn.ReLU(),\n",
    "        }[activation]\n",
    "        self.model = nn.Sequential(nn.Linear(in_dim, hidden), act, nn.Linear(hidden, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "def rmse_loss(pred, target):\n",
    "    return torch.sqrt(torch.mean((pred - target)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f07e8c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(Xtr, ytr, Xval, yval, hidden, lr, act, epochs=10):\n",
    "    in_dim = Xtr.shape[1]\n",
    "    model = NeuralBetaNet(in_dim, hidden, act).to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_hist, val_hist = [], []\n",
    "\n",
    "    Xtr_t = torch.tensor(Xtr, dtype=torch.float32).to(device)\n",
    "    ytr_t = torch.tensor(ytr, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "    Xval_t = torch.tensor(Xval, dtype=torch.float32).to(device)\n",
    "    yval_t = torch.tensor(yval, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        opt.zero_grad()\n",
    "        out = model(Xtr_t)\n",
    "        loss = rmse_loss(out, ytr_t)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_out = model(Xval_t)\n",
    "            val_loss = rmse_loss(val_out, yval_t)\n",
    "        loss_hist.append(loss.item())\n",
    "        val_hist.append(val_loss.item())\n",
    "        print(\n",
    "            f\"Epoch {ep+1:03d} | train RMSE {loss.item():.6f} | val RMSE {val_loss.item():.6f}\"\n",
    "        )\n",
    "    return model, loss_hist, val_hist\n",
    "\n",
    "\n",
    "def grid_search(Xtr, ytr, Xval, yval, market_assets):\n",
    "    params = {\n",
    "        \"hidden\": [4, 8, 16],\n",
    "        \"lr\": [0.001, 0.01, 0.1],\n",
    "        \"act\": [\"linear\", \"sigmoid\", \"tanh\", \"relu\"],\n",
    "        \"w\": [12, 24, 36],\n",
    "    }\n",
    "    results = []\n",
    "    for h in params[\"hidden\"]:\n",
    "        for lr in params[\"lr\"]:\n",
    "            for act in params[\"act\"]:\n",
    "                for w in params[\"w\"]:\n",
    "                    try:\n",
    "                        model, loss_hist, val_hist = train_nn(\n",
    "                            Xtr, ytr, Xval, yval, hidden=h, lr=lr, act=act, epochs=10\n",
    "                        )\n",
    "                        val_rmse = val_hist[-1]\n",
    "                        results.append([market_assets, w, h, lr, act, val_rmse])\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error {market_assets}, w={w}, act={act}: {e}\")\n",
    "    df = pd.DataFrame(\n",
    "        results,\n",
    "        columns=[\"MarketAssets\", \"Window\", \"Hidden\", \"LR\", \"Activation\", \"Val_RMSE\"],\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3fc6e2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(loss_hist, val_hist, label, out_path):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(loss_hist, label=\"Train RMSE\")\n",
    "    plt.plot(val_hist, label=\"Validation RMSE\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.title(f\"Learning Curve – {label}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "81831bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_descriptive_stats(betas):\n",
    "    desc = {\n",
    "        \"N\": len(betas),\n",
    "        \"Mean\": np.mean(betas),\n",
    "        \"Std\": np.std(betas, ddof=1),\n",
    "        \"Skew\": skew(betas),\n",
    "        \"Kurtosis\": kurtosis(betas, fisher=False),\n",
    "        \"Min\": np.min(betas),\n",
    "        \"P1\": np.percentile(betas, 1),\n",
    "        \"P5\": np.percentile(betas, 5),\n",
    "        \"P25\": np.percentile(betas, 25),\n",
    "        \"P50\": np.percentile(betas, 50),\n",
    "        \"P75\": np.percentile(betas, 75),\n",
    "        \"P95\": np.percentile(betas, 95),\n",
    "        \"P99\": np.percentile(betas, 99),\n",
    "        \"Max\": np.max(betas),\n",
    "    }\n",
    "    return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0224224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_annual_beta_dynamics(df_betas, out_path):\n",
    "    df_betas[\"Date\"] = pd.to_datetime(df_betas[\"Date\"], errors=\"coerce\")\n",
    "    df_betas[\"year\"] = df_betas[\"Date\"].dt.year\n",
    "    df_betas[\"month\"] = df_betas[\"Date\"].dt.month\n",
    "\n",
    "    unique_years = df_betas[\"year\"].dropna().unique()\n",
    "    if len(unique_years) == 1:\n",
    "\n",
    "        agg = (\n",
    "            df_betas.groupby([\"month\", \"Crypto\"])[\"Beta\"]\n",
    "            .agg([\"mean\", \"std\"])\n",
    "            .reset_index()\n",
    "        )\n",
    "        plt.figure(figsize=(7, 4))\n",
    "        for c in agg[\"Crypto\"].unique():\n",
    "            subset = agg[agg[\"Crypto\"] == c]\n",
    "            plt.plot(subset[\"month\"], subset[\"mean\"], label=c, marker=\"o\")\n",
    "        plt.xlabel(\"Month\")\n",
    "        plt.ylabel(\"Mean β\")\n",
    "        plt.title(f\"Monthly Mean Neural β Dynamics ({unique_years[0]})\")\n",
    "        plt.xticks(range(1, 13))\n",
    "    else:\n",
    "\n",
    "        agg = (\n",
    "            df_betas.groupby([\"year\", \"Crypto\"])[\"Beta\"]\n",
    "            .agg([\"mean\", \"std\"])\n",
    "            .reset_index()\n",
    "        )\n",
    "        plt.figure(figsize=(7, 4))\n",
    "        for c in agg[\"Crypto\"].unique():\n",
    "            subset = agg[agg[\"Crypto\"] == c]\n",
    "            plt.plot(subset[\"year\"], subset[\"mean\"], label=c, marker=\"o\")\n",
    "        plt.xlabel(\"Year\")\n",
    "        plt.ylabel(\"Mean β\")\n",
    "        plt.title(\"Annual Mean Neural β Dynamics\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "20f9f6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ff_factors(data, ff_df):\n",
    "    ff_df.columns = [c.strip() for c in ff_df.columns]\n",
    "\n",
    "    if \"date\" not in [c.lower() for c in ff_df.columns]:\n",
    "        ff_df.rename(columns={ff_df.columns[0]: \"date\"}, inplace=True)\n",
    "\n",
    "    ff_df = ff_df[ff_df[\"date\"].astype(str).str.match(r\"^\\d{6}$\", na=False)]\n",
    "\n",
    "    ff_df[\"date\"] = pd.to_datetime(\n",
    "        ff_df[\"date\"].astype(str) + \"01\", format=\"%Y%m%d\"\n",
    "    ) + pd.offsets.MonthEnd(0)\n",
    "\n",
    "    for col in ff_df.columns:\n",
    "        if col != \"date\":\n",
    "            ff_df[col] = pd.to_numeric(ff_df[col], errors=\"coerce\") / 100.0\n",
    "\n",
    "    ff_df = ff_df.set_index(\"date\").sort_index()\n",
    "\n",
    "    merged = data.join(ff_df, how=\"left\").dropna()\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "496bc4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_and_portfolio(df_betas, returns_df):\n",
    "    result = []\n",
    "    for asset in df_betas[\"Asset\"].unique():\n",
    "        temp = df_betas[df_betas[\"Asset\"] == asset]\n",
    "        for date, grp in temp.groupby(\"Date\"):\n",
    "            ranked = grp.sort_values(\"Beta\")\n",
    "            ranked[\"Quartile\"] = range(1, len(ranked) + 1)\n",
    "            for q, sub in ranked.groupby(\"Quartile\"):\n",
    "                mean_b = sub[\"Beta\"].mean()\n",
    "\n",
    "                rets = []\n",
    "                for c in sub[\"Crypto\"]:\n",
    "                    if c in returns_df.columns and asset in returns_df.columns:\n",
    "                        rets.append(\n",
    "                            returns_df[c].loc[date] - returns_df[asset].loc[date]\n",
    "                        )\n",
    "                if rets:\n",
    "                    mean_ex = np.nanmean(rets)\n",
    "                    result.append([date, asset, q, mean_b, mean_ex])\n",
    "    return pd.DataFrame(\n",
    "        result, columns=[\"Date\", \"Asset\", \"Quartile\", \"MeanBeta\", \"ExcessReturn\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e40a171",
   "metadata": {},
   "source": [
    "### Step 0 – Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "987a5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rx/4mtzy3y13t9f2njmm29j60pm0000gp/T/ipykernel_56309/1874547837.py:18: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 BTC       ETH       LTC       BCH      FIAT    EQUITY  \\\n",
      "Date                                                                     \n",
      "2018-01-31 -0.316698  0.399245 -0.338720 -0.474456 -0.030520 -0.079369   \n",
      "2018-02-28  0.020315 -0.262385  0.221883 -0.208192  0.015064  0.136639   \n",
      "2018-03-31 -0.397206 -0.767504 -0.552861 -0.560178 -0.008448 -0.051404   \n",
      "2018-04-30  0.288312  0.529274  0.243438  0.681713  0.017133  0.091894   \n",
      "2018-05-31 -0.211054 -0.148979 -0.225709 -0.305480  0.023970 -1.948422   \n",
      "\n",
      "                GOLD    ENERGY  \n",
      "Date                            \n",
      "2018-01-31  0.023697  0.027373  \n",
      "2018-02-28 -0.018993 -0.084467  \n",
      "2018-03-31  0.006084 -0.027967  \n",
      "2018-04-30 -0.010383  0.109011  \n",
      "2018-05-31 -0.016046  0.037446  \n"
     ]
    }
   ],
   "source": [
    "data = load_and_prepare_prices()\n",
    "print(data.head())\n",
    "data.to_csv(\"outputs/data_monthly_log_returns.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e76df06",
   "metadata": {},
   "source": [
    "### Step 1 – Neural‑network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d614c43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train RMSE 0.258597 | val RMSE 0.316866\n",
      "Epoch 002 | train RMSE 0.256398 | val RMSE 0.315961\n",
      "Epoch 003 | train RMSE 0.254233 | val RMSE 0.315068\n",
      "Epoch 004 | train RMSE 0.252101 | val RMSE 0.314190\n",
      "Epoch 005 | train RMSE 0.250003 | val RMSE 0.313332\n",
      "Epoch 006 | train RMSE 0.247940 | val RMSE 0.312495\n",
      "Epoch 007 | train RMSE 0.245913 | val RMSE 0.311682\n",
      "Epoch 008 | train RMSE 0.243923 | val RMSE 0.310895\n",
      "Epoch 009 | train RMSE 0.241971 | val RMSE 0.310134\n",
      "Epoch 010 | train RMSE 0.240058 | val RMSE 0.309403\n",
      "Epoch 011 | train RMSE 0.238183 | val RMSE 0.308701\n",
      "Epoch 012 | train RMSE 0.236348 | val RMSE 0.308032\n",
      "Epoch 013 | train RMSE 0.234552 | val RMSE 0.307396\n",
      "Epoch 014 | train RMSE 0.232795 | val RMSE 0.306796\n",
      "Epoch 015 | train RMSE 0.231077 | val RMSE 0.306233\n",
      "Epoch 016 | train RMSE 0.229397 | val RMSE 0.305709\n",
      "Epoch 017 | train RMSE 0.227756 | val RMSE 0.305223\n",
      "Epoch 018 | train RMSE 0.226151 | val RMSE 0.304779\n",
      "Epoch 019 | train RMSE 0.224584 | val RMSE 0.304375\n",
      "Epoch 020 | train RMSE 0.223053 | val RMSE 0.304012\n",
      "Epoch 021 | train RMSE 0.221557 | val RMSE 0.303689\n",
      "Epoch 022 | train RMSE 0.220095 | val RMSE 0.303407\n",
      "Epoch 023 | train RMSE 0.218667 | val RMSE 0.303164\n",
      "Epoch 024 | train RMSE 0.217271 | val RMSE 0.302960\n",
      "Epoch 025 | train RMSE 0.215906 | val RMSE 0.302792\n",
      "Saved baseline model and learning curve\n"
     ]
    }
   ],
   "source": [
    "panel_fiat = build_panel_for_market(data, [\"FIAT\"], BASELINE_WINDOW)\n",
    "model1, loss_hist1, val_hist1 = train_nn(\n",
    "    panel_fiat[\"Xtr\"], panel_fiat[\"ytr\"],\n",
    "    panel_fiat[\"Xval\"], panel_fiat[\"yval\"],\n",
    "    hidden=BASELINE_HIDDEN, lr=BASELINE_LR, act=BASELINE_ACT,\n",
    "    epochs=BASELINE_EPOCHS\n",
    ")\n",
    "torch.save(model1.state_dict(), \"outputs/model_step1_fiat.pt\")\n",
    "plot_learning_curve(loss_hist1, val_hist1, \"FIAT w=12 baseline\", \"outputs/step1_learning_curve_fiat_w12.png\")\n",
    "p(\"Saved baseline model and learning curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e616d1e7",
   "metadata": {},
   "source": [
    "### Step 2 – Hyper‑parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5ade4c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning market=FIAT\n",
      "Epoch 001 | train RMSE 0.331727 | val RMSE 0.344828\n",
      "Epoch 002 | train RMSE 0.328838 | val RMSE 0.343624\n",
      "Epoch 003 | train RMSE 0.325982 | val RMSE 0.342430\n",
      "Epoch 004 | train RMSE 0.323160 | val RMSE 0.341248\n",
      "Epoch 005 | train RMSE 0.320372 | val RMSE 0.340076\n",
      "Epoch 006 | train RMSE 0.317619 | val RMSE 0.338916\n",
      "Epoch 007 | train RMSE 0.314902 | val RMSE 0.337767\n",
      "Epoch 008 | train RMSE 0.312222 | val RMSE 0.336629\n",
      "Epoch 009 | train RMSE 0.309578 | val RMSE 0.335502\n",
      "Epoch 010 | train RMSE 0.306972 | val RMSE 0.334387\n",
      "  h=4 lr=0.001 act=linear -> val RMSE=0.33439\n",
      "Epoch 001 | train RMSE 0.259909 | val RMSE 0.257399\n",
      "Epoch 002 | train RMSE 0.258778 | val RMSE 0.257349\n",
      "Epoch 003 | train RMSE 0.257663 | val RMSE 0.257307\n",
      "Epoch 004 | train RMSE 0.256562 | val RMSE 0.257273\n",
      "Epoch 005 | train RMSE 0.255478 | val RMSE 0.257247\n",
      "Epoch 006 | train RMSE 0.254411 | val RMSE 0.257229\n",
      "Epoch 007 | train RMSE 0.253359 | val RMSE 0.257219\n",
      "Epoch 008 | train RMSE 0.252325 | val RMSE 0.257218\n",
      "Epoch 009 | train RMSE 0.251307 | val RMSE 0.257225\n",
      "Epoch 010 | train RMSE 0.250306 | val RMSE 0.257240\n",
      "  h=4 lr=0.001 act=tanh -> val RMSE=0.25724\n",
      "Epoch 001 | train RMSE 0.521311 | val RMSE 0.476019\n",
      "Epoch 002 | train RMSE 0.518971 | val RMSE 0.474215\n",
      "Epoch 003 | train RMSE 0.516639 | val RMSE 0.472402\n",
      "Epoch 004 | train RMSE 0.514298 | val RMSE 0.470595\n",
      "Epoch 005 | train RMSE 0.511974 | val RMSE 0.468790\n",
      "Epoch 006 | train RMSE 0.509655 | val RMSE 0.466990\n",
      "Epoch 007 | train RMSE 0.507338 | val RMSE 0.465194\n",
      "Epoch 008 | train RMSE 0.505020 | val RMSE 0.463400\n",
      "Epoch 009 | train RMSE 0.502693 | val RMSE 0.461613\n",
      "Epoch 010 | train RMSE 0.500357 | val RMSE 0.459830\n",
      "  h=4 lr=0.001 act=relu -> val RMSE=0.45983\n",
      "Epoch 001 | train RMSE 0.280390 | val RMSE 0.292068\n",
      "Epoch 002 | train RMSE 0.259808 | val RMSE 0.287226\n",
      "Epoch 003 | train RMSE 0.241991 | val RMSE 0.283759\n",
      "Epoch 004 | train RMSE 0.227168 | val RMSE 0.281965\n",
      "Epoch 005 | train RMSE 0.215275 | val RMSE 0.282070\n",
      "Epoch 006 | train RMSE 0.206277 | val RMSE 0.283895\n",
      "Epoch 007 | train RMSE 0.199769 | val RMSE 0.286972\n",
      "Epoch 008 | train RMSE 0.194737 | val RMSE 0.290706\n",
      "Epoch 009 | train RMSE 0.189931 | val RMSE 0.294575\n",
      "Epoch 010 | train RMSE 0.184509 | val RMSE 0.298255\n",
      "  h=4 lr=0.01 act=linear -> val RMSE=0.29825\n",
      "Epoch 001 | train RMSE 0.492067 | val RMSE 0.543967\n",
      "Epoch 002 | train RMSE 0.463361 | val RMSE 0.528415\n",
      "Epoch 003 | train RMSE 0.435803 | val RMSE 0.513293\n",
      "Epoch 004 | train RMSE 0.409454 | val RMSE 0.498704\n",
      "Epoch 005 | train RMSE 0.384318 | val RMSE 0.484775\n",
      "Epoch 006 | train RMSE 0.360314 | val RMSE 0.471602\n",
      "Epoch 007 | train RMSE 0.337289 | val RMSE 0.459202\n",
      "Epoch 008 | train RMSE 0.315104 | val RMSE 0.447527\n",
      "Epoch 009 | train RMSE 0.293742 | val RMSE 0.436523\n",
      "Epoch 010 | train RMSE 0.273334 | val RMSE 0.426156\n",
      "  h=4 lr=0.01 act=tanh -> val RMSE=0.42616\n",
      "Epoch 001 | train RMSE 0.301016 | val RMSE 0.284880\n",
      "Epoch 002 | train RMSE 0.290179 | val RMSE 0.279912\n",
      "Epoch 003 | train RMSE 0.278802 | val RMSE 0.275616\n",
      "Epoch 004 | train RMSE 0.266037 | val RMSE 0.272147\n",
      "Epoch 005 | train RMSE 0.252457 | val RMSE 0.269538\n",
      "Epoch 006 | train RMSE 0.239008 | val RMSE 0.267817\n",
      "Epoch 007 | train RMSE 0.226348 | val RMSE 0.267309\n",
      "Epoch 008 | train RMSE 0.214858 | val RMSE 0.268017\n",
      "Epoch 009 | train RMSE 0.205347 | val RMSE 0.270015\n",
      "Epoch 010 | train RMSE 0.198426 | val RMSE 0.273068\n",
      "  h=4 lr=0.01 act=relu -> val RMSE=0.27307\n",
      "Epoch 001 | train RMSE 0.247022 | val RMSE 0.264171\n",
      "Epoch 002 | train RMSE 0.245068 | val RMSE 0.264721\n",
      "Epoch 003 | train RMSE 0.243171 | val RMSE 0.265326\n",
      "Epoch 004 | train RMSE 0.241324 | val RMSE 0.265966\n",
      "Epoch 005 | train RMSE 0.239523 | val RMSE 0.266633\n",
      "Epoch 006 | train RMSE 0.237768 | val RMSE 0.267322\n",
      "Epoch 007 | train RMSE 0.236059 | val RMSE 0.268031\n",
      "Epoch 008 | train RMSE 0.234395 | val RMSE 0.268760\n",
      "Epoch 009 | train RMSE 0.232775 | val RMSE 0.269506\n",
      "Epoch 010 | train RMSE 0.231199 | val RMSE 0.270269\n",
      "  h=8 lr=0.001 act=linear -> val RMSE=0.27027\n",
      "Epoch 001 | train RMSE 0.479419 | val RMSE 0.498331\n",
      "Epoch 002 | train RMSE 0.474906 | val RMSE 0.496201\n",
      "Epoch 003 | train RMSE 0.470417 | val RMSE 0.494098\n",
      "Epoch 004 | train RMSE 0.465952 | val RMSE 0.492031\n",
      "Epoch 005 | train RMSE 0.461510 | val RMSE 0.489993\n",
      "Epoch 006 | train RMSE 0.457089 | val RMSE 0.487973\n",
      "Epoch 007 | train RMSE 0.452690 | val RMSE 0.485968\n",
      "Epoch 008 | train RMSE 0.448311 | val RMSE 0.483977\n",
      "Epoch 009 | train RMSE 0.443955 | val RMSE 0.481998\n",
      "Epoch 010 | train RMSE 0.439620 | val RMSE 0.480031\n",
      "  h=8 lr=0.001 act=tanh -> val RMSE=0.48003\n",
      "Epoch 001 | train RMSE 0.299746 | val RMSE 0.276827\n",
      "Epoch 002 | train RMSE 0.297479 | val RMSE 0.276055\n",
      "Epoch 003 | train RMSE 0.295230 | val RMSE 0.275302\n",
      "Epoch 004 | train RMSE 0.292997 | val RMSE 0.274563\n",
      "Epoch 005 | train RMSE 0.290771 | val RMSE 0.273821\n",
      "Epoch 006 | train RMSE 0.288546 | val RMSE 0.273098\n",
      "Epoch 007 | train RMSE 0.286309 | val RMSE 0.272388\n",
      "Epoch 008 | train RMSE 0.284079 | val RMSE 0.271702\n",
      "Epoch 009 | train RMSE 0.281865 | val RMSE 0.271027\n",
      "Epoch 010 | train RMSE 0.279671 | val RMSE 0.270369\n",
      "  h=8 lr=0.001 act=relu -> val RMSE=0.27037\n",
      "Epoch 001 | train RMSE 0.371167 | val RMSE 0.376202\n",
      "Epoch 002 | train RMSE 0.341947 | val RMSE 0.363553\n",
      "Epoch 003 | train RMSE 0.314844 | val RMSE 0.351151\n",
      "Epoch 004 | train RMSE 0.289388 | val RMSE 0.339308\n",
      "Epoch 005 | train RMSE 0.265468 | val RMSE 0.328278\n",
      "Epoch 006 | train RMSE 0.243469 | val RMSE 0.318339\n",
      "Epoch 007 | train RMSE 0.224016 | val RMSE 0.309782\n",
      "Epoch 008 | train RMSE 0.207896 | val RMSE 0.302872\n",
      "Epoch 009 | train RMSE 0.195823 | val RMSE 0.297897\n",
      "Epoch 010 | train RMSE 0.188080 | val RMSE 0.295171\n",
      "  h=8 lr=0.01 act=linear -> val RMSE=0.29517\n",
      "Epoch 001 | train RMSE 0.369835 | val RMSE 0.339467\n",
      "Epoch 002 | train RMSE 0.330321 | val RMSE 0.324570\n",
      "Epoch 003 | train RMSE 0.294132 | val RMSE 0.310826\n",
      "Epoch 004 | train RMSE 0.262109 | val RMSE 0.298966\n",
      "Epoch 005 | train RMSE 0.235116 | val RMSE 0.289750\n",
      "Epoch 006 | train RMSE 0.214165 | val RMSE 0.283626\n",
      "Epoch 007 | train RMSE 0.200151 | val RMSE 0.280734\n",
      "Epoch 008 | train RMSE 0.192578 | val RMSE 0.280875\n",
      "Epoch 009 | train RMSE 0.189050 | val RMSE 0.283390\n",
      "Epoch 010 | train RMSE 0.186541 | val RMSE 0.287443\n",
      "  h=8 lr=0.01 act=tanh -> val RMSE=0.28744\n",
      "Epoch 001 | train RMSE 0.306881 | val RMSE 0.321163\n",
      "Epoch 002 | train RMSE 0.291203 | val RMSE 0.313031\n",
      "Epoch 003 | train RMSE 0.277336 | val RMSE 0.305380\n",
      "Epoch 004 | train RMSE 0.265409 | val RMSE 0.298013\n",
      "Epoch 005 | train RMSE 0.255377 | val RMSE 0.291147\n",
      "Epoch 006 | train RMSE 0.246399 | val RMSE 0.285025\n",
      "Epoch 007 | train RMSE 0.239078 | val RMSE 0.279713\n",
      "Epoch 008 | train RMSE 0.233046 | val RMSE 0.275202\n",
      "Epoch 009 | train RMSE 0.227851 | val RMSE 0.271570\n",
      "Epoch 010 | train RMSE 0.223324 | val RMSE 0.268875\n",
      "  h=8 lr=0.01 act=relu -> val RMSE=0.26887\n",
      "Epoch 001 | train RMSE 0.268063 | val RMSE 0.274935\n",
      "Epoch 002 | train RMSE 0.263773 | val RMSE 0.273820\n",
      "Epoch 003 | train RMSE 0.259566 | val RMSE 0.272769\n",
      "Epoch 004 | train RMSE 0.255444 | val RMSE 0.271768\n",
      "Epoch 005 | train RMSE 0.251407 | val RMSE 0.270811\n",
      "Epoch 006 | train RMSE 0.247451 | val RMSE 0.269910\n",
      "Epoch 007 | train RMSE 0.243572 | val RMSE 0.269078\n",
      "Epoch 008 | train RMSE 0.239773 | val RMSE 0.268325\n",
      "Epoch 009 | train RMSE 0.236055 | val RMSE 0.267657\n",
      "Epoch 010 | train RMSE 0.232420 | val RMSE 0.267077\n",
      "  h=16 lr=0.001 act=linear -> val RMSE=0.26708\n",
      "Epoch 001 | train RMSE 0.261447 | val RMSE 0.285801\n",
      "Epoch 002 | train RMSE 0.257441 | val RMSE 0.285095\n",
      "Epoch 003 | train RMSE 0.253514 | val RMSE 0.284485\n",
      "Epoch 004 | train RMSE 0.249667 | val RMSE 0.283961\n",
      "Epoch 005 | train RMSE 0.245901 | val RMSE 0.283507\n",
      "Epoch 006 | train RMSE 0.242221 | val RMSE 0.283120\n",
      "Epoch 007 | train RMSE 0.238631 | val RMSE 0.282796\n",
      "Epoch 008 | train RMSE 0.235134 | val RMSE 0.282533\n",
      "Epoch 009 | train RMSE 0.231733 | val RMSE 0.282331\n",
      "Epoch 010 | train RMSE 0.228428 | val RMSE 0.282187\n",
      "  h=16 lr=0.001 act=tanh -> val RMSE=0.28219\n",
      "Epoch 001 | train RMSE 0.261593 | val RMSE 0.265872\n",
      "Epoch 002 | train RMSE 0.258657 | val RMSE 0.265313\n",
      "Epoch 003 | train RMSE 0.255795 | val RMSE 0.264810\n",
      "Epoch 004 | train RMSE 0.252996 | val RMSE 0.264368\n",
      "Epoch 005 | train RMSE 0.250275 | val RMSE 0.263989\n",
      "Epoch 006 | train RMSE 0.247644 | val RMSE 0.263664\n",
      "Epoch 007 | train RMSE 0.245118 | val RMSE 0.263406\n",
      "Epoch 008 | train RMSE 0.242690 | val RMSE 0.263216\n",
      "Epoch 009 | train RMSE 0.240388 | val RMSE 0.263098\n",
      "Epoch 010 | train RMSE 0.238168 | val RMSE 0.263048\n",
      "  h=16 lr=0.001 act=relu -> val RMSE=0.26305\n",
      "Epoch 001 | train RMSE 0.294032 | val RMSE 0.273961\n",
      "Epoch 002 | train RMSE 0.259018 | val RMSE 0.270845\n",
      "Epoch 003 | train RMSE 0.233464 | val RMSE 0.274466\n",
      "Epoch 004 | train RMSE 0.218366 | val RMSE 0.281439\n",
      "Epoch 005 | train RMSE 0.210920 | val RMSE 0.287053\n",
      "Epoch 006 | train RMSE 0.203592 | val RMSE 0.289639\n",
      "Epoch 007 | train RMSE 0.192787 | val RMSE 0.289968\n",
      "Epoch 008 | train RMSE 0.179709 | val RMSE 0.289423\n",
      "Epoch 009 | train RMSE 0.166913 | val RMSE 0.289247\n",
      "Epoch 010 | train RMSE 0.156442 | val RMSE 0.290261\n",
      "  h=16 lr=0.01 act=linear -> val RMSE=0.29026\n",
      "Epoch 001 | train RMSE 0.208786 | val RMSE 0.268356\n",
      "Epoch 002 | train RMSE 0.187409 | val RMSE 0.281086\n",
      "Epoch 003 | train RMSE 0.170736 | val RMSE 0.289373\n",
      "Epoch 004 | train RMSE 0.156109 | val RMSE 0.297313\n",
      "Epoch 005 | train RMSE 0.145950 | val RMSE 0.307835\n",
      "Epoch 006 | train RMSE 0.139102 | val RMSE 0.319570\n",
      "Epoch 007 | train RMSE 0.134336 | val RMSE 0.328764\n",
      "Epoch 008 | train RMSE 0.131258 | val RMSE 0.332265\n",
      "Epoch 009 | train RMSE 0.127556 | val RMSE 0.331248\n",
      "Epoch 010 | train RMSE 0.122877 | val RMSE 0.328446\n",
      "  h=16 lr=0.01 act=tanh -> val RMSE=0.32845\n",
      "Epoch 001 | train RMSE 0.381477 | val RMSE 0.314230\n",
      "Epoch 002 | train RMSE 0.348757 | val RMSE 0.299408\n",
      "Epoch 003 | train RMSE 0.317824 | val RMSE 0.286495\n",
      "Epoch 004 | train RMSE 0.288669 | val RMSE 0.275737\n",
      "Epoch 005 | train RMSE 0.261392 | val RMSE 0.267517\n",
      "Epoch 006 | train RMSE 0.236336 | val RMSE 0.262090\n",
      "Epoch 007 | train RMSE 0.214319 | val RMSE 0.259768\n",
      "Epoch 008 | train RMSE 0.196412 | val RMSE 0.260501\n",
      "Epoch 009 | train RMSE 0.184015 | val RMSE 0.264207\n",
      "Epoch 010 | train RMSE 0.177370 | val RMSE 0.269981\n",
      "  h=16 lr=0.01 act=relu -> val RMSE=0.26998\n",
      "Tuning market=EQUITY\n",
      "Epoch 001 | train RMSE 0.440740 | val RMSE 0.391749\n",
      "Epoch 002 | train RMSE 0.436387 | val RMSE 0.389618\n",
      "Epoch 003 | train RMSE 0.432045 | val RMSE 0.387520\n",
      "Epoch 004 | train RMSE 0.427714 | val RMSE 0.385454\n",
      "Epoch 005 | train RMSE 0.423393 | val RMSE 0.383423\n",
      "Epoch 006 | train RMSE 0.419085 | val RMSE 0.381426\n",
      "Epoch 007 | train RMSE 0.414788 | val RMSE 0.379463\n",
      "Epoch 008 | train RMSE 0.410504 | val RMSE 0.377536\n",
      "Epoch 009 | train RMSE 0.406233 | val RMSE 0.375645\n",
      "Epoch 010 | train RMSE 0.401975 | val RMSE 0.373789\n",
      "  h=4 lr=0.001 act=linear -> val RMSE=0.37379\n",
      "Epoch 001 | train RMSE 0.725199 | val RMSE 0.666108\n",
      "Epoch 002 | train RMSE 0.719458 | val RMSE 0.664699\n",
      "Epoch 003 | train RMSE 0.713747 | val RMSE 0.663299\n",
      "Epoch 004 | train RMSE 0.708066 | val RMSE 0.661905\n",
      "Epoch 005 | train RMSE 0.702416 | val RMSE 0.660511\n",
      "Epoch 006 | train RMSE 0.696798 | val RMSE 0.659110\n",
      "Epoch 007 | train RMSE 0.691211 | val RMSE 0.657696\n",
      "Epoch 008 | train RMSE 0.685657 | val RMSE 0.656262\n",
      "Epoch 009 | train RMSE 0.680135 | val RMSE 0.654805\n",
      "Epoch 010 | train RMSE 0.674644 | val RMSE 0.653327\n",
      "  h=4 lr=0.001 act=tanh -> val RMSE=0.65333\n",
      "Epoch 001 | train RMSE 0.304107 | val RMSE 0.366659\n",
      "Epoch 002 | train RMSE 0.301174 | val RMSE 0.365144\n",
      "Epoch 003 | train RMSE 0.298260 | val RMSE 0.363644\n",
      "Epoch 004 | train RMSE 0.295367 | val RMSE 0.362158\n",
      "Epoch 005 | train RMSE 0.292495 | val RMSE 0.360680\n",
      "Epoch 006 | train RMSE 0.289644 | val RMSE 0.359199\n",
      "Epoch 007 | train RMSE 0.286814 | val RMSE 0.357671\n",
      "Epoch 008 | train RMSE 0.284006 | val RMSE 0.356157\n",
      "Epoch 009 | train RMSE 0.281220 | val RMSE 0.354665\n",
      "Epoch 010 | train RMSE 0.278455 | val RMSE 0.353195\n",
      "  h=4 lr=0.001 act=relu -> val RMSE=0.35320\n",
      "Epoch 001 | train RMSE 0.411083 | val RMSE 0.377159\n",
      "Epoch 002 | train RMSE 0.365031 | val RMSE 0.362971\n",
      "Epoch 003 | train RMSE 0.323294 | val RMSE 0.352013\n",
      "Epoch 004 | train RMSE 0.285655 | val RMSE 0.344390\n",
      "Epoch 005 | train RMSE 0.251665 | val RMSE 0.339624\n",
      "Epoch 006 | train RMSE 0.220947 | val RMSE 0.337704\n",
      "Epoch 007 | train RMSE 0.193341 | val RMSE 0.338822\n",
      "Epoch 008 | train RMSE 0.168988 | val RMSE 0.343107\n",
      "Epoch 009 | train RMSE 0.148558 | val RMSE 0.350491\n",
      "Epoch 010 | train RMSE 0.133180 | val RMSE 0.360501\n",
      "  h=4 lr=0.01 act=linear -> val RMSE=0.36050\n",
      "Epoch 001 | train RMSE 0.673035 | val RMSE 0.580801\n",
      "Epoch 002 | train RMSE 0.611892 | val RMSE 0.556422\n",
      "Epoch 003 | train RMSE 0.553385 | val RMSE 0.535703\n",
      "Epoch 004 | train RMSE 0.497871 | val RMSE 0.518301\n",
      "Epoch 005 | train RMSE 0.445321 | val RMSE 0.504041\n",
      "Epoch 006 | train RMSE 0.395665 | val RMSE 0.492866\n",
      "Epoch 007 | train RMSE 0.349182 | val RMSE 0.484649\n",
      "Epoch 008 | train RMSE 0.306442 | val RMSE 0.479118\n",
      "Epoch 009 | train RMSE 0.268173 | val RMSE 0.475851\n",
      "Epoch 010 | train RMSE 0.235137 | val RMSE 0.474328\n",
      "  h=4 lr=0.01 act=tanh -> val RMSE=0.47433\n",
      "Epoch 001 | train RMSE 0.400917 | val RMSE 0.424326\n",
      "Epoch 002 | train RMSE 0.353307 | val RMSE 0.401105\n",
      "Epoch 003 | train RMSE 0.309985 | val RMSE 0.381622\n",
      "Epoch 004 | train RMSE 0.270172 | val RMSE 0.365654\n",
      "Epoch 005 | train RMSE 0.234781 | val RMSE 0.353005\n",
      "Epoch 006 | train RMSE 0.205562 | val RMSE 0.342824\n",
      "Epoch 007 | train RMSE 0.183403 | val RMSE 0.335871\n",
      "Epoch 008 | train RMSE 0.167457 | val RMSE 0.332140\n",
      "Epoch 009 | train RMSE 0.157851 | val RMSE 0.331267\n",
      "Epoch 010 | train RMSE 0.153644 | val RMSE 0.332506\n",
      "  h=4 lr=0.01 act=relu -> val RMSE=0.33251\n",
      "Epoch 001 | train RMSE 0.355721 | val RMSE 0.363570\n",
      "Epoch 002 | train RMSE 0.351611 | val RMSE 0.362469\n",
      "Epoch 003 | train RMSE 0.347522 | val RMSE 0.361413\n",
      "Epoch 004 | train RMSE 0.343457 | val RMSE 0.360422\n",
      "Epoch 005 | train RMSE 0.339415 | val RMSE 0.359512\n",
      "Epoch 006 | train RMSE 0.335393 | val RMSE 0.358683\n",
      "Epoch 007 | train RMSE 0.331390 | val RMSE 0.357923\n",
      "Epoch 008 | train RMSE 0.327401 | val RMSE 0.357219\n",
      "Epoch 009 | train RMSE 0.323427 | val RMSE 0.356563\n",
      "Epoch 010 | train RMSE 0.319464 | val RMSE 0.355951\n",
      "  h=8 lr=0.001 act=linear -> val RMSE=0.35595\n",
      "Epoch 001 | train RMSE 0.415263 | val RMSE 0.420375\n",
      "Epoch 002 | train RMSE 0.409181 | val RMSE 0.419128\n",
      "Epoch 003 | train RMSE 0.403138 | val RMSE 0.417988\n",
      "Epoch 004 | train RMSE 0.397133 | val RMSE 0.416952\n",
      "Epoch 005 | train RMSE 0.391166 | val RMSE 0.415999\n",
      "Epoch 006 | train RMSE 0.385237 | val RMSE 0.415111\n",
      "Epoch 007 | train RMSE 0.379347 | val RMSE 0.414278\n",
      "Epoch 008 | train RMSE 0.373498 | val RMSE 0.413490\n",
      "Epoch 009 | train RMSE 0.367690 | val RMSE 0.412743\n",
      "Epoch 010 | train RMSE 0.361923 | val RMSE 0.412030\n",
      "  h=8 lr=0.001 act=tanh -> val RMSE=0.41203\n",
      "Epoch 001 | train RMSE 0.356549 | val RMSE 0.373313\n",
      "Epoch 002 | train RMSE 0.351703 | val RMSE 0.371115\n",
      "Epoch 003 | train RMSE 0.346873 | val RMSE 0.368957\n",
      "Epoch 004 | train RMSE 0.342059 | val RMSE 0.366842\n",
      "Epoch 005 | train RMSE 0.337264 | val RMSE 0.364784\n",
      "Epoch 006 | train RMSE 0.332490 | val RMSE 0.362744\n",
      "Epoch 007 | train RMSE 0.327733 | val RMSE 0.360715\n",
      "Epoch 008 | train RMSE 0.322995 | val RMSE 0.358697\n",
      "Epoch 009 | train RMSE 0.318276 | val RMSE 0.356704\n",
      "Epoch 010 | train RMSE 0.313576 | val RMSE 0.354747\n",
      "  h=8 lr=0.001 act=relu -> val RMSE=0.35475\n",
      "Epoch 001 | train RMSE 0.330057 | val RMSE 0.391243\n",
      "Epoch 002 | train RMSE 0.280940 | val RMSE 0.381438\n",
      "Epoch 003 | train RMSE 0.237936 | val RMSE 0.373402\n",
      "Epoch 004 | train RMSE 0.200067 | val RMSE 0.367988\n",
      "Epoch 005 | train RMSE 0.167512 | val RMSE 0.365469\n",
      "Epoch 006 | train RMSE 0.141103 | val RMSE 0.366018\n",
      "Epoch 007 | train RMSE 0.122770 | val RMSE 0.368900\n",
      "Epoch 008 | train RMSE 0.114839 | val RMSE 0.372953\n",
      "Epoch 009 | train RMSE 0.116010 | val RMSE 0.376918\n",
      "Epoch 010 | train RMSE 0.119895 | val RMSE 0.379389\n",
      "  h=8 lr=0.01 act=linear -> val RMSE=0.37939\n",
      "Epoch 001 | train RMSE 0.427580 | val RMSE 0.426172\n",
      "Epoch 002 | train RMSE 0.347728 | val RMSE 0.394304\n",
      "Epoch 003 | train RMSE 0.279650 | val RMSE 0.368296\n",
      "Epoch 004 | train RMSE 0.223620 | val RMSE 0.349712\n",
      "Epoch 005 | train RMSE 0.178917 | val RMSE 0.340348\n",
      "Epoch 006 | train RMSE 0.145908 | val RMSE 0.339747\n",
      "Epoch 007 | train RMSE 0.126982 | val RMSE 0.345310\n",
      "Epoch 008 | train RMSE 0.121274 | val RMSE 0.353083\n",
      "Epoch 009 | train RMSE 0.121917 | val RMSE 0.360298\n",
      "Epoch 010 | train RMSE 0.123047 | val RMSE 0.365629\n",
      "  h=8 lr=0.01 act=tanh -> val RMSE=0.36563\n",
      "Epoch 001 | train RMSE 0.237687 | val RMSE 0.313420\n",
      "Epoch 002 | train RMSE 0.202642 | val RMSE 0.325173\n",
      "Epoch 003 | train RMSE 0.172924 | val RMSE 0.337390\n",
      "Epoch 004 | train RMSE 0.148910 | val RMSE 0.349011\n",
      "Epoch 005 | train RMSE 0.129077 | val RMSE 0.360176\n",
      "Epoch 006 | train RMSE 0.113097 | val RMSE 0.371341\n",
      "Epoch 007 | train RMSE 0.102013 | val RMSE 0.382066\n",
      "Epoch 008 | train RMSE 0.096061 | val RMSE 0.391269\n",
      "Epoch 009 | train RMSE 0.094023 | val RMSE 0.397981\n",
      "Epoch 010 | train RMSE 0.094090 | val RMSE 0.402622\n",
      "  h=8 lr=0.01 act=relu -> val RMSE=0.40262\n",
      "Epoch 001 | train RMSE 0.441855 | val RMSE 0.427960\n",
      "Epoch 002 | train RMSE 0.430005 | val RMSE 0.422651\n",
      "Epoch 003 | train RMSE 0.418306 | val RMSE 0.417559\n",
      "Epoch 004 | train RMSE 0.406765 | val RMSE 0.412712\n",
      "Epoch 005 | train RMSE 0.395388 | val RMSE 0.408099\n",
      "Epoch 006 | train RMSE 0.384181 | val RMSE 0.403708\n",
      "Epoch 007 | train RMSE 0.373151 | val RMSE 0.399539\n",
      "Epoch 008 | train RMSE 0.362302 | val RMSE 0.395595\n",
      "Epoch 009 | train RMSE 0.351641 | val RMSE 0.391877\n",
      "Epoch 010 | train RMSE 0.341172 | val RMSE 0.388385\n",
      "  h=16 lr=0.001 act=linear -> val RMSE=0.38838\n",
      "Epoch 001 | train RMSE 0.355030 | val RMSE 0.395645\n",
      "Epoch 002 | train RMSE 0.344074 | val RMSE 0.391176\n",
      "Epoch 003 | train RMSE 0.333346 | val RMSE 0.386939\n",
      "Epoch 004 | train RMSE 0.322860 | val RMSE 0.382952\n",
      "Epoch 005 | train RMSE 0.312628 | val RMSE 0.379235\n",
      "Epoch 006 | train RMSE 0.302654 | val RMSE 0.375792\n",
      "Epoch 007 | train RMSE 0.292938 | val RMSE 0.372614\n",
      "Epoch 008 | train RMSE 0.283475 | val RMSE 0.369681\n",
      "Epoch 009 | train RMSE 0.274256 | val RMSE 0.366974\n",
      "Epoch 010 | train RMSE 0.265270 | val RMSE 0.364478\n",
      "  h=16 lr=0.001 act=tanh -> val RMSE=0.36448\n",
      "Epoch 001 | train RMSE 0.323787 | val RMSE 0.399894\n",
      "Epoch 002 | train RMSE 0.317001 | val RMSE 0.396065\n",
      "Epoch 003 | train RMSE 0.310299 | val RMSE 0.392301\n",
      "Epoch 004 | train RMSE 0.303722 | val RMSE 0.388580\n",
      "Epoch 005 | train RMSE 0.297297 | val RMSE 0.384915\n",
      "Epoch 006 | train RMSE 0.291060 | val RMSE 0.381310\n",
      "Epoch 007 | train RMSE 0.284957 | val RMSE 0.377774\n",
      "Epoch 008 | train RMSE 0.279021 | val RMSE 0.374324\n",
      "Epoch 009 | train RMSE 0.273203 | val RMSE 0.370971\n",
      "Epoch 010 | train RMSE 0.267516 | val RMSE 0.367696\n",
      "  h=16 lr=0.001 act=relu -> val RMSE=0.36770\n",
      "Epoch 001 | train RMSE 0.322008 | val RMSE 0.307235\n",
      "Epoch 002 | train RMSE 0.252563 | val RMSE 0.324468\n",
      "Epoch 003 | train RMSE 0.200760 | val RMSE 0.348826\n",
      "Epoch 004 | train RMSE 0.161437 | val RMSE 0.373900\n",
      "Epoch 005 | train RMSE 0.128452 | val RMSE 0.397865\n",
      "Epoch 006 | train RMSE 0.103721 | val RMSE 0.419400\n",
      "Epoch 007 | train RMSE 0.100743 | val RMSE 0.433404\n",
      "Epoch 008 | train RMSE 0.114502 | val RMSE 0.438227\n",
      "Epoch 009 | train RMSE 0.124319 | val RMSE 0.435370\n",
      "Epoch 010 | train RMSE 0.124242 | val RMSE 0.426812\n",
      "  h=16 lr=0.01 act=linear -> val RMSE=0.42681\n",
      "Epoch 001 | train RMSE 0.277891 | val RMSE 0.347644\n",
      "Epoch 002 | train RMSE 0.205959 | val RMSE 0.356436\n",
      "Epoch 003 | train RMSE 0.158733 | val RMSE 0.366227\n",
      "Epoch 004 | train RMSE 0.131976 | val RMSE 0.374734\n",
      "Epoch 005 | train RMSE 0.120387 | val RMSE 0.381287\n",
      "Epoch 006 | train RMSE 0.116799 | val RMSE 0.384473\n",
      "Epoch 007 | train RMSE 0.116543 | val RMSE 0.384478\n",
      "Epoch 008 | train RMSE 0.115622 | val RMSE 0.382065\n",
      "Epoch 009 | train RMSE 0.111637 | val RMSE 0.377360\n",
      "Epoch 010 | train RMSE 0.105077 | val RMSE 0.370501\n",
      "  h=16 lr=0.01 act=tanh -> val RMSE=0.37050\n",
      "Epoch 001 | train RMSE 0.331065 | val RMSE 0.319608\n",
      "Epoch 002 | train RMSE 0.273763 | val RMSE 0.301825\n",
      "Epoch 003 | train RMSE 0.230528 | val RMSE 0.294808\n",
      "Epoch 004 | train RMSE 0.198439 | val RMSE 0.295101\n",
      "Epoch 005 | train RMSE 0.173537 | val RMSE 0.298192\n",
      "Epoch 006 | train RMSE 0.151353 | val RMSE 0.302516\n",
      "Epoch 007 | train RMSE 0.128977 | val RMSE 0.307746\n",
      "Epoch 008 | train RMSE 0.109473 | val RMSE 0.313969\n",
      "Epoch 009 | train RMSE 0.097720 | val RMSE 0.320791\n",
      "Epoch 010 | train RMSE 0.096303 | val RMSE 0.326944\n",
      "  h=16 lr=0.01 act=relu -> val RMSE=0.32694\n",
      "Tuning market=GOLD\n",
      "Epoch 001 | train RMSE 0.555555 | val RMSE 0.619153\n",
      "Epoch 002 | train RMSE 0.552746 | val RMSE 0.617383\n",
      "Epoch 003 | train RMSE 0.549947 | val RMSE 0.615617\n",
      "Epoch 004 | train RMSE 0.547159 | val RMSE 0.613855\n",
      "Epoch 005 | train RMSE 0.544381 | val RMSE 0.612099\n",
      "Epoch 006 | train RMSE 0.541616 | val RMSE 0.610348\n",
      "Epoch 007 | train RMSE 0.538861 | val RMSE 0.608602\n",
      "Epoch 008 | train RMSE 0.536118 | val RMSE 0.606864\n",
      "Epoch 009 | train RMSE 0.533386 | val RMSE 0.605132\n",
      "Epoch 010 | train RMSE 0.530666 | val RMSE 0.603407\n",
      "  h=4 lr=0.001 act=linear -> val RMSE=0.60341\n",
      "Epoch 001 | train RMSE 0.253287 | val RMSE 0.277889\n",
      "Epoch 002 | train RMSE 0.250635 | val RMSE 0.277269\n",
      "Epoch 003 | train RMSE 0.248029 | val RMSE 0.276658\n",
      "Epoch 004 | train RMSE 0.245470 | val RMSE 0.276059\n",
      "Epoch 005 | train RMSE 0.242958 | val RMSE 0.275476\n",
      "Epoch 006 | train RMSE 0.240492 | val RMSE 0.274914\n",
      "Epoch 007 | train RMSE 0.238072 | val RMSE 0.274378\n",
      "Epoch 008 | train RMSE 0.235701 | val RMSE 0.273871\n",
      "Epoch 009 | train RMSE 0.233380 | val RMSE 0.273396\n",
      "Epoch 010 | train RMSE 0.231110 | val RMSE 0.272953\n",
      "  h=4 lr=0.001 act=tanh -> val RMSE=0.27295\n",
      "Epoch 001 | train RMSE 0.430310 | val RMSE 0.423198\n",
      "Epoch 002 | train RMSE 0.427430 | val RMSE 0.421679\n",
      "Epoch 003 | train RMSE 0.424587 | val RMSE 0.420176\n",
      "Epoch 004 | train RMSE 0.421747 | val RMSE 0.418679\n",
      "Epoch 005 | train RMSE 0.418906 | val RMSE 0.417191\n",
      "Epoch 006 | train RMSE 0.416068 | val RMSE 0.415712\n",
      "Epoch 007 | train RMSE 0.413244 | val RMSE 0.414241\n",
      "Epoch 008 | train RMSE 0.410420 | val RMSE 0.412778\n",
      "Epoch 009 | train RMSE 0.407571 | val RMSE 0.411322\n",
      "Epoch 010 | train RMSE 0.404736 | val RMSE 0.409874\n",
      "  h=4 lr=0.001 act=relu -> val RMSE=0.40987\n",
      "Epoch 001 | train RMSE 0.276471 | val RMSE 0.260906\n",
      "Epoch 002 | train RMSE 0.259907 | val RMSE 0.261336\n",
      "Epoch 003 | train RMSE 0.246207 | val RMSE 0.263766\n",
      "Epoch 004 | train RMSE 0.235514 | val RMSE 0.267435\n",
      "Epoch 005 | train RMSE 0.227148 | val RMSE 0.271197\n",
      "Epoch 006 | train RMSE 0.219629 | val RMSE 0.274496\n",
      "Epoch 007 | train RMSE 0.211857 | val RMSE 0.277460\n",
      "Epoch 008 | train RMSE 0.203672 | val RMSE 0.280471\n",
      "Epoch 009 | train RMSE 0.195499 | val RMSE 0.283853\n",
      "Epoch 010 | train RMSE 0.187892 | val RMSE 0.287741\n",
      "  h=4 lr=0.01 act=linear -> val RMSE=0.28774\n",
      "Epoch 001 | train RMSE 0.583590 | val RMSE 0.577665\n",
      "Epoch 002 | train RMSE 0.551831 | val RMSE 0.562395\n",
      "Epoch 003 | train RMSE 0.519594 | val RMSE 0.547277\n",
      "Epoch 004 | train RMSE 0.486968 | val RMSE 0.532354\n",
      "Epoch 005 | train RMSE 0.454066 | val RMSE 0.517680\n",
      "Epoch 006 | train RMSE 0.421026 | val RMSE 0.503314\n",
      "Epoch 007 | train RMSE 0.388026 | val RMSE 0.489328\n",
      "Epoch 008 | train RMSE 0.355295 | val RMSE 0.475798\n",
      "Epoch 009 | train RMSE 0.323151 | val RMSE 0.462810\n",
      "Epoch 010 | train RMSE 0.292045 | val RMSE 0.450454\n",
      "  h=4 lr=0.01 act=tanh -> val RMSE=0.45045\n",
      "Epoch 001 | train RMSE 0.223648 | val RMSE 0.264781\n",
      "Epoch 002 | train RMSE 0.215709 | val RMSE 0.266187\n",
      "Epoch 003 | train RMSE 0.207756 | val RMSE 0.268781\n",
      "Epoch 004 | train RMSE 0.199772 | val RMSE 0.271994\n",
      "Epoch 005 | train RMSE 0.191312 | val RMSE 0.275724\n",
      "Epoch 006 | train RMSE 0.182638 | val RMSE 0.280140\n",
      "Epoch 007 | train RMSE 0.174046 | val RMSE 0.284956\n",
      "Epoch 008 | train RMSE 0.165979 | val RMSE 0.289969\n",
      "Epoch 009 | train RMSE 0.158533 | val RMSE 0.295064\n",
      "Epoch 010 | train RMSE 0.151451 | val RMSE 0.300118\n",
      "  h=4 lr=0.01 act=relu -> val RMSE=0.30012\n",
      "Epoch 001 | train RMSE 0.302849 | val RMSE 0.297268\n",
      "Epoch 002 | train RMSE 0.300409 | val RMSE 0.296274\n",
      "Epoch 003 | train RMSE 0.297989 | val RMSE 0.295296\n",
      "Epoch 004 | train RMSE 0.295590 | val RMSE 0.294334\n",
      "Epoch 005 | train RMSE 0.293213 | val RMSE 0.293389\n",
      "Epoch 006 | train RMSE 0.290859 | val RMSE 0.292461\n",
      "Epoch 007 | train RMSE 0.288528 | val RMSE 0.291551\n",
      "Epoch 008 | train RMSE 0.286221 | val RMSE 0.290659\n",
      "Epoch 009 | train RMSE 0.283938 | val RMSE 0.289786\n",
      "Epoch 010 | train RMSE 0.281681 | val RMSE 0.288934\n",
      "  h=8 lr=0.001 act=linear -> val RMSE=0.28893\n",
      "Epoch 001 | train RMSE 0.190567 | val RMSE 0.269415\n",
      "Epoch 002 | train RMSE 0.189182 | val RMSE 0.269463\n",
      "Epoch 003 | train RMSE 0.187835 | val RMSE 0.269662\n",
      "Epoch 004 | train RMSE 0.186515 | val RMSE 0.270042\n",
      "Epoch 005 | train RMSE 0.185206 | val RMSE 0.270600\n",
      "Epoch 006 | train RMSE 0.183896 | val RMSE 0.271308\n",
      "Epoch 007 | train RMSE 0.182577 | val RMSE 0.272125\n",
      "Epoch 008 | train RMSE 0.181252 | val RMSE 0.273020\n",
      "Epoch 009 | train RMSE 0.179924 | val RMSE 0.273964\n",
      "Epoch 010 | train RMSE 0.178598 | val RMSE 0.274935\n",
      "  h=8 lr=0.001 act=tanh -> val RMSE=0.27494\n",
      "Epoch 001 | train RMSE 0.349737 | val RMSE 0.339073\n",
      "Epoch 002 | train RMSE 0.346639 | val RMSE 0.337476\n",
      "Epoch 003 | train RMSE 0.343573 | val RMSE 0.335890\n",
      "Epoch 004 | train RMSE 0.340526 | val RMSE 0.334312\n",
      "Epoch 005 | train RMSE 0.337494 | val RMSE 0.332744\n",
      "Epoch 006 | train RMSE 0.334507 | val RMSE 0.331188\n",
      "Epoch 007 | train RMSE 0.331548 | val RMSE 0.329649\n",
      "Epoch 008 | train RMSE 0.328606 | val RMSE 0.328123\n",
      "Epoch 009 | train RMSE 0.325681 | val RMSE 0.326610\n",
      "Epoch 010 | train RMSE 0.322765 | val RMSE 0.325110\n",
      "  h=8 lr=0.001 act=relu -> val RMSE=0.32511\n",
      "Epoch 001 | train RMSE 0.256384 | val RMSE 0.300804\n",
      "Epoch 002 | train RMSE 0.234518 | val RMSE 0.291423\n",
      "Epoch 003 | train RMSE 0.217500 | val RMSE 0.284558\n",
      "Epoch 004 | train RMSE 0.204888 | val RMSE 0.281044\n",
      "Epoch 005 | train RMSE 0.195399 | val RMSE 0.281088\n",
      "Epoch 006 | train RMSE 0.187210 | val RMSE 0.284188\n",
      "Epoch 007 | train RMSE 0.178701 | val RMSE 0.289607\n",
      "Epoch 008 | train RMSE 0.169444 | val RMSE 0.296751\n",
      "Epoch 009 | train RMSE 0.160210 | val RMSE 0.305127\n",
      "Epoch 010 | train RMSE 0.152294 | val RMSE 0.314106\n",
      "  h=8 lr=0.01 act=linear -> val RMSE=0.31411\n",
      "Epoch 001 | train RMSE 0.506185 | val RMSE 0.499617\n",
      "Epoch 002 | train RMSE 0.459750 | val RMSE 0.479543\n",
      "Epoch 003 | train RMSE 0.416297 | val RMSE 0.460388\n",
      "Epoch 004 | train RMSE 0.375878 | val RMSE 0.442124\n",
      "Epoch 005 | train RMSE 0.338799 | val RMSE 0.424783\n",
      "Epoch 006 | train RMSE 0.305560 | val RMSE 0.408371\n",
      "Epoch 007 | train RMSE 0.276662 | val RMSE 0.392919\n",
      "Epoch 008 | train RMSE 0.252439 | val RMSE 0.378571\n",
      "Epoch 009 | train RMSE 0.233009 | val RMSE 0.365596\n",
      "Epoch 010 | train RMSE 0.218291 | val RMSE 0.354308\n",
      "  h=8 lr=0.01 act=tanh -> val RMSE=0.35431\n",
      "Epoch 001 | train RMSE 0.362337 | val RMSE 0.363467\n",
      "Epoch 002 | train RMSE 0.337733 | val RMSE 0.350873\n",
      "Epoch 003 | train RMSE 0.313269 | val RMSE 0.338955\n",
      "Epoch 004 | train RMSE 0.288575 | val RMSE 0.327779\n",
      "Epoch 005 | train RMSE 0.264372 | val RMSE 0.317684\n",
      "Epoch 006 | train RMSE 0.241767 | val RMSE 0.309028\n",
      "Epoch 007 | train RMSE 0.222087 | val RMSE 0.301957\n",
      "Epoch 008 | train RMSE 0.206051 | val RMSE 0.296678\n",
      "Epoch 009 | train RMSE 0.193968 | val RMSE 0.293397\n",
      "Epoch 010 | train RMSE 0.185636 | val RMSE 0.292084\n",
      "  h=8 lr=0.01 act=relu -> val RMSE=0.29208\n",
      "Epoch 001 | train RMSE 0.243527 | val RMSE 0.257504\n",
      "Epoch 002 | train RMSE 0.239170 | val RMSE 0.258249\n",
      "Epoch 003 | train RMSE 0.234915 | val RMSE 0.259124\n",
      "Epoch 004 | train RMSE 0.230769 | val RMSE 0.260126\n",
      "Epoch 005 | train RMSE 0.226738 | val RMSE 0.261249\n",
      "Epoch 006 | train RMSE 0.222829 | val RMSE 0.262488\n",
      "Epoch 007 | train RMSE 0.219048 | val RMSE 0.263835\n",
      "Epoch 008 | train RMSE 0.215401 | val RMSE 0.265283\n",
      "Epoch 009 | train RMSE 0.211893 | val RMSE 0.266822\n",
      "Epoch 010 | train RMSE 0.208529 | val RMSE 0.268439\n",
      "  h=16 lr=0.001 act=linear -> val RMSE=0.26844\n",
      "Epoch 001 | train RMSE 0.289306 | val RMSE 0.285249\n",
      "Epoch 002 | train RMSE 0.285542 | val RMSE 0.284237\n",
      "Epoch 003 | train RMSE 0.281848 | val RMSE 0.283271\n",
      "Epoch 004 | train RMSE 0.278227 | val RMSE 0.282352\n",
      "Epoch 005 | train RMSE 0.274680 | val RMSE 0.281482\n",
      "Epoch 006 | train RMSE 0.271209 | val RMSE 0.280661\n",
      "Epoch 007 | train RMSE 0.267814 | val RMSE 0.279887\n",
      "Epoch 008 | train RMSE 0.264495 | val RMSE 0.279159\n",
      "Epoch 009 | train RMSE 0.261251 | val RMSE 0.278478\n",
      "Epoch 010 | train RMSE 0.258081 | val RMSE 0.277841\n",
      "  h=16 lr=0.001 act=tanh -> val RMSE=0.27784\n",
      "Epoch 001 | train RMSE 0.259197 | val RMSE 0.267824\n",
      "Epoch 002 | train RMSE 0.256414 | val RMSE 0.266831\n",
      "Epoch 003 | train RMSE 0.253702 | val RMSE 0.265888\n",
      "Epoch 004 | train RMSE 0.251049 | val RMSE 0.264994\n",
      "Epoch 005 | train RMSE 0.248437 | val RMSE 0.264149\n",
      "Epoch 006 | train RMSE 0.245888 | val RMSE 0.263350\n",
      "Epoch 007 | train RMSE 0.243421 | val RMSE 0.262608\n",
      "Epoch 008 | train RMSE 0.241021 | val RMSE 0.261924\n",
      "Epoch 009 | train RMSE 0.238699 | val RMSE 0.261297\n",
      "Epoch 010 | train RMSE 0.236451 | val RMSE 0.260742\n",
      "  h=16 lr=0.001 act=relu -> val RMSE=0.26074\n",
      "Epoch 001 | train RMSE 0.269840 | val RMSE 0.318110\n",
      "Epoch 002 | train RMSE 0.234744 | val RMSE 0.307923\n",
      "Epoch 003 | train RMSE 0.210518 | val RMSE 0.302228\n",
      "Epoch 004 | train RMSE 0.195524 | val RMSE 0.301342\n",
      "Epoch 005 | train RMSE 0.185903 | val RMSE 0.304737\n",
      "Epoch 006 | train RMSE 0.176686 | val RMSE 0.310856\n",
      "Epoch 007 | train RMSE 0.166270 | val RMSE 0.318376\n",
      "Epoch 008 | train RMSE 0.155972 | val RMSE 0.326421\n",
      "Epoch 009 | train RMSE 0.148151 | val RMSE 0.333587\n",
      "Epoch 010 | train RMSE 0.143868 | val RMSE 0.338119\n",
      "  h=16 lr=0.01 act=linear -> val RMSE=0.33812\n",
      "Epoch 001 | train RMSE 0.263471 | val RMSE 0.269931\n",
      "Epoch 002 | train RMSE 0.221627 | val RMSE 0.269817\n",
      "Epoch 003 | train RMSE 0.194209 | val RMSE 0.276325\n",
      "Epoch 004 | train RMSE 0.182414 | val RMSE 0.285238\n",
      "Epoch 005 | train RMSE 0.177393 | val RMSE 0.292872\n",
      "Epoch 006 | train RMSE 0.171460 | val RMSE 0.297770\n",
      "Epoch 007 | train RMSE 0.162889 | val RMSE 0.300399\n",
      "Epoch 008 | train RMSE 0.153256 | val RMSE 0.301865\n",
      "Epoch 009 | train RMSE 0.144424 | val RMSE 0.303210\n",
      "Epoch 010 | train RMSE 0.137822 | val RMSE 0.305036\n",
      "  h=16 lr=0.01 act=tanh -> val RMSE=0.30504\n",
      "Epoch 001 | train RMSE 0.377813 | val RMSE 0.385693\n",
      "Epoch 002 | train RMSE 0.342036 | val RMSE 0.364767\n",
      "Epoch 003 | train RMSE 0.312148 | val RMSE 0.345632\n",
      "Epoch 004 | train RMSE 0.286859 | val RMSE 0.328625\n",
      "Epoch 005 | train RMSE 0.266254 | val RMSE 0.313869\n",
      "Epoch 006 | train RMSE 0.250114 | val RMSE 0.301675\n",
      "Epoch 007 | train RMSE 0.237535 | val RMSE 0.292127\n",
      "Epoch 008 | train RMSE 0.227620 | val RMSE 0.285229\n",
      "Epoch 009 | train RMSE 0.219269 | val RMSE 0.280686\n",
      "Epoch 010 | train RMSE 0.212481 | val RMSE 0.278493\n",
      "  h=16 lr=0.01 act=relu -> val RMSE=0.27849\n",
      "Tuning market=ENERGY\n",
      "Epoch 001 | train RMSE 0.289935 | val RMSE 0.256306\n",
      "Epoch 002 | train RMSE 0.287762 | val RMSE 0.256007\n",
      "Epoch 003 | train RMSE 0.285615 | val RMSE 0.255733\n",
      "Epoch 004 | train RMSE 0.283496 | val RMSE 0.255485\n",
      "Epoch 005 | train RMSE 0.281405 | val RMSE 0.255262\n",
      "Epoch 006 | train RMSE 0.279344 | val RMSE 0.255066\n",
      "Epoch 007 | train RMSE 0.277314 | val RMSE 0.254896\n",
      "Epoch 008 | train RMSE 0.275314 | val RMSE 0.254753\n",
      "Epoch 009 | train RMSE 0.273347 | val RMSE 0.254636\n",
      "Epoch 010 | train RMSE 0.271413 | val RMSE 0.254546\n",
      "  h=4 lr=0.001 act=linear -> val RMSE=0.25455\n",
      "Epoch 001 | train RMSE 0.276174 | val RMSE 0.279364\n",
      "Epoch 002 | train RMSE 0.273355 | val RMSE 0.278751\n",
      "Epoch 003 | train RMSE 0.270561 | val RMSE 0.278162\n",
      "Epoch 004 | train RMSE 0.267792 | val RMSE 0.277597\n",
      "Epoch 005 | train RMSE 0.265050 | val RMSE 0.277055\n",
      "Epoch 006 | train RMSE 0.262336 | val RMSE 0.276537\n",
      "Epoch 007 | train RMSE 0.259651 | val RMSE 0.276042\n",
      "Epoch 008 | train RMSE 0.256996 | val RMSE 0.275569\n",
      "Epoch 009 | train RMSE 0.254372 | val RMSE 0.275118\n",
      "Epoch 010 | train RMSE 0.251780 | val RMSE 0.274689\n",
      "  h=4 lr=0.001 act=tanh -> val RMSE=0.27469\n",
      "Epoch 001 | train RMSE 0.254031 | val RMSE 0.269554\n",
      "Epoch 002 | train RMSE 0.252316 | val RMSE 0.268950\n",
      "Epoch 003 | train RMSE 0.250615 | val RMSE 0.268376\n",
      "Epoch 004 | train RMSE 0.248942 | val RMSE 0.267854\n",
      "Epoch 005 | train RMSE 0.247349 | val RMSE 0.267417\n",
      "Epoch 006 | train RMSE 0.245813 | val RMSE 0.267058\n",
      "Epoch 007 | train RMSE 0.244287 | val RMSE 0.266772\n",
      "Epoch 008 | train RMSE 0.242774 | val RMSE 0.266538\n",
      "Epoch 009 | train RMSE 0.241257 | val RMSE 0.266349\n",
      "Epoch 010 | train RMSE 0.239738 | val RMSE 0.266190\n",
      "  h=4 lr=0.001 act=relu -> val RMSE=0.26619\n",
      "Epoch 001 | train RMSE 0.267409 | val RMSE 0.274459\n",
      "Epoch 002 | train RMSE 0.247072 | val RMSE 0.270169\n",
      "Epoch 003 | train RMSE 0.230199 | val RMSE 0.267877\n",
      "Epoch 004 | train RMSE 0.216572 | val RMSE 0.267767\n",
      "Epoch 005 | train RMSE 0.205844 | val RMSE 0.269717\n",
      "Epoch 006 | train RMSE 0.197244 | val RMSE 0.273352\n",
      "Epoch 007 | train RMSE 0.189812 | val RMSE 0.278119\n",
      "Epoch 008 | train RMSE 0.182650 | val RMSE 0.283479\n",
      "Epoch 009 | train RMSE 0.175066 | val RMSE 0.289073\n",
      "Epoch 010 | train RMSE 0.166701 | val RMSE 0.294756\n",
      "  h=4 lr=0.01 act=linear -> val RMSE=0.29476\n",
      "Epoch 001 | train RMSE 0.422795 | val RMSE 0.495280\n",
      "Epoch 002 | train RMSE 0.379985 | val RMSE 0.481081\n",
      "Epoch 003 | train RMSE 0.338329 | val RMSE 0.467678\n",
      "Epoch 004 | train RMSE 0.298676 | val RMSE 0.455016\n",
      "Epoch 005 | train RMSE 0.262274 | val RMSE 0.443191\n",
      "Epoch 006 | train RMSE 0.230854 | val RMSE 0.432252\n",
      "Epoch 007 | train RMSE 0.206548 | val RMSE 0.422213\n",
      "Epoch 008 | train RMSE 0.191048 | val RMSE 0.413138\n",
      "Epoch 009 | train RMSE 0.184225 | val RMSE 0.405175\n",
      "Epoch 010 | train RMSE 0.183554 | val RMSE 0.398526\n",
      "  h=4 lr=0.01 act=tanh -> val RMSE=0.39853\n",
      "Epoch 001 | train RMSE 0.243817 | val RMSE 0.268447\n",
      "Epoch 002 | train RMSE 0.234835 | val RMSE 0.267904\n",
      "Epoch 003 | train RMSE 0.225150 | val RMSE 0.267975\n",
      "Epoch 004 | train RMSE 0.215607 | val RMSE 0.268652\n",
      "Epoch 005 | train RMSE 0.206350 | val RMSE 0.269961\n",
      "Epoch 006 | train RMSE 0.197322 | val RMSE 0.271859\n",
      "Epoch 007 | train RMSE 0.188354 | val RMSE 0.274323\n",
      "Epoch 008 | train RMSE 0.179629 | val RMSE 0.277267\n",
      "Epoch 009 | train RMSE 0.171203 | val RMSE 0.280666\n",
      "Epoch 010 | train RMSE 0.162999 | val RMSE 0.284489\n",
      "  h=4 lr=0.01 act=relu -> val RMSE=0.28449\n",
      "Epoch 001 | train RMSE 0.326378 | val RMSE 0.284419\n",
      "Epoch 002 | train RMSE 0.322289 | val RMSE 0.283324\n",
      "Epoch 003 | train RMSE 0.318237 | val RMSE 0.282276\n",
      "Epoch 004 | train RMSE 0.314224 | val RMSE 0.281277\n",
      "Epoch 005 | train RMSE 0.310253 | val RMSE 0.280326\n",
      "Epoch 006 | train RMSE 0.306326 | val RMSE 0.279424\n",
      "Epoch 007 | train RMSE 0.302447 | val RMSE 0.278571\n",
      "Epoch 008 | train RMSE 0.298617 | val RMSE 0.277768\n",
      "Epoch 009 | train RMSE 0.294838 | val RMSE 0.277014\n",
      "Epoch 010 | train RMSE 0.291113 | val RMSE 0.276310\n",
      "  h=8 lr=0.001 act=linear -> val RMSE=0.27631\n",
      "Epoch 001 | train RMSE 0.260839 | val RMSE 0.286106\n",
      "Epoch 002 | train RMSE 0.257985 | val RMSE 0.285467\n",
      "Epoch 003 | train RMSE 0.255180 | val RMSE 0.284914\n",
      "Epoch 004 | train RMSE 0.252424 | val RMSE 0.284445\n",
      "Epoch 005 | train RMSE 0.249721 | val RMSE 0.284051\n",
      "Epoch 006 | train RMSE 0.247072 | val RMSE 0.283728\n",
      "Epoch 007 | train RMSE 0.244479 | val RMSE 0.283474\n",
      "Epoch 008 | train RMSE 0.241946 | val RMSE 0.283287\n",
      "Epoch 009 | train RMSE 0.239474 | val RMSE 0.283166\n",
      "Epoch 010 | train RMSE 0.237064 | val RMSE 0.283108\n",
      "  h=8 lr=0.001 act=tanh -> val RMSE=0.28311\n",
      "Epoch 001 | train RMSE 0.276738 | val RMSE 0.280113\n",
      "Epoch 002 | train RMSE 0.274969 | val RMSE 0.279518\n",
      "Epoch 003 | train RMSE 0.273207 | val RMSE 0.278938\n",
      "Epoch 004 | train RMSE 0.271453 | val RMSE 0.278370\n",
      "Epoch 005 | train RMSE 0.269716 | val RMSE 0.277806\n",
      "Epoch 006 | train RMSE 0.267985 | val RMSE 0.277256\n",
      "Epoch 007 | train RMSE 0.266263 | val RMSE 0.276715\n",
      "Epoch 008 | train RMSE 0.264550 | val RMSE 0.276185\n",
      "Epoch 009 | train RMSE 0.262846 | val RMSE 0.275665\n",
      "Epoch 010 | train RMSE 0.261150 | val RMSE 0.275156\n",
      "  h=8 lr=0.001 act=relu -> val RMSE=0.27516\n",
      "Epoch 001 | train RMSE 0.283117 | val RMSE 0.291697\n",
      "Epoch 002 | train RMSE 0.256462 | val RMSE 0.286930\n",
      "Epoch 003 | train RMSE 0.235036 | val RMSE 0.284548\n",
      "Epoch 004 | train RMSE 0.217893 | val RMSE 0.284768\n",
      "Epoch 005 | train RMSE 0.203444 | val RMSE 0.287242\n",
      "Epoch 006 | train RMSE 0.190171 | val RMSE 0.291471\n",
      "Epoch 007 | train RMSE 0.176925 | val RMSE 0.297093\n",
      "Epoch 008 | train RMSE 0.163428 | val RMSE 0.303937\n",
      "Epoch 009 | train RMSE 0.150293 | val RMSE 0.311872\n",
      "Epoch 010 | train RMSE 0.138565 | val RMSE 0.320618\n",
      "  h=8 lr=0.01 act=linear -> val RMSE=0.32062\n",
      "Epoch 001 | train RMSE 0.288538 | val RMSE 0.294183\n",
      "Epoch 002 | train RMSE 0.253269 | val RMSE 0.288266\n",
      "Epoch 003 | train RMSE 0.222533 | val RMSE 0.286641\n",
      "Epoch 004 | train RMSE 0.197694 | val RMSE 0.289100\n",
      "Epoch 005 | train RMSE 0.179858 | val RMSE 0.295125\n",
      "Epoch 006 | train RMSE 0.169129 | val RMSE 0.303408\n",
      "Epoch 007 | train RMSE 0.163504 | val RMSE 0.311962\n",
      "Epoch 008 | train RMSE 0.159230 | val RMSE 0.319322\n",
      "Epoch 009 | train RMSE 0.153474 | val RMSE 0.325028\n",
      "Epoch 010 | train RMSE 0.145506 | val RMSE 0.329217\n",
      "  h=8 lr=0.01 act=tanh -> val RMSE=0.32922\n",
      "Epoch 001 | train RMSE 0.321622 | val RMSE 0.296218\n",
      "Epoch 002 | train RMSE 0.296726 | val RMSE 0.285330\n",
      "Epoch 003 | train RMSE 0.274826 | val RMSE 0.276730\n",
      "Epoch 004 | train RMSE 0.255850 | val RMSE 0.270483\n",
      "Epoch 005 | train RMSE 0.240253 | val RMSE 0.266589\n",
      "Epoch 006 | train RMSE 0.228036 | val RMSE 0.265012\n",
      "Epoch 007 | train RMSE 0.218468 | val RMSE 0.265630\n",
      "Epoch 008 | train RMSE 0.211279 | val RMSE 0.268069\n",
      "Epoch 009 | train RMSE 0.205532 | val RMSE 0.271784\n",
      "Epoch 010 | train RMSE 0.200120 | val RMSE 0.276214\n",
      "  h=8 lr=0.01 act=relu -> val RMSE=0.27621\n",
      "Epoch 001 | train RMSE 0.282991 | val RMSE 0.275091\n",
      "Epoch 002 | train RMSE 0.279730 | val RMSE 0.273999\n",
      "Epoch 003 | train RMSE 0.276537 | val RMSE 0.272993\n",
      "Epoch 004 | train RMSE 0.273408 | val RMSE 0.272078\n",
      "Epoch 005 | train RMSE 0.270337 | val RMSE 0.271242\n",
      "Epoch 006 | train RMSE 0.267324 | val RMSE 0.270475\n",
      "Epoch 007 | train RMSE 0.264367 | val RMSE 0.269774\n",
      "Epoch 008 | train RMSE 0.261465 | val RMSE 0.269142\n",
      "Epoch 009 | train RMSE 0.258618 | val RMSE 0.268579\n",
      "Epoch 010 | train RMSE 0.255825 | val RMSE 0.268088\n",
      "  h=16 lr=0.001 act=linear -> val RMSE=0.26809\n",
      "Epoch 001 | train RMSE 0.336498 | val RMSE 0.364544\n",
      "Epoch 002 | train RMSE 0.330516 | val RMSE 0.362649\n",
      "Epoch 003 | train RMSE 0.324593 | val RMSE 0.360789\n",
      "Epoch 004 | train RMSE 0.318731 | val RMSE 0.358963\n",
      "Epoch 005 | train RMSE 0.312933 | val RMSE 0.357172\n",
      "Epoch 006 | train RMSE 0.307199 | val RMSE 0.355420\n",
      "Epoch 007 | train RMSE 0.301533 | val RMSE 0.353708\n",
      "Epoch 008 | train RMSE 0.295935 | val RMSE 0.352039\n",
      "Epoch 009 | train RMSE 0.290411 | val RMSE 0.350414\n",
      "Epoch 010 | train RMSE 0.284962 | val RMSE 0.348837\n",
      "  h=16 lr=0.001 act=tanh -> val RMSE=0.34884\n",
      "Epoch 001 | train RMSE 0.248288 | val RMSE 0.266962\n",
      "Epoch 002 | train RMSE 0.246738 | val RMSE 0.266331\n",
      "Epoch 003 | train RMSE 0.245218 | val RMSE 0.265755\n",
      "Epoch 004 | train RMSE 0.243723 | val RMSE 0.265215\n",
      "Epoch 005 | train RMSE 0.242251 | val RMSE 0.264699\n",
      "Epoch 006 | train RMSE 0.240805 | val RMSE 0.264188\n",
      "Epoch 007 | train RMSE 0.239395 | val RMSE 0.263691\n",
      "Epoch 008 | train RMSE 0.238018 | val RMSE 0.263203\n",
      "Epoch 009 | train RMSE 0.236679 | val RMSE 0.262730\n",
      "Epoch 010 | train RMSE 0.235369 | val RMSE 0.262271\n",
      "  h=16 lr=0.001 act=relu -> val RMSE=0.26227\n",
      "Epoch 001 | train RMSE 0.314805 | val RMSE 0.240780\n",
      "Epoch 002 | train RMSE 0.265538 | val RMSE 0.252109\n",
      "Epoch 003 | train RMSE 0.230852 | val RMSE 0.270139\n",
      "Epoch 004 | train RMSE 0.208213 | val RMSE 0.287834\n",
      "Epoch 005 | train RMSE 0.190844 | val RMSE 0.301840\n",
      "Epoch 006 | train RMSE 0.174130 | val RMSE 0.312298\n",
      "Epoch 007 | train RMSE 0.157712 | val RMSE 0.320566\n",
      "Epoch 008 | train RMSE 0.143122 | val RMSE 0.327930\n",
      "Epoch 009 | train RMSE 0.132492 | val RMSE 0.335119\n",
      "Epoch 010 | train RMSE 0.127203 | val RMSE 0.342116\n",
      "  h=16 lr=0.01 act=linear -> val RMSE=0.34212\n",
      "Epoch 001 | train RMSE 0.282726 | val RMSE 0.332958\n",
      "Epoch 002 | train RMSE 0.246751 | val RMSE 0.319701\n",
      "Epoch 003 | train RMSE 0.218396 | val RMSE 0.312490\n",
      "Epoch 004 | train RMSE 0.197723 | val RMSE 0.311963\n",
      "Epoch 005 | train RMSE 0.180739 | val RMSE 0.317427\n",
      "Epoch 006 | train RMSE 0.163468 | val RMSE 0.326812\n",
      "Epoch 007 | train RMSE 0.146782 | val RMSE 0.338109\n",
      "Epoch 008 | train RMSE 0.134116 | val RMSE 0.349114\n",
      "Epoch 009 | train RMSE 0.127097 | val RMSE 0.357625\n",
      "Epoch 010 | train RMSE 0.123613 | val RMSE 0.362666\n",
      "  h=16 lr=0.01 act=tanh -> val RMSE=0.36267\n",
      "Epoch 001 | train RMSE 0.236904 | val RMSE 0.268585\n",
      "Epoch 002 | train RMSE 0.221300 | val RMSE 0.270626\n",
      "Epoch 003 | train RMSE 0.207051 | val RMSE 0.274522\n",
      "Epoch 004 | train RMSE 0.193364 | val RMSE 0.279869\n",
      "Epoch 005 | train RMSE 0.180272 | val RMSE 0.286467\n",
      "Epoch 006 | train RMSE 0.167401 | val RMSE 0.294314\n",
      "Epoch 007 | train RMSE 0.154722 | val RMSE 0.303214\n",
      "Epoch 008 | train RMSE 0.142890 | val RMSE 0.313073\n",
      "Epoch 009 | train RMSE 0.132627 | val RMSE 0.323477\n",
      "Epoch 010 | train RMSE 0.125253 | val RMSE 0.333500\n",
      "  h=16 lr=0.01 act=relu -> val RMSE=0.33350\n",
      "Tuning market=FIAT+EQUITY\n",
      "Epoch 001 | train RMSE 0.271168 | val RMSE 0.330775\n",
      "Epoch 002 | train RMSE 0.266278 | val RMSE 0.329994\n",
      "Epoch 003 | train RMSE 0.261433 | val RMSE 0.329279\n",
      "Epoch 004 | train RMSE 0.256632 | val RMSE 0.328637\n",
      "Epoch 005 | train RMSE 0.251871 | val RMSE 0.328069\n",
      "Epoch 006 | train RMSE 0.247149 | val RMSE 0.327576\n",
      "Epoch 007 | train RMSE 0.242469 | val RMSE 0.327161\n",
      "Epoch 008 | train RMSE 0.237832 | val RMSE 0.326828\n",
      "Epoch 009 | train RMSE 0.233239 | val RMSE 0.326581\n",
      "Epoch 010 | train RMSE 0.228690 | val RMSE 0.326424\n",
      "  h=4 lr=0.001 act=linear -> val RMSE=0.32642\n",
      "Epoch 001 | train RMSE 0.244691 | val RMSE 0.253119\n",
      "Epoch 002 | train RMSE 0.242795 | val RMSE 0.253592\n",
      "Epoch 003 | train RMSE 0.240936 | val RMSE 0.254081\n",
      "Epoch 004 | train RMSE 0.239113 | val RMSE 0.254583\n",
      "Epoch 005 | train RMSE 0.237328 | val RMSE 0.255099\n",
      "Epoch 006 | train RMSE 0.235581 | val RMSE 0.255631\n",
      "Epoch 007 | train RMSE 0.233872 | val RMSE 0.256178\n",
      "Epoch 008 | train RMSE 0.232201 | val RMSE 0.256740\n",
      "Epoch 009 | train RMSE 0.230569 | val RMSE 0.257318\n",
      "Epoch 010 | train RMSE 0.228974 | val RMSE 0.257909\n",
      "  h=4 lr=0.001 act=tanh -> val RMSE=0.25791\n",
      "Epoch 001 | train RMSE 0.225245 | val RMSE 0.292342\n",
      "Epoch 002 | train RMSE 0.222825 | val RMSE 0.292675\n",
      "Epoch 003 | train RMSE 0.220446 | val RMSE 0.292993\n",
      "Epoch 004 | train RMSE 0.218085 | val RMSE 0.293375\n",
      "Epoch 005 | train RMSE 0.215723 | val RMSE 0.293806\n",
      "Epoch 006 | train RMSE 0.213384 | val RMSE 0.294278\n",
      "Epoch 007 | train RMSE 0.211007 | val RMSE 0.294794\n",
      "Epoch 008 | train RMSE 0.208593 | val RMSE 0.295358\n",
      "Epoch 009 | train RMSE 0.206174 | val RMSE 0.295967\n",
      "Epoch 010 | train RMSE 0.203768 | val RMSE 0.296615\n",
      "  h=4 lr=0.001 act=relu -> val RMSE=0.29661\n",
      "Epoch 001 | train RMSE 0.398550 | val RMSE 0.374015\n",
      "Epoch 002 | train RMSE 0.349842 | val RMSE 0.361794\n",
      "Epoch 003 | train RMSE 0.304783 | val RMSE 0.353490\n",
      "Epoch 004 | train RMSE 0.263634 | val RMSE 0.348860\n",
      "Epoch 005 | train RMSE 0.225995 | val RMSE 0.347661\n",
      "Epoch 006 | train RMSE 0.191569 | val RMSE 0.349757\n",
      "Epoch 007 | train RMSE 0.161078 | val RMSE 0.354961\n",
      "Epoch 008 | train RMSE 0.136494 | val RMSE 0.362260\n",
      "Epoch 009 | train RMSE 0.120760 | val RMSE 0.370187\n",
      "Epoch 010 | train RMSE 0.115086 | val RMSE 0.377643\n",
      "  h=4 lr=0.01 act=linear -> val RMSE=0.37764\n",
      "Epoch 001 | train RMSE 0.479211 | val RMSE 0.532887\n",
      "Epoch 002 | train RMSE 0.445102 | val RMSE 0.526768\n",
      "Epoch 003 | train RMSE 0.410902 | val RMSE 0.521760\n",
      "Epoch 004 | train RMSE 0.376632 | val RMSE 0.517800\n",
      "Epoch 005 | train RMSE 0.342591 | val RMSE 0.514649\n",
      "Epoch 006 | train RMSE 0.308941 | val RMSE 0.512025\n",
      "Epoch 007 | train RMSE 0.275959 | val RMSE 0.509824\n",
      "Epoch 008 | train RMSE 0.244378 | val RMSE 0.507986\n",
      "Epoch 009 | train RMSE 0.215367 | val RMSE 0.506382\n",
      "Epoch 010 | train RMSE 0.190336 | val RMSE 0.504819\n",
      "  h=4 lr=0.01 act=tanh -> val RMSE=0.50482\n",
      "Epoch 001 | train RMSE 0.228154 | val RMSE 0.348366\n",
      "Epoch 002 | train RMSE 0.199067 | val RMSE 0.350476\n",
      "Epoch 003 | train RMSE 0.176151 | val RMSE 0.356263\n",
      "Epoch 004 | train RMSE 0.159974 | val RMSE 0.364031\n",
      "Epoch 005 | train RMSE 0.151139 | val RMSE 0.372607\n",
      "Epoch 006 | train RMSE 0.146769 | val RMSE 0.380525\n",
      "Epoch 007 | train RMSE 0.145024 | val RMSE 0.386153\n",
      "Epoch 008 | train RMSE 0.144730 | val RMSE 0.389354\n",
      "Epoch 009 | train RMSE 0.144856 | val RMSE 0.389770\n",
      "Epoch 010 | train RMSE 0.144642 | val RMSE 0.387990\n",
      "  h=4 lr=0.01 act=relu -> val RMSE=0.38799\n",
      "Epoch 001 | train RMSE 0.376248 | val RMSE 0.420058\n",
      "Epoch 002 | train RMSE 0.371151 | val RMSE 0.418424\n",
      "Epoch 003 | train RMSE 0.366138 | val RMSE 0.416860\n",
      "Epoch 004 | train RMSE 0.361210 | val RMSE 0.415377\n",
      "Epoch 005 | train RMSE 0.356366 | val RMSE 0.413988\n",
      "Epoch 006 | train RMSE 0.351604 | val RMSE 0.412705\n",
      "Epoch 007 | train RMSE 0.346920 | val RMSE 0.411532\n",
      "Epoch 008 | train RMSE 0.342310 | val RMSE 0.410466\n",
      "Epoch 009 | train RMSE 0.337767 | val RMSE 0.409504\n",
      "Epoch 010 | train RMSE 0.333288 | val RMSE 0.408647\n",
      "  h=8 lr=0.001 act=linear -> val RMSE=0.40865\n",
      "Epoch 001 | train RMSE 0.222538 | val RMSE 0.384776\n",
      "Epoch 002 | train RMSE 0.218687 | val RMSE 0.386725\n",
      "Epoch 003 | train RMSE 0.214902 | val RMSE 0.388689\n",
      "Epoch 004 | train RMSE 0.211187 | val RMSE 0.390672\n",
      "Epoch 005 | train RMSE 0.207544 | val RMSE 0.392665\n",
      "Epoch 006 | train RMSE 0.203975 | val RMSE 0.394656\n",
      "Epoch 007 | train RMSE 0.200484 | val RMSE 0.396630\n",
      "Epoch 008 | train RMSE 0.197069 | val RMSE 0.398571\n",
      "Epoch 009 | train RMSE 0.193730 | val RMSE 0.400470\n",
      "Epoch 010 | train RMSE 0.190464 | val RMSE 0.402321\n",
      "  h=8 lr=0.001 act=tanh -> val RMSE=0.40232\n",
      "Epoch 001 | train RMSE 0.277645 | val RMSE 0.289323\n",
      "Epoch 002 | train RMSE 0.273091 | val RMSE 0.287526\n",
      "Epoch 003 | train RMSE 0.268580 | val RMSE 0.285776\n",
      "Epoch 004 | train RMSE 0.264108 | val RMSE 0.284063\n",
      "Epoch 005 | train RMSE 0.259677 | val RMSE 0.282389\n",
      "Epoch 006 | train RMSE 0.255290 | val RMSE 0.280780\n",
      "Epoch 007 | train RMSE 0.251062 | val RMSE 0.279224\n",
      "Epoch 008 | train RMSE 0.247040 | val RMSE 0.277709\n",
      "Epoch 009 | train RMSE 0.243055 | val RMSE 0.276248\n",
      "Epoch 010 | train RMSE 0.239120 | val RMSE 0.274863\n",
      "  h=8 lr=0.001 act=relu -> val RMSE=0.27486\n",
      "Epoch 001 | train RMSE 0.441480 | val RMSE 0.403219\n",
      "Epoch 002 | train RMSE 0.368544 | val RMSE 0.382625\n",
      "Epoch 003 | train RMSE 0.304644 | val RMSE 0.375008\n",
      "Epoch 004 | train RMSE 0.247170 | val RMSE 0.377874\n",
      "Epoch 005 | train RMSE 0.195956 | val RMSE 0.387885\n",
      "Epoch 006 | train RMSE 0.153059 | val RMSE 0.405130\n",
      "Epoch 007 | train RMSE 0.124232 | val RMSE 0.426672\n",
      "Epoch 008 | train RMSE 0.116966 | val RMSE 0.446641\n",
      "Epoch 009 | train RMSE 0.126058 | val RMSE 0.459669\n",
      "Epoch 010 | train RMSE 0.136513 | val RMSE 0.465039\n",
      "  h=8 lr=0.01 act=linear -> val RMSE=0.46504\n",
      "Epoch 001 | train RMSE 0.325684 | val RMSE 0.402279\n",
      "Epoch 002 | train RMSE 0.267760 | val RMSE 0.403933\n",
      "Epoch 003 | train RMSE 0.216111 | val RMSE 0.410631\n",
      "Epoch 004 | train RMSE 0.170005 | val RMSE 0.422086\n",
      "Epoch 005 | train RMSE 0.134250 | val RMSE 0.437702\n",
      "Epoch 006 | train RMSE 0.118230 | val RMSE 0.455267\n",
      "Epoch 007 | train RMSE 0.123430 | val RMSE 0.470202\n",
      "Epoch 008 | train RMSE 0.135565 | val RMSE 0.478775\n",
      "Epoch 009 | train RMSE 0.142328 | val RMSE 0.480264\n",
      "Epoch 010 | train RMSE 0.141074 | val RMSE 0.475347\n",
      "  h=8 lr=0.01 act=tanh -> val RMSE=0.47535\n",
      "Epoch 001 | train RMSE 0.418221 | val RMSE 0.391979\n",
      "Epoch 002 | train RMSE 0.355031 | val RMSE 0.370599\n",
      "Epoch 003 | train RMSE 0.300956 | val RMSE 0.353219\n",
      "Epoch 004 | train RMSE 0.258440 | val RMSE 0.339529\n",
      "Epoch 005 | train RMSE 0.222939 | val RMSE 0.330210\n",
      "Epoch 006 | train RMSE 0.192748 | val RMSE 0.325274\n",
      "Epoch 007 | train RMSE 0.169276 | val RMSE 0.324505\n",
      "Epoch 008 | train RMSE 0.154162 | val RMSE 0.326714\n",
      "Epoch 009 | train RMSE 0.143908 | val RMSE 0.330172\n",
      "Epoch 010 | train RMSE 0.135565 | val RMSE 0.333556\n",
      "  h=8 lr=0.01 act=relu -> val RMSE=0.33356\n",
      "Epoch 001 | train RMSE 0.265248 | val RMSE 0.262329\n",
      "Epoch 002 | train RMSE 0.258345 | val RMSE 0.263062\n",
      "Epoch 003 | train RMSE 0.251558 | val RMSE 0.263988\n",
      "Epoch 004 | train RMSE 0.244898 | val RMSE 0.265085\n",
      "Epoch 005 | train RMSE 0.238366 | val RMSE 0.266322\n",
      "Epoch 006 | train RMSE 0.231960 | val RMSE 0.267676\n",
      "Epoch 007 | train RMSE 0.225679 | val RMSE 0.269157\n",
      "Epoch 008 | train RMSE 0.219526 | val RMSE 0.270782\n",
      "Epoch 009 | train RMSE 0.213507 | val RMSE 0.272558\n",
      "Epoch 010 | train RMSE 0.207631 | val RMSE 0.274490\n",
      "  h=16 lr=0.001 act=linear -> val RMSE=0.27449\n",
      "Epoch 001 | train RMSE 0.407293 | val RMSE 0.371929\n",
      "Epoch 002 | train RMSE 0.396964 | val RMSE 0.368307\n",
      "Epoch 003 | train RMSE 0.386815 | val RMSE 0.364944\n",
      "Epoch 004 | train RMSE 0.376856 | val RMSE 0.361855\n",
      "Epoch 005 | train RMSE 0.367093 | val RMSE 0.359047\n",
      "Epoch 006 | train RMSE 0.357532 | val RMSE 0.356525\n",
      "Epoch 007 | train RMSE 0.348177 | val RMSE 0.354288\n",
      "Epoch 008 | train RMSE 0.339030 | val RMSE 0.352328\n",
      "Epoch 009 | train RMSE 0.330095 | val RMSE 0.350634\n",
      "Epoch 010 | train RMSE 0.321371 | val RMSE 0.349191\n",
      "  h=16 lr=0.001 act=tanh -> val RMSE=0.34919\n",
      "Epoch 001 | train RMSE 0.377962 | val RMSE 0.316067\n",
      "Epoch 002 | train RMSE 0.371008 | val RMSE 0.313317\n",
      "Epoch 003 | train RMSE 0.364130 | val RMSE 0.310682\n",
      "Epoch 004 | train RMSE 0.357317 | val RMSE 0.308183\n",
      "Epoch 005 | train RMSE 0.350575 | val RMSE 0.305826\n",
      "Epoch 006 | train RMSE 0.343875 | val RMSE 0.303618\n",
      "Epoch 007 | train RMSE 0.337211 | val RMSE 0.301548\n",
      "Epoch 008 | train RMSE 0.330614 | val RMSE 0.299609\n",
      "Epoch 009 | train RMSE 0.324083 | val RMSE 0.297797\n",
      "Epoch 010 | train RMSE 0.317649 | val RMSE 0.296113\n",
      "  h=16 lr=0.001 act=relu -> val RMSE=0.29611\n",
      "Epoch 001 | train RMSE 0.448983 | val RMSE 0.384909\n",
      "Epoch 002 | train RMSE 0.340507 | val RMSE 0.402917\n",
      "Epoch 003 | train RMSE 0.252034 | val RMSE 0.436922\n",
      "Epoch 004 | train RMSE 0.189131 | val RMSE 0.468676\n",
      "Epoch 005 | train RMSE 0.149112 | val RMSE 0.490123\n",
      "Epoch 006 | train RMSE 0.137022 | val RMSE 0.499004\n",
      "Epoch 007 | train RMSE 0.139859 | val RMSE 0.498827\n",
      "Epoch 008 | train RMSE 0.140088 | val RMSE 0.493008\n",
      "Epoch 009 | train RMSE 0.135367 | val RMSE 0.483485\n",
      "Epoch 010 | train RMSE 0.129096 | val RMSE 0.471637\n",
      "  h=16 lr=0.01 act=linear -> val RMSE=0.47164\n",
      "Epoch 001 | train RMSE 0.350573 | val RMSE 0.312852\n",
      "Epoch 002 | train RMSE 0.276678 | val RMSE 0.324372\n",
      "Epoch 003 | train RMSE 0.214629 | val RMSE 0.344561\n",
      "Epoch 004 | train RMSE 0.169233 | val RMSE 0.367789\n",
      "Epoch 005 | train RMSE 0.137304 | val RMSE 0.389011\n",
      "Epoch 006 | train RMSE 0.116176 | val RMSE 0.405009\n",
      "Epoch 007 | train RMSE 0.109178 | val RMSE 0.412344\n",
      "Epoch 008 | train RMSE 0.111608 | val RMSE 0.412592\n",
      "Epoch 009 | train RMSE 0.115290 | val RMSE 0.407828\n",
      "Epoch 010 | train RMSE 0.116838 | val RMSE 0.398960\n",
      "  h=16 lr=0.01 act=tanh -> val RMSE=0.39896\n",
      "Epoch 001 | train RMSE 0.287502 | val RMSE 0.283728\n",
      "Epoch 002 | train RMSE 0.239918 | val RMSE 0.278367\n",
      "Epoch 003 | train RMSE 0.197680 | val RMSE 0.279701\n",
      "Epoch 004 | train RMSE 0.160243 | val RMSE 0.287610\n",
      "Epoch 005 | train RMSE 0.133024 | val RMSE 0.300129\n",
      "Epoch 006 | train RMSE 0.118903 | val RMSE 0.312872\n",
      "Epoch 007 | train RMSE 0.114262 | val RMSE 0.322472\n",
      "Epoch 008 | train RMSE 0.110827 | val RMSE 0.328547\n",
      "Epoch 009 | train RMSE 0.107282 | val RMSE 0.331167\n",
      "Epoch 010 | train RMSE 0.104902 | val RMSE 0.330705\n",
      "  h=16 lr=0.01 act=relu -> val RMSE=0.33071\n",
      "Tuning market=FIAT+GOLD\n",
      "Epoch 001 | train RMSE 0.225834 | val RMSE 0.273774\n",
      "Epoch 002 | train RMSE 0.224282 | val RMSE 0.273981\n",
      "Epoch 003 | train RMSE 0.222767 | val RMSE 0.274216\n",
      "Epoch 004 | train RMSE 0.221291 | val RMSE 0.274482\n",
      "Epoch 005 | train RMSE 0.219856 | val RMSE 0.274776\n",
      "Epoch 006 | train RMSE 0.218461 | val RMSE 0.275100\n",
      "Epoch 007 | train RMSE 0.217108 | val RMSE 0.275452\n",
      "Epoch 008 | train RMSE 0.215798 | val RMSE 0.275834\n",
      "Epoch 009 | train RMSE 0.214528 | val RMSE 0.276243\n",
      "Epoch 010 | train RMSE 0.213299 | val RMSE 0.276679\n",
      "  h=4 lr=0.001 act=linear -> val RMSE=0.27668\n",
      "Epoch 001 | train RMSE 0.274761 | val RMSE 0.292009\n",
      "Epoch 002 | train RMSE 0.272953 | val RMSE 0.291604\n",
      "Epoch 003 | train RMSE 0.271174 | val RMSE 0.291216\n",
      "Epoch 004 | train RMSE 0.269426 | val RMSE 0.290847\n",
      "Epoch 005 | train RMSE 0.267709 | val RMSE 0.290499\n",
      "Epoch 006 | train RMSE 0.266023 | val RMSE 0.290171\n",
      "Epoch 007 | train RMSE 0.264367 | val RMSE 0.289865\n",
      "Epoch 008 | train RMSE 0.262742 | val RMSE 0.289578\n",
      "Epoch 009 | train RMSE 0.261146 | val RMSE 0.289310\n",
      "Epoch 010 | train RMSE 0.259576 | val RMSE 0.289059\n",
      "  h=4 lr=0.001 act=tanh -> val RMSE=0.28906\n",
      "Epoch 001 | train RMSE 0.253891 | val RMSE 0.248730\n",
      "Epoch 002 | train RMSE 0.253314 | val RMSE 0.248827\n",
      "Epoch 003 | train RMSE 0.252750 | val RMSE 0.248932\n",
      "Epoch 004 | train RMSE 0.252201 | val RMSE 0.249044\n",
      "Epoch 005 | train RMSE 0.251670 | val RMSE 0.249160\n",
      "Epoch 006 | train RMSE 0.251154 | val RMSE 0.249283\n",
      "Epoch 007 | train RMSE 0.250650 | val RMSE 0.249414\n",
      "Epoch 008 | train RMSE 0.250155 | val RMSE 0.249552\n",
      "Epoch 009 | train RMSE 0.249672 | val RMSE 0.249698\n",
      "Epoch 010 | train RMSE 0.249202 | val RMSE 0.249851\n",
      "  h=4 lr=0.001 act=relu -> val RMSE=0.24985\n",
      "Epoch 001 | train RMSE 0.265313 | val RMSE 0.280888\n",
      "Epoch 002 | train RMSE 0.244838 | val RMSE 0.276145\n",
      "Epoch 003 | train RMSE 0.226712 | val RMSE 0.272570\n",
      "Epoch 004 | train RMSE 0.211055 | val RMSE 0.270255\n",
      "Epoch 005 | train RMSE 0.198027 | val RMSE 0.269557\n",
      "Epoch 006 | train RMSE 0.187504 | val RMSE 0.270739\n",
      "Epoch 007 | train RMSE 0.178804 | val RMSE 0.273732\n",
      "Epoch 008 | train RMSE 0.170829 | val RMSE 0.278225\n",
      "Epoch 009 | train RMSE 0.162655 | val RMSE 0.283898\n",
      "Epoch 010 | train RMSE 0.154107 | val RMSE 0.290512\n",
      "  h=4 lr=0.01 act=linear -> val RMSE=0.29051\n",
      "Epoch 001 | train RMSE 0.271402 | val RMSE 0.276783\n",
      "Epoch 002 | train RMSE 0.255646 | val RMSE 0.272881\n",
      "Epoch 003 | train RMSE 0.241561 | val RMSE 0.270500\n",
      "Epoch 004 | train RMSE 0.229123 | val RMSE 0.269510\n",
      "Epoch 005 | train RMSE 0.218313 | val RMSE 0.269736\n",
      "Epoch 006 | train RMSE 0.209040 | val RMSE 0.271052\n",
      "Epoch 007 | train RMSE 0.201190 | val RMSE 0.273300\n",
      "Epoch 008 | train RMSE 0.194516 | val RMSE 0.276263\n",
      "Epoch 009 | train RMSE 0.188545 | val RMSE 0.279689\n",
      "Epoch 010 | train RMSE 0.182687 | val RMSE 0.283372\n",
      "  h=4 lr=0.01 act=tanh -> val RMSE=0.28337\n",
      "Epoch 001 | train RMSE 0.283217 | val RMSE 0.254190\n",
      "Epoch 002 | train RMSE 0.265070 | val RMSE 0.250536\n",
      "Epoch 003 | train RMSE 0.248834 | val RMSE 0.248564\n",
      "Epoch 004 | train RMSE 0.234291 | val RMSE 0.248375\n",
      "Epoch 005 | train RMSE 0.222478 | val RMSE 0.249897\n",
      "Epoch 006 | train RMSE 0.213481 | val RMSE 0.252869\n",
      "Epoch 007 | train RMSE 0.206607 | val RMSE 0.256903\n",
      "Epoch 008 | train RMSE 0.200917 | val RMSE 0.261392\n",
      "Epoch 009 | train RMSE 0.195893 | val RMSE 0.265979\n",
      "Epoch 010 | train RMSE 0.190744 | val RMSE 0.270322\n",
      "  h=4 lr=0.01 act=relu -> val RMSE=0.27032\n",
      "Epoch 001 | train RMSE 0.249944 | val RMSE 0.270985\n",
      "Epoch 002 | train RMSE 0.247864 | val RMSE 0.270509\n",
      "Epoch 003 | train RMSE 0.245822 | val RMSE 0.270067\n",
      "Epoch 004 | train RMSE 0.243821 | val RMSE 0.269660\n",
      "Epoch 005 | train RMSE 0.241861 | val RMSE 0.269290\n",
      "Epoch 006 | train RMSE 0.239946 | val RMSE 0.268959\n",
      "Epoch 007 | train RMSE 0.238075 | val RMSE 0.268669\n",
      "Epoch 008 | train RMSE 0.236251 | val RMSE 0.268422\n",
      "Epoch 009 | train RMSE 0.234473 | val RMSE 0.268220\n",
      "Epoch 010 | train RMSE 0.232741 | val RMSE 0.268063\n",
      "  h=8 lr=0.001 act=linear -> val RMSE=0.26806\n",
      "Epoch 001 | train RMSE 0.260974 | val RMSE 0.315122\n",
      "Epoch 002 | train RMSE 0.258564 | val RMSE 0.313688\n",
      "Epoch 003 | train RMSE 0.256206 | val RMSE 0.312270\n",
      "Epoch 004 | train RMSE 0.253899 | val RMSE 0.310873\n",
      "Epoch 005 | train RMSE 0.251644 | val RMSE 0.309501\n",
      "Epoch 006 | train RMSE 0.249440 | val RMSE 0.308157\n",
      "Epoch 007 | train RMSE 0.247287 | val RMSE 0.306847\n",
      "Epoch 008 | train RMSE 0.245181 | val RMSE 0.305578\n",
      "Epoch 009 | train RMSE 0.243120 | val RMSE 0.304355\n",
      "Epoch 010 | train RMSE 0.241100 | val RMSE 0.303183\n",
      "  h=8 lr=0.001 act=tanh -> val RMSE=0.30318\n",
      "Epoch 001 | train RMSE 0.237608 | val RMSE 0.267879\n",
      "Epoch 002 | train RMSE 0.236109 | val RMSE 0.267489\n",
      "Epoch 003 | train RMSE 0.234615 | val RMSE 0.267134\n",
      "Epoch 004 | train RMSE 0.233122 | val RMSE 0.266794\n",
      "Epoch 005 | train RMSE 0.231624 | val RMSE 0.266469\n",
      "Epoch 006 | train RMSE 0.230133 | val RMSE 0.266157\n",
      "Epoch 007 | train RMSE 0.228644 | val RMSE 0.265859\n",
      "Epoch 008 | train RMSE 0.227157 | val RMSE 0.265576\n",
      "Epoch 009 | train RMSE 0.225676 | val RMSE 0.265312\n",
      "Epoch 010 | train RMSE 0.224204 | val RMSE 0.265068\n",
      "  h=8 lr=0.001 act=relu -> val RMSE=0.26507\n",
      "Epoch 001 | train RMSE 0.469949 | val RMSE 0.430333\n",
      "Epoch 002 | train RMSE 0.425645 | val RMSE 0.413859\n",
      "Epoch 003 | train RMSE 0.384059 | val RMSE 0.398353\n",
      "Epoch 004 | train RMSE 0.345285 | val RMSE 0.383732\n",
      "Epoch 005 | train RMSE 0.309929 | val RMSE 0.370204\n",
      "Epoch 006 | train RMSE 0.279164 | val RMSE 0.357944\n",
      "Epoch 007 | train RMSE 0.254254 | val RMSE 0.347114\n",
      "Epoch 008 | train RMSE 0.235964 | val RMSE 0.337984\n",
      "Epoch 009 | train RMSE 0.224204 | val RMSE 0.330949\n",
      "Epoch 010 | train RMSE 0.217603 | val RMSE 0.326280\n",
      "  h=8 lr=0.01 act=linear -> val RMSE=0.32628\n",
      "Epoch 001 | train RMSE 0.464961 | val RMSE 0.466042\n",
      "Epoch 002 | train RMSE 0.418603 | val RMSE 0.447944\n",
      "Epoch 003 | train RMSE 0.375336 | val RMSE 0.430410\n",
      "Epoch 004 | train RMSE 0.335149 | val RMSE 0.414252\n",
      "Epoch 005 | train RMSE 0.298297 | val RMSE 0.399912\n",
      "Epoch 006 | train RMSE 0.265292 | val RMSE 0.387516\n",
      "Epoch 007 | train RMSE 0.237214 | val RMSE 0.377049\n",
      "Epoch 008 | train RMSE 0.215696 | val RMSE 0.368463\n",
      "Epoch 009 | train RMSE 0.202156 | val RMSE 0.361672\n",
      "Epoch 010 | train RMSE 0.196592 | val RMSE 0.356538\n",
      "  h=8 lr=0.01 act=tanh -> val RMSE=0.35654\n",
      "Epoch 001 | train RMSE 0.442555 | val RMSE 0.454246\n",
      "Epoch 002 | train RMSE 0.418587 | val RMSE 0.440769\n",
      "Epoch 003 | train RMSE 0.393579 | val RMSE 0.427078\n",
      "Epoch 004 | train RMSE 0.368937 | val RMSE 0.413553\n",
      "Epoch 005 | train RMSE 0.344196 | val RMSE 0.400484\n",
      "Epoch 006 | train RMSE 0.319046 | val RMSE 0.387825\n",
      "Epoch 007 | train RMSE 0.294587 | val RMSE 0.375498\n",
      "Epoch 008 | train RMSE 0.270415 | val RMSE 0.363729\n",
      "Epoch 009 | train RMSE 0.247651 | val RMSE 0.352515\n",
      "Epoch 010 | train RMSE 0.227832 | val RMSE 0.342220\n",
      "  h=8 lr=0.01 act=relu -> val RMSE=0.34222\n",
      "Epoch 001 | train RMSE 0.442496 | val RMSE 0.470651\n",
      "Epoch 002 | train RMSE 0.435724 | val RMSE 0.467751\n",
      "Epoch 003 | train RMSE 0.428990 | val RMSE 0.464866\n",
      "Epoch 004 | train RMSE 0.422294 | val RMSE 0.461999\n",
      "Epoch 005 | train RMSE 0.415637 | val RMSE 0.459149\n",
      "Epoch 006 | train RMSE 0.409022 | val RMSE 0.456319\n",
      "Epoch 007 | train RMSE 0.402450 | val RMSE 0.453508\n",
      "Epoch 008 | train RMSE 0.395924 | val RMSE 0.450718\n",
      "Epoch 009 | train RMSE 0.389447 | val RMSE 0.447948\n",
      "Epoch 010 | train RMSE 0.383021 | val RMSE 0.445201\n",
      "  h=16 lr=0.001 act=linear -> val RMSE=0.44520\n",
      "Epoch 001 | train RMSE 0.329128 | val RMSE 0.297256\n",
      "Epoch 002 | train RMSE 0.324400 | val RMSE 0.295534\n",
      "Epoch 003 | train RMSE 0.319723 | val RMSE 0.293858\n",
      "Epoch 004 | train RMSE 0.315095 | val RMSE 0.292230\n",
      "Epoch 005 | train RMSE 0.310515 | val RMSE 0.290651\n",
      "Epoch 006 | train RMSE 0.305983 | val RMSE 0.289122\n",
      "Epoch 007 | train RMSE 0.301499 | val RMSE 0.287645\n",
      "Epoch 008 | train RMSE 0.297067 | val RMSE 0.286220\n",
      "Epoch 009 | train RMSE 0.292686 | val RMSE 0.284847\n",
      "Epoch 010 | train RMSE 0.288358 | val RMSE 0.283530\n",
      "  h=16 lr=0.001 act=tanh -> val RMSE=0.28353\n",
      "Epoch 001 | train RMSE 0.241757 | val RMSE 0.251831\n",
      "Epoch 002 | train RMSE 0.240371 | val RMSE 0.251956\n",
      "Epoch 003 | train RMSE 0.239009 | val RMSE 0.252090\n",
      "Epoch 004 | train RMSE 0.237684 | val RMSE 0.252252\n",
      "Epoch 005 | train RMSE 0.236403 | val RMSE 0.252435\n",
      "Epoch 006 | train RMSE 0.235169 | val RMSE 0.252633\n",
      "Epoch 007 | train RMSE 0.233953 | val RMSE 0.252843\n",
      "Epoch 008 | train RMSE 0.232771 | val RMSE 0.253073\n",
      "Epoch 009 | train RMSE 0.231611 | val RMSE 0.253321\n",
      "Epoch 010 | train RMSE 0.230465 | val RMSE 0.253593\n",
      "  h=16 lr=0.001 act=relu -> val RMSE=0.25359\n",
      "Epoch 001 | train RMSE 0.290318 | val RMSE 0.273935\n",
      "Epoch 002 | train RMSE 0.246741 | val RMSE 0.271136\n",
      "Epoch 003 | train RMSE 0.215363 | val RMSE 0.274233\n",
      "Epoch 004 | train RMSE 0.195376 | val RMSE 0.282795\n",
      "Epoch 005 | train RMSE 0.183690 | val RMSE 0.293199\n",
      "Epoch 006 | train RMSE 0.175185 | val RMSE 0.302243\n",
      "Epoch 007 | train RMSE 0.166101 | val RMSE 0.309006\n",
      "Epoch 008 | train RMSE 0.156341 | val RMSE 0.313658\n",
      "Epoch 009 | train RMSE 0.147424 | val RMSE 0.316735\n",
      "Epoch 010 | train RMSE 0.140738 | val RMSE 0.318834\n",
      "  h=16 lr=0.01 act=linear -> val RMSE=0.31883\n",
      "Epoch 001 | train RMSE 0.319450 | val RMSE 0.329957\n",
      "Epoch 002 | train RMSE 0.281211 | val RMSE 0.313240\n",
      "Epoch 003 | train RMSE 0.250228 | val RMSE 0.301212\n",
      "Epoch 004 | train RMSE 0.225971 | val RMSE 0.293845\n",
      "Epoch 005 | train RMSE 0.208109 | val RMSE 0.290740\n",
      "Epoch 006 | train RMSE 0.196040 | val RMSE 0.291479\n",
      "Epoch 007 | train RMSE 0.187650 | val RMSE 0.295290\n",
      "Epoch 008 | train RMSE 0.180017 | val RMSE 0.301060\n",
      "Epoch 009 | train RMSE 0.171575 | val RMSE 0.307752\n",
      "Epoch 010 | train RMSE 0.162514 | val RMSE 0.314638\n",
      "  h=16 lr=0.01 act=tanh -> val RMSE=0.31464\n",
      "Epoch 001 | train RMSE 0.323283 | val RMSE 0.307351\n",
      "Epoch 002 | train RMSE 0.289446 | val RMSE 0.292577\n",
      "Epoch 003 | train RMSE 0.258568 | val RMSE 0.280716\n",
      "Epoch 004 | train RMSE 0.230871 | val RMSE 0.272206\n",
      "Epoch 005 | train RMSE 0.208448 | val RMSE 0.267743\n",
      "Epoch 006 | train RMSE 0.192964 | val RMSE 0.267298\n",
      "Epoch 007 | train RMSE 0.183867 | val RMSE 0.269668\n",
      "Epoch 008 | train RMSE 0.177496 | val RMSE 0.273456\n",
      "Epoch 009 | train RMSE 0.170278 | val RMSE 0.277774\n",
      "Epoch 010 | train RMSE 0.161454 | val RMSE 0.282344\n",
      "  h=16 lr=0.01 act=relu -> val RMSE=0.28234\n",
      "Tuning market=FIAT+EQUITY+GOLD+ENERGY\n",
      "Epoch 001 | train RMSE 0.568540 | val RMSE 0.592257\n",
      "Epoch 002 | train RMSE 0.563969 | val RMSE 0.590832\n",
      "Epoch 003 | train RMSE 0.559406 | val RMSE 0.589425\n",
      "Epoch 004 | train RMSE 0.554851 | val RMSE 0.588037\n",
      "Epoch 005 | train RMSE 0.550306 | val RMSE 0.586669\n",
      "Epoch 006 | train RMSE 0.545769 | val RMSE 0.585320\n",
      "Epoch 007 | train RMSE 0.541241 | val RMSE 0.583990\n",
      "Epoch 008 | train RMSE 0.536723 | val RMSE 0.582680\n",
      "Epoch 009 | train RMSE 0.532215 | val RMSE 0.581389\n",
      "Epoch 010 | train RMSE 0.527716 | val RMSE 0.580118\n",
      "  h=4 lr=0.001 act=linear -> val RMSE=0.58012\n",
      "Epoch 001 | train RMSE 0.328025 | val RMSE 0.270045\n",
      "Epoch 002 | train RMSE 0.324072 | val RMSE 0.269179\n",
      "Epoch 003 | train RMSE 0.320140 | val RMSE 0.268368\n",
      "Epoch 004 | train RMSE 0.316232 | val RMSE 0.267614\n",
      "Epoch 005 | train RMSE 0.312348 | val RMSE 0.266919\n",
      "Epoch 006 | train RMSE 0.308490 | val RMSE 0.266281\n",
      "Epoch 007 | train RMSE 0.304660 | val RMSE 0.265702\n",
      "Epoch 008 | train RMSE 0.300859 | val RMSE 0.265182\n",
      "Epoch 009 | train RMSE 0.297089 | val RMSE 0.264722\n",
      "Epoch 010 | train RMSE 0.293351 | val RMSE 0.264322\n",
      "  h=4 lr=0.001 act=tanh -> val RMSE=0.26432\n",
      "Epoch 001 | train RMSE 0.248054 | val RMSE 0.282453\n",
      "Epoch 002 | train RMSE 0.245428 | val RMSE 0.282234\n",
      "Epoch 003 | train RMSE 0.242939 | val RMSE 0.282121\n",
      "Epoch 004 | train RMSE 0.240543 | val RMSE 0.282086\n",
      "Epoch 005 | train RMSE 0.238145 | val RMSE 0.282136\n",
      "Epoch 006 | train RMSE 0.235837 | val RMSE 0.282266\n",
      "Epoch 007 | train RMSE 0.233661 | val RMSE 0.282526\n",
      "Epoch 008 | train RMSE 0.231584 | val RMSE 0.282873\n",
      "Epoch 009 | train RMSE 0.229483 | val RMSE 0.283260\n",
      "Epoch 010 | train RMSE 0.227415 | val RMSE 0.283668\n",
      "  h=4 lr=0.001 act=relu -> val RMSE=0.28367\n",
      "Epoch 001 | train RMSE 0.440756 | val RMSE 0.463922\n",
      "Epoch 002 | train RMSE 0.403913 | val RMSE 0.453897\n",
      "Epoch 003 | train RMSE 0.369236 | val RMSE 0.444918\n",
      "Epoch 004 | train RMSE 0.335932 | val RMSE 0.437173\n",
      "Epoch 005 | train RMSE 0.303494 | val RMSE 0.431057\n",
      "Epoch 006 | train RMSE 0.271749 | val RMSE 0.426978\n",
      "Epoch 007 | train RMSE 0.240613 | val RMSE 0.425265\n",
      "Epoch 008 | train RMSE 0.210148 | val RMSE 0.426107\n",
      "Epoch 009 | train RMSE 0.180822 | val RMSE 0.429601\n",
      "Epoch 010 | train RMSE 0.153903 | val RMSE 0.435795\n",
      "  h=4 lr=0.01 act=linear -> val RMSE=0.43580\n",
      "Epoch 001 | train RMSE 0.208696 | val RMSE 0.298441\n",
      "Epoch 002 | train RMSE 0.170736 | val RMSE 0.309705\n",
      "Epoch 003 | train RMSE 0.143408 | val RMSE 0.326024\n",
      "Epoch 004 | train RMSE 0.122812 | val RMSE 0.343538\n",
      "Epoch 005 | train RMSE 0.107045 | val RMSE 0.359638\n",
      "Epoch 006 | train RMSE 0.098379 | val RMSE 0.372130\n",
      "Epoch 007 | train RMSE 0.097588 | val RMSE 0.379767\n",
      "Epoch 008 | train RMSE 0.100824 | val RMSE 0.382681\n",
      "Epoch 009 | train RMSE 0.103366 | val RMSE 0.382178\n",
      "Epoch 010 | train RMSE 0.103607 | val RMSE 0.379496\n",
      "  h=4 lr=0.01 act=tanh -> val RMSE=0.37950\n",
      "Epoch 001 | train RMSE 0.260315 | val RMSE 0.252347\n",
      "Epoch 002 | train RMSE 0.236259 | val RMSE 0.252487\n",
      "Epoch 003 | train RMSE 0.217682 | val RMSE 0.256153\n",
      "Epoch 004 | train RMSE 0.203785 | val RMSE 0.261349\n",
      "Epoch 005 | train RMSE 0.192430 | val RMSE 0.266074\n",
      "Epoch 006 | train RMSE 0.184335 | val RMSE 0.270383\n",
      "Epoch 007 | train RMSE 0.180833 | val RMSE 0.274532\n",
      "Epoch 008 | train RMSE 0.179510 | val RMSE 0.278201\n",
      "Epoch 009 | train RMSE 0.179662 | val RMSE 0.280878\n",
      "Epoch 010 | train RMSE 0.180510 | val RMSE 0.282522\n",
      "  h=4 lr=0.01 act=relu -> val RMSE=0.28252\n",
      "Epoch 001 | train RMSE 0.449783 | val RMSE 0.429874\n",
      "Epoch 002 | train RMSE 0.443004 | val RMSE 0.428790\n",
      "Epoch 003 | train RMSE 0.436293 | val RMSE 0.427774\n",
      "Epoch 004 | train RMSE 0.429652 | val RMSE 0.426823\n",
      "Epoch 005 | train RMSE 0.423081 | val RMSE 0.425932\n",
      "Epoch 006 | train RMSE 0.416583 | val RMSE 0.425098\n",
      "Epoch 007 | train RMSE 0.410156 | val RMSE 0.424314\n",
      "Epoch 008 | train RMSE 0.403798 | val RMSE 0.423574\n",
      "Epoch 009 | train RMSE 0.397507 | val RMSE 0.422874\n",
      "Epoch 010 | train RMSE 0.391280 | val RMSE 0.422209\n",
      "  h=8 lr=0.001 act=linear -> val RMSE=0.42221\n",
      "Epoch 001 | train RMSE 0.306628 | val RMSE 0.319761\n",
      "Epoch 002 | train RMSE 0.301670 | val RMSE 0.319159\n",
      "Epoch 003 | train RMSE 0.296772 | val RMSE 0.318612\n",
      "Epoch 004 | train RMSE 0.291936 | val RMSE 0.318121\n",
      "Epoch 005 | train RMSE 0.287164 | val RMSE 0.317690\n",
      "Epoch 006 | train RMSE 0.282456 | val RMSE 0.317321\n",
      "Epoch 007 | train RMSE 0.277812 | val RMSE 0.317019\n",
      "Epoch 008 | train RMSE 0.273229 | val RMSE 0.316785\n",
      "Epoch 009 | train RMSE 0.268705 | val RMSE 0.316620\n",
      "Epoch 010 | train RMSE 0.264238 | val RMSE 0.316527\n",
      "  h=8 lr=0.001 act=tanh -> val RMSE=0.31653\n",
      "Epoch 001 | train RMSE 0.414134 | val RMSE 0.481307\n",
      "Epoch 002 | train RMSE 0.408673 | val RMSE 0.478546\n",
      "Epoch 003 | train RMSE 0.403327 | val RMSE 0.475803\n",
      "Epoch 004 | train RMSE 0.398068 | val RMSE 0.473125\n",
      "Epoch 005 | train RMSE 0.392910 | val RMSE 0.470484\n",
      "Epoch 006 | train RMSE 0.387838 | val RMSE 0.467829\n",
      "Epoch 007 | train RMSE 0.382966 | val RMSE 0.465127\n",
      "Epoch 008 | train RMSE 0.378189 | val RMSE 0.462399\n",
      "Epoch 009 | train RMSE 0.373446 | val RMSE 0.459641\n",
      "Epoch 010 | train RMSE 0.368789 | val RMSE 0.456863\n",
      "  h=8 lr=0.001 act=relu -> val RMSE=0.45686\n",
      "Epoch 001 | train RMSE 0.333547 | val RMSE 0.269011\n",
      "Epoch 002 | train RMSE 0.286814 | val RMSE 0.269258\n",
      "Epoch 003 | train RMSE 0.242987 | val RMSE 0.277172\n",
      "Epoch 004 | train RMSE 0.203735 | val RMSE 0.292751\n",
      "Epoch 005 | train RMSE 0.171478 | val RMSE 0.313810\n",
      "Epoch 006 | train RMSE 0.149380 | val RMSE 0.336288\n",
      "Epoch 007 | train RMSE 0.138578 | val RMSE 0.354986\n",
      "Epoch 008 | train RMSE 0.133746 | val RMSE 0.366559\n",
      "Epoch 009 | train RMSE 0.127526 | val RMSE 0.370918\n",
      "Epoch 010 | train RMSE 0.118285 | val RMSE 0.369708\n",
      "  h=8 lr=0.01 act=linear -> val RMSE=0.36971\n",
      "Epoch 001 | train RMSE 0.258729 | val RMSE 0.281611\n",
      "Epoch 002 | train RMSE 0.216509 | val RMSE 0.290956\n",
      "Epoch 003 | train RMSE 0.183092 | val RMSE 0.304093\n",
      "Epoch 004 | train RMSE 0.157997 | val RMSE 0.317855\n",
      "Epoch 005 | train RMSE 0.139429 | val RMSE 0.330037\n",
      "Epoch 006 | train RMSE 0.126458 | val RMSE 0.340053\n",
      "Epoch 007 | train RMSE 0.117082 | val RMSE 0.347504\n",
      "Epoch 008 | train RMSE 0.110025 | val RMSE 0.352650\n",
      "Epoch 009 | train RMSE 0.105625 | val RMSE 0.356279\n",
      "Epoch 010 | train RMSE 0.103481 | val RMSE 0.358688\n",
      "  h=8 lr=0.01 act=tanh -> val RMSE=0.35869\n",
      "Epoch 001 | train RMSE 0.286483 | val RMSE 0.308782\n",
      "Epoch 002 | train RMSE 0.239360 | val RMSE 0.304540\n",
      "Epoch 003 | train RMSE 0.196389 | val RMSE 0.305670\n",
      "Epoch 004 | train RMSE 0.160405 | val RMSE 0.311827\n",
      "Epoch 005 | train RMSE 0.135476 | val RMSE 0.321427\n",
      "Epoch 006 | train RMSE 0.125225 | val RMSE 0.332139\n",
      "Epoch 007 | train RMSE 0.126467 | val RMSE 0.340437\n",
      "Epoch 008 | train RMSE 0.128846 | val RMSE 0.345344\n",
      "Epoch 009 | train RMSE 0.126279 | val RMSE 0.346986\n",
      "Epoch 010 | train RMSE 0.118477 | val RMSE 0.346057\n",
      "  h=8 lr=0.01 act=relu -> val RMSE=0.34606\n",
      "Epoch 001 | train RMSE 0.331083 | val RMSE 0.289754\n",
      "Epoch 002 | train RMSE 0.319737 | val RMSE 0.287735\n",
      "Epoch 003 | train RMSE 0.308583 | val RMSE 0.286002\n",
      "Epoch 004 | train RMSE 0.297636 | val RMSE 0.284544\n",
      "Epoch 005 | train RMSE 0.286904 | val RMSE 0.283348\n",
      "Epoch 006 | train RMSE 0.276394 | val RMSE 0.282407\n",
      "Epoch 007 | train RMSE 0.266105 | val RMSE 0.281721\n",
      "Epoch 008 | train RMSE 0.256037 | val RMSE 0.281302\n",
      "Epoch 009 | train RMSE 0.246195 | val RMSE 0.281160\n",
      "Epoch 010 | train RMSE 0.236592 | val RMSE 0.281308\n",
      "  h=16 lr=0.001 act=linear -> val RMSE=0.28131\n",
      "Epoch 001 | train RMSE 0.254663 | val RMSE 0.275666\n",
      "Epoch 002 | train RMSE 0.249569 | val RMSE 0.276262\n",
      "Epoch 003 | train RMSE 0.244602 | val RMSE 0.277025\n",
      "Epoch 004 | train RMSE 0.239761 | val RMSE 0.277940\n",
      "Epoch 005 | train RMSE 0.235042 | val RMSE 0.278998\n",
      "Epoch 006 | train RMSE 0.230445 | val RMSE 0.280200\n",
      "Epoch 007 | train RMSE 0.225967 | val RMSE 0.281550\n",
      "Epoch 008 | train RMSE 0.221602 | val RMSE 0.283052\n",
      "Epoch 009 | train RMSE 0.217343 | val RMSE 0.284705\n",
      "Epoch 010 | train RMSE 0.213181 | val RMSE 0.286508\n",
      "  h=16 lr=0.001 act=tanh -> val RMSE=0.28651\n",
      "Epoch 001 | train RMSE 0.306642 | val RMSE 0.265104\n",
      "Epoch 002 | train RMSE 0.300032 | val RMSE 0.264148\n",
      "Epoch 003 | train RMSE 0.293427 | val RMSE 0.263292\n",
      "Epoch 004 | train RMSE 0.286862 | val RMSE 0.262533\n",
      "Epoch 005 | train RMSE 0.280407 | val RMSE 0.261861\n",
      "Epoch 006 | train RMSE 0.274039 | val RMSE 0.261256\n",
      "Epoch 007 | train RMSE 0.267754 | val RMSE 0.260738\n",
      "Epoch 008 | train RMSE 0.261572 | val RMSE 0.260291\n",
      "Epoch 009 | train RMSE 0.255528 | val RMSE 0.259913\n",
      "Epoch 010 | train RMSE 0.249590 | val RMSE 0.259582\n",
      "  h=16 lr=0.001 act=relu -> val RMSE=0.25958\n",
      "Epoch 001 | train RMSE 0.396557 | val RMSE 0.340686\n",
      "Epoch 002 | train RMSE 0.308492 | val RMSE 0.354343\n",
      "Epoch 003 | train RMSE 0.231742 | val RMSE 0.381275\n",
      "Epoch 004 | train RMSE 0.170988 | val RMSE 0.412928\n",
      "Epoch 005 | train RMSE 0.137509 | val RMSE 0.441746\n",
      "Epoch 006 | train RMSE 0.132830 | val RMSE 0.460883\n",
      "Epoch 007 | train RMSE 0.134118 | val RMSE 0.468537\n",
      "Epoch 008 | train RMSE 0.128685 | val RMSE 0.466748\n",
      "Epoch 009 | train RMSE 0.118233 | val RMSE 0.458530\n",
      "Epoch 010 | train RMSE 0.108766 | val RMSE 0.446636\n",
      "  h=16 lr=0.01 act=linear -> val RMSE=0.44664\n",
      "Epoch 001 | train RMSE 0.302238 | val RMSE 0.320802\n",
      "Epoch 002 | train RMSE 0.218111 | val RMSE 0.333463\n",
      "Epoch 003 | train RMSE 0.157527 | val RMSE 0.349753\n",
      "Epoch 004 | train RMSE 0.125671 | val RMSE 0.366039\n",
      "Epoch 005 | train RMSE 0.118447 | val RMSE 0.380198\n",
      "Epoch 006 | train RMSE 0.118628 | val RMSE 0.389330\n",
      "Epoch 007 | train RMSE 0.119251 | val RMSE 0.391122\n",
      "Epoch 008 | train RMSE 0.116562 | val RMSE 0.386375\n",
      "Epoch 009 | train RMSE 0.111055 | val RMSE 0.377618\n",
      "Epoch 010 | train RMSE 0.105673 | val RMSE 0.367426\n",
      "  h=16 lr=0.01 act=tanh -> val RMSE=0.36743\n",
      "Epoch 001 | train RMSE 0.233420 | val RMSE 0.259546\n",
      "Epoch 002 | train RMSE 0.198605 | val RMSE 0.267225\n",
      "Epoch 003 | train RMSE 0.168695 | val RMSE 0.278678\n",
      "Epoch 004 | train RMSE 0.143271 | val RMSE 0.292947\n",
      "Epoch 005 | train RMSE 0.124542 | val RMSE 0.305695\n",
      "Epoch 006 | train RMSE 0.115018 | val RMSE 0.313832\n",
      "Epoch 007 | train RMSE 0.109817 | val RMSE 0.316979\n",
      "Epoch 008 | train RMSE 0.104971 | val RMSE 0.317170\n",
      "Epoch 009 | train RMSE 0.099154 | val RMSE 0.316031\n",
      "Epoch 010 | train RMSE 0.094030 | val RMSE 0.315422\n",
      "  h=16 lr=0.01 act=relu -> val RMSE=0.31542\n",
      "Saved grid results and best per market CSVs\n"
     ]
    }
   ],
   "source": [
    "grid_out_all = []\n",
    "best_by_market = []\n",
    "\n",
    "\n",
    "hidden_list = [4, 8, 16]\n",
    "lr_list = [0.001, 0.01]\n",
    "act_list = [\"linear\", \"tanh\", \"relu\"]\n",
    "w_list = [12]\n",
    "\n",
    "for market_assets in MARKET_CHOICES:\n",
    "    p(f\"Tuning market={'+'.join(market_assets)}\")\n",
    "    pnl = build_panel_for_market(data, market_assets, BASELINE_WINDOW)\n",
    "    if len(pnl[\"Xtr\"]) == 0 or len(pnl[\"Xval\"]) == 0:\n",
    "        p(\"Skipping due to empty train or val\")\n",
    "        continue\n",
    "    results = []\n",
    "    for h in hidden_list:\n",
    "        for lr in lr_list:\n",
    "            for act in act_list:\n",
    "                try:\n",
    "                    model_tmp, tr_h, va_h = train_nn(\n",
    "                        pnl[\"Xtr\"],\n",
    "                        pnl[\"ytr\"],\n",
    "                        pnl[\"Xval\"],\n",
    "                        pnl[\"yval\"],\n",
    "                        hidden=h,\n",
    "                        lr=lr,\n",
    "                        act=act,\n",
    "                        epochs=10,\n",
    "                    )\n",
    "                    val_rmse = va_h[-1]\n",
    "                    results.append(\n",
    "                        [\n",
    "                            \"+\".join(market_assets),\n",
    "                            BASELINE_WINDOW,\n",
    "                            h,\n",
    "                            lr,\n",
    "                            act,\n",
    "                            float(val_rmse),\n",
    "                        ]\n",
    "                    )\n",
    "                    p(f\"  h={h} lr={lr} act={act} -> val RMSE={val_rmse:.5f}\")\n",
    "                except Exception as e:\n",
    "                    p(f\"  error h={h} lr={lr} act={act}: {e}\")\n",
    "    if results:\n",
    "        df_res = pd.DataFrame(\n",
    "            results,\n",
    "            columns=[\n",
    "                \"MarketAssets\",\n",
    "                \"Window\",\n",
    "                \"Hidden\",\n",
    "                \"LR\",\n",
    "                \"Activation\",\n",
    "                \"Val_RMSE\",\n",
    "            ],\n",
    "        )\n",
    "        grid_out_all.append(df_res)\n",
    "\n",
    "        best_row = df_res.sort_values(\"Val_RMSE\", ascending=True).iloc[0].to_dict()\n",
    "        best_by_market.append(best_row)\n",
    "\n",
    "if grid_out_all:\n",
    "    df_all = pd.concat(grid_out_all, ignore_index=True)\n",
    "    df_all.to_csv(\"outputs/step2_grid_results.csv\", index=False)\n",
    "    pd.DataFrame(best_by_market).to_csv(\"outputs/step2_best_by_market.csv\", index=False)\n",
    "    p(\"Saved grid results and best per market CSVs\")\n",
    "else:\n",
    "    p(\"No grid results created. Check data lengths or grid size.\")\n",
    "\n",
    "\n",
    "best_map = {}\n",
    "if os.path.exists(\"outputs/step2_best_by_market.csv\"):\n",
    "    best_df = pd.read_csv(\"outputs/step2_best_by_market.csv\")\n",
    "    for _, r in best_df.iterrows():\n",
    "        best_map[r[\"MarketAssets\"]] = dict(\n",
    "            w=int(r[\"Window\"]),\n",
    "            hidden=int(r[\"Hidden\"]),\n",
    "            lr=float(r[\"LR\"]),\n",
    "            act=str(r[\"Activation\"]),\n",
    "        )\n",
    "else:\n",
    "\n",
    "    for m in [\n",
    "        \"FIAT\",\n",
    "        \"EQUITY\",\n",
    "        \"GOLD\",\n",
    "        \"ENERGY\",\n",
    "        \"FIAT+EQUITY\",\n",
    "        \"FIAT+GOLD\",\n",
    "        \"FIAT+EQUITY+GOLD+ENERGY\",\n",
    "    ]:\n",
    "        best_map[m] = dict(\n",
    "            w=BASELINE_WINDOW, hidden=BASELINE_HIDDEN, lr=BASELINE_LR, act=BASELINE_ACT\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0680e9d3",
   "metadata": {},
   "source": [
    "### Step 3 – Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "aefca5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train RMSE 0.284705 | val RMSE 0.294928\n",
      "Epoch 002 | train RMSE 0.283108 | val RMSE 0.294137\n",
      "Epoch 003 | train RMSE 0.281517 | val RMSE 0.293356\n",
      "Epoch 004 | train RMSE 0.279933 | val RMSE 0.292587\n",
      "Epoch 005 | train RMSE 0.278356 | val RMSE 0.291833\n",
      "Epoch 006 | train RMSE 0.276786 | val RMSE 0.291097\n",
      "Epoch 007 | train RMSE 0.275224 | val RMSE 0.290378\n",
      "Epoch 008 | train RMSE 0.273668 | val RMSE 0.289678\n",
      "Epoch 009 | train RMSE 0.272119 | val RMSE 0.288996\n",
      "Epoch 010 | train RMSE 0.270577 | val RMSE 0.288331\n",
      "Epoch 011 | train RMSE 0.269043 | val RMSE 0.287683\n",
      "Epoch 012 | train RMSE 0.267515 | val RMSE 0.287051\n",
      "Epoch 013 | train RMSE 0.265995 | val RMSE 0.286436\n",
      "Epoch 014 | train RMSE 0.264484 | val RMSE 0.285837\n",
      "Epoch 015 | train RMSE 0.262980 | val RMSE 0.285255\n",
      "Epoch 016 | train RMSE 0.261485 | val RMSE 0.284690\n",
      "Epoch 017 | train RMSE 0.259998 | val RMSE 0.284142\n",
      "Epoch 018 | train RMSE 0.258519 | val RMSE 0.283613\n",
      "Epoch 019 | train RMSE 0.257049 | val RMSE 0.283102\n",
      "Epoch 020 | train RMSE 0.255588 | val RMSE 0.282610\n",
      "Epoch 021 | train RMSE 0.254135 | val RMSE 0.282137\n",
      "Epoch 022 | train RMSE 0.252690 | val RMSE 0.281684\n",
      "Epoch 023 | train RMSE 0.251254 | val RMSE 0.281252\n",
      "Epoch 024 | train RMSE 0.249826 | val RMSE 0.280840\n",
      "Epoch 025 | train RMSE 0.248407 | val RMSE 0.280450\n",
      "Epoch 001 | train RMSE 0.265401 | val RMSE 0.313242\n",
      "Epoch 002 | train RMSE 0.213655 | val RMSE 0.306189\n",
      "Epoch 003 | train RMSE 0.178754 | val RMSE 0.304674\n",
      "Epoch 004 | train RMSE 0.153721 | val RMSE 0.306362\n",
      "Epoch 005 | train RMSE 0.132769 | val RMSE 0.309755\n",
      "Epoch 006 | train RMSE 0.116885 | val RMSE 0.314311\n",
      "Epoch 007 | train RMSE 0.108171 | val RMSE 0.318885\n",
      "Epoch 008 | train RMSE 0.106319 | val RMSE 0.322333\n",
      "Epoch 009 | train RMSE 0.105223 | val RMSE 0.323768\n",
      "Epoch 010 | train RMSE 0.101863 | val RMSE 0.324490\n",
      "Epoch 011 | train RMSE 0.096881 | val RMSE 0.325615\n",
      "Epoch 012 | train RMSE 0.091835 | val RMSE 0.327366\n",
      "Epoch 013 | train RMSE 0.088283 | val RMSE 0.329590\n",
      "Epoch 014 | train RMSE 0.086914 | val RMSE 0.331646\n",
      "Epoch 015 | train RMSE 0.087449 | val RMSE 0.332891\n",
      "Epoch 016 | train RMSE 0.088675 | val RMSE 0.332902\n",
      "Epoch 017 | train RMSE 0.088675 | val RMSE 0.331534\n",
      "Epoch 018 | train RMSE 0.086671 | val RMSE 0.329213\n",
      "Epoch 019 | train RMSE 0.083616 | val RMSE 0.326720\n",
      "Epoch 020 | train RMSE 0.081019 | val RMSE 0.324644\n",
      "Epoch 021 | train RMSE 0.079877 | val RMSE 0.323052\n",
      "Epoch 022 | train RMSE 0.079751 | val RMSE 0.321835\n",
      "Epoch 023 | train RMSE 0.079846 | val RMSE 0.320916\n",
      "Epoch 024 | train RMSE 0.079583 | val RMSE 0.320264\n",
      "Epoch 025 | train RMSE 0.078607 | val RMSE 0.319765\n",
      "Epoch 001 | train RMSE 0.345139 | val RMSE 0.355006\n",
      "Epoch 002 | train RMSE 0.341661 | val RMSE 0.353403\n",
      "Epoch 003 | train RMSE 0.338213 | val RMSE 0.351804\n",
      "Epoch 004 | train RMSE 0.334793 | val RMSE 0.350212\n",
      "Epoch 005 | train RMSE 0.331395 | val RMSE 0.348630\n",
      "Epoch 006 | train RMSE 0.328015 | val RMSE 0.347057\n",
      "Epoch 007 | train RMSE 0.324668 | val RMSE 0.345493\n",
      "Epoch 008 | train RMSE 0.321353 | val RMSE 0.343936\n",
      "Epoch 009 | train RMSE 0.318077 | val RMSE 0.342391\n",
      "Epoch 010 | train RMSE 0.314838 | val RMSE 0.340855\n",
      "Epoch 011 | train RMSE 0.311622 | val RMSE 0.339330\n",
      "Epoch 012 | train RMSE 0.308427 | val RMSE 0.337820\n",
      "Epoch 013 | train RMSE 0.305250 | val RMSE 0.336318\n",
      "Epoch 014 | train RMSE 0.302081 | val RMSE 0.334829\n",
      "Epoch 015 | train RMSE 0.298925 | val RMSE 0.333355\n",
      "Epoch 016 | train RMSE 0.295793 | val RMSE 0.331896\n",
      "Epoch 017 | train RMSE 0.292689 | val RMSE 0.330453\n",
      "Epoch 018 | train RMSE 0.289626 | val RMSE 0.329025\n",
      "Epoch 019 | train RMSE 0.286606 | val RMSE 0.327615\n",
      "Epoch 020 | train RMSE 0.283579 | val RMSE 0.326223\n",
      "Epoch 021 | train RMSE 0.280576 | val RMSE 0.324854\n",
      "Epoch 022 | train RMSE 0.277602 | val RMSE 0.323502\n",
      "Epoch 023 | train RMSE 0.274654 | val RMSE 0.322165\n",
      "Epoch 024 | train RMSE 0.271733 | val RMSE 0.320848\n",
      "Epoch 025 | train RMSE 0.268833 | val RMSE 0.319551\n",
      "Epoch 001 | train RMSE 0.370952 | val RMSE 0.380060\n",
      "Epoch 002 | train RMSE 0.368468 | val RMSE 0.378964\n",
      "Epoch 003 | train RMSE 0.366008 | val RMSE 0.377875\n",
      "Epoch 004 | train RMSE 0.363571 | val RMSE 0.376792\n",
      "Epoch 005 | train RMSE 0.361157 | val RMSE 0.375717\n",
      "Epoch 006 | train RMSE 0.358768 | val RMSE 0.374649\n",
      "Epoch 007 | train RMSE 0.356403 | val RMSE 0.373588\n",
      "Epoch 008 | train RMSE 0.354061 | val RMSE 0.372535\n",
      "Epoch 009 | train RMSE 0.351744 | val RMSE 0.371489\n",
      "Epoch 010 | train RMSE 0.349450 | val RMSE 0.370452\n",
      "Epoch 011 | train RMSE 0.347179 | val RMSE 0.369422\n",
      "Epoch 012 | train RMSE 0.344930 | val RMSE 0.368400\n",
      "Epoch 013 | train RMSE 0.342702 | val RMSE 0.367387\n",
      "Epoch 014 | train RMSE 0.340494 | val RMSE 0.366381\n",
      "Epoch 015 | train RMSE 0.338304 | val RMSE 0.365383\n",
      "Epoch 016 | train RMSE 0.336133 | val RMSE 0.364394\n",
      "Epoch 017 | train RMSE 0.333979 | val RMSE 0.363413\n",
      "Epoch 018 | train RMSE 0.331841 | val RMSE 0.362439\n",
      "Epoch 019 | train RMSE 0.329720 | val RMSE 0.361475\n",
      "Epoch 020 | train RMSE 0.327615 | val RMSE 0.360518\n",
      "Epoch 021 | train RMSE 0.325524 | val RMSE 0.359570\n",
      "Epoch 022 | train RMSE 0.323448 | val RMSE 0.358631\n",
      "Epoch 023 | train RMSE 0.321386 | val RMSE 0.357700\n",
      "Epoch 024 | train RMSE 0.319338 | val RMSE 0.356778\n",
      "Epoch 025 | train RMSE 0.317302 | val RMSE 0.355864\n",
      "Epoch 001 | train RMSE 0.356224 | val RMSE 0.313309\n",
      "Epoch 002 | train RMSE 0.351947 | val RMSE 0.311727\n",
      "Epoch 003 | train RMSE 0.347726 | val RMSE 0.310210\n",
      "Epoch 004 | train RMSE 0.343565 | val RMSE 0.308762\n",
      "Epoch 005 | train RMSE 0.339465 | val RMSE 0.307385\n",
      "Epoch 006 | train RMSE 0.335430 | val RMSE 0.306080\n",
      "Epoch 007 | train RMSE 0.331461 | val RMSE 0.304849\n",
      "Epoch 008 | train RMSE 0.327561 | val RMSE 0.303694\n",
      "Epoch 009 | train RMSE 0.323730 | val RMSE 0.302617\n",
      "Epoch 010 | train RMSE 0.319969 | val RMSE 0.301619\n",
      "Epoch 011 | train RMSE 0.316279 | val RMSE 0.300702\n",
      "Epoch 012 | train RMSE 0.312658 | val RMSE 0.299866\n",
      "Epoch 013 | train RMSE 0.309105 | val RMSE 0.299111\n",
      "Epoch 014 | train RMSE 0.305618 | val RMSE 0.298438\n",
      "Epoch 015 | train RMSE 0.302193 | val RMSE 0.297844\n",
      "Epoch 016 | train RMSE 0.298827 | val RMSE 0.297330\n",
      "Epoch 017 | train RMSE 0.295515 | val RMSE 0.296894\n",
      "Epoch 018 | train RMSE 0.292253 | val RMSE 0.296535\n",
      "Epoch 019 | train RMSE 0.289037 | val RMSE 0.296250\n",
      "Epoch 020 | train RMSE 0.285861 | val RMSE 0.296038\n",
      "Epoch 021 | train RMSE 0.282721 | val RMSE 0.295897\n",
      "Epoch 022 | train RMSE 0.279614 | val RMSE 0.295824\n",
      "Epoch 023 | train RMSE 0.276534 | val RMSE 0.295818\n",
      "Epoch 024 | train RMSE 0.273480 | val RMSE 0.295877\n",
      "Epoch 025 | train RMSE 0.270447 | val RMSE 0.295998\n",
      "Epoch 001 | train RMSE 0.282028 | val RMSE 0.311107\n",
      "Epoch 002 | train RMSE 0.280238 | val RMSE 0.310308\n",
      "Epoch 003 | train RMSE 0.278461 | val RMSE 0.309516\n",
      "Epoch 004 | train RMSE 0.276699 | val RMSE 0.308732\n",
      "Epoch 005 | train RMSE 0.274952 | val RMSE 0.307959\n",
      "Epoch 006 | train RMSE 0.273212 | val RMSE 0.307195\n",
      "Epoch 007 | train RMSE 0.271471 | val RMSE 0.306441\n",
      "Epoch 008 | train RMSE 0.269749 | val RMSE 0.305699\n",
      "Epoch 009 | train RMSE 0.268169 | val RMSE 0.304968\n",
      "Epoch 010 | train RMSE 0.266665 | val RMSE 0.304244\n",
      "Epoch 011 | train RMSE 0.265174 | val RMSE 0.303525\n",
      "Epoch 012 | train RMSE 0.263697 | val RMSE 0.302821\n",
      "Epoch 013 | train RMSE 0.262238 | val RMSE 0.302133\n",
      "Epoch 014 | train RMSE 0.260829 | val RMSE 0.301460\n",
      "Epoch 015 | train RMSE 0.259427 | val RMSE 0.300799\n",
      "Epoch 016 | train RMSE 0.258051 | val RMSE 0.300149\n",
      "Epoch 017 | train RMSE 0.256685 | val RMSE 0.299509\n",
      "Epoch 018 | train RMSE 0.255328 | val RMSE 0.298885\n",
      "Epoch 019 | train RMSE 0.253979 | val RMSE 0.298270\n",
      "Epoch 020 | train RMSE 0.252611 | val RMSE 0.297667\n",
      "Epoch 021 | train RMSE 0.251216 | val RMSE 0.297077\n",
      "Epoch 022 | train RMSE 0.249821 | val RMSE 0.296494\n",
      "Epoch 023 | train RMSE 0.248425 | val RMSE 0.295922\n",
      "Epoch 024 | train RMSE 0.247024 | val RMSE 0.295361\n",
      "Epoch 025 | train RMSE 0.245629 | val RMSE 0.294810\n",
      "Epoch 001 | train RMSE 0.340599 | val RMSE 0.301331\n",
      "Epoch 002 | train RMSE 0.333287 | val RMSE 0.299010\n",
      "Epoch 003 | train RMSE 0.326285 | val RMSE 0.296719\n",
      "Epoch 004 | train RMSE 0.319301 | val RMSE 0.294472\n",
      "Epoch 005 | train RMSE 0.312457 | val RMSE 0.292275\n",
      "Epoch 006 | train RMSE 0.305760 | val RMSE 0.290126\n",
      "Epoch 007 | train RMSE 0.299155 | val RMSE 0.288050\n",
      "Epoch 008 | train RMSE 0.292617 | val RMSE 0.286065\n",
      "Epoch 009 | train RMSE 0.286161 | val RMSE 0.284155\n",
      "Epoch 010 | train RMSE 0.279786 | val RMSE 0.282353\n",
      "Epoch 011 | train RMSE 0.273402 | val RMSE 0.280644\n",
      "Epoch 012 | train RMSE 0.267174 | val RMSE 0.279020\n",
      "Epoch 013 | train RMSE 0.261054 | val RMSE 0.277508\n",
      "Epoch 014 | train RMSE 0.254959 | val RMSE 0.276120\n",
      "Epoch 015 | train RMSE 0.248856 | val RMSE 0.274841\n",
      "Epoch 016 | train RMSE 0.242804 | val RMSE 0.273662\n",
      "Epoch 017 | train RMSE 0.236810 | val RMSE 0.272600\n",
      "Epoch 018 | train RMSE 0.230942 | val RMSE 0.271642\n",
      "Epoch 019 | train RMSE 0.225234 | val RMSE 0.270801\n",
      "Epoch 020 | train RMSE 0.219596 | val RMSE 0.270065\n",
      "Epoch 021 | train RMSE 0.214035 | val RMSE 0.269401\n",
      "Epoch 022 | train RMSE 0.208527 | val RMSE 0.268831\n",
      "Epoch 023 | train RMSE 0.203080 | val RMSE 0.268333\n",
      "Epoch 024 | train RMSE 0.197687 | val RMSE 0.267937\n",
      "Epoch 025 | train RMSE 0.192380 | val RMSE 0.267657\n",
      "Saved learning curves\n"
     ]
    }
   ],
   "source": [
    "curves_index = []\n",
    "for market_assets in MARKET_CHOICES:\n",
    "    label = \"+\".join(market_assets)\n",
    "    cfg = best_map.get(\n",
    "        label,\n",
    "        dict(\n",
    "            w=BASELINE_WINDOW, hidden=BASELINE_HIDDEN, lr=BASELINE_LR, act=BASELINE_ACT\n",
    "        ),\n",
    "    )\n",
    "    w = int(cfg[\"w\"])\n",
    "    pnl = build_panel_for_market(data, market_assets, w)\n",
    "    if len(pnl[\"Xtr\"]) == 0 or len(pnl[\"Xval\"]) == 0:\n",
    "        p(f\"Skipping curves for {label} due to empty split\")\n",
    "        continue\n",
    "    model_best, tr_hist, va_hist = train_nn(\n",
    "        pnl[\"Xtr\"],\n",
    "        pnl[\"ytr\"],\n",
    "        pnl[\"Xval\"],\n",
    "        pnl[\"yval\"],\n",
    "        hidden=int(cfg[\"hidden\"]),\n",
    "        lr=float(cfg[\"lr\"]),\n",
    "        act=str(cfg[\"act\"]),\n",
    "        epochs=BASELINE_EPOCHS,\n",
    "    )\n",
    "    model_path = f\"outputs/model_step3_{label.replace('+','_')}.pt\"\n",
    "    torch.save(model_best.state_dict(), model_path)\n",
    "    plot_path = f\"outputs/step3_learning_curve_{label.replace('+','_')}.png\"\n",
    "    plot_learning_curve(tr_hist, va_hist, f\"{label} w={w} act={cfg['act']}\", plot_path)\n",
    "    curves_index.append(\n",
    "        dict(market=label, model_path=model_path, curve_path=plot_path, cfg=cfg)\n",
    "    )\n",
    "\n",
    "with open(\"outputs/step3_curves_index.json\", \"w\") as f:\n",
    "    json.dump(curves_index, f, indent=2)\n",
    "\n",
    "p(\"Saved learning curves\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f919793a",
   "metadata": {},
   "source": [
    "### Step 4 – Descriptive statistics of neural 𝛽"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e7ea627d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train RMSE 0.434227 | val RMSE 0.441631\n",
      "Epoch 002 | train RMSE 0.432346 | val RMSE 0.439707\n",
      "Epoch 003 | train RMSE 0.430470 | val RMSE 0.437789\n",
      "Epoch 004 | train RMSE 0.428599 | val RMSE 0.435877\n",
      "Epoch 005 | train RMSE 0.426732 | val RMSE 0.433971\n",
      "Epoch 006 | train RMSE 0.424871 | val RMSE 0.432071\n",
      "Epoch 007 | train RMSE 0.423015 | val RMSE 0.430178\n",
      "Epoch 008 | train RMSE 0.421165 | val RMSE 0.428292\n",
      "Epoch 009 | train RMSE 0.419320 | val RMSE 0.426414\n",
      "Epoch 010 | train RMSE 0.417481 | val RMSE 0.424543\n",
      "Epoch 011 | train RMSE 0.415648 | val RMSE 0.422681\n",
      "Epoch 012 | train RMSE 0.413820 | val RMSE 0.420827\n",
      "Epoch 013 | train RMSE 0.411999 | val RMSE 0.418981\n",
      "Epoch 014 | train RMSE 0.410183 | val RMSE 0.417145\n",
      "Epoch 015 | train RMSE 0.408374 | val RMSE 0.415318\n",
      "Epoch 016 | train RMSE 0.406570 | val RMSE 0.413501\n",
      "Epoch 017 | train RMSE 0.404773 | val RMSE 0.411694\n",
      "Epoch 018 | train RMSE 0.402982 | val RMSE 0.409896\n",
      "Epoch 019 | train RMSE 0.401197 | val RMSE 0.408108\n",
      "Epoch 020 | train RMSE 0.399418 | val RMSE 0.406331\n",
      "Epoch 021 | train RMSE 0.397646 | val RMSE 0.404563\n",
      "Epoch 022 | train RMSE 0.395880 | val RMSE 0.402806\n",
      "Epoch 023 | train RMSE 0.394120 | val RMSE 0.401058\n",
      "Epoch 024 | train RMSE 0.392367 | val RMSE 0.399320\n",
      "Epoch 025 | train RMSE 0.390620 | val RMSE 0.397591\n",
      "Epoch 001 | train RMSE 0.352265 | val RMSE 0.301429\n",
      "Epoch 002 | train RMSE 0.299933 | val RMSE 0.263236\n",
      "Epoch 003 | train RMSE 0.261629 | val RMSE 0.243713\n",
      "Epoch 004 | train RMSE 0.240411 | val RMSE 0.239021\n",
      "Epoch 005 | train RMSE 0.233159 | val RMSE 0.238323\n",
      "Epoch 006 | train RMSE 0.230207 | val RMSE 0.234838\n",
      "Epoch 007 | train RMSE 0.225091 | val RMSE 0.227005\n",
      "Epoch 008 | train RMSE 0.216356 | val RMSE 0.216248\n",
      "Epoch 009 | train RMSE 0.205408 | val RMSE 0.204812\n",
      "Epoch 010 | train RMSE 0.194384 | val RMSE 0.194630\n",
      "Epoch 011 | train RMSE 0.184967 | val RMSE 0.186226\n",
      "Epoch 012 | train RMSE 0.177456 | val RMSE 0.178771\n",
      "Epoch 013 | train RMSE 0.170696 | val RMSE 0.171426\n",
      "Epoch 014 | train RMSE 0.163672 | val RMSE 0.163642\n",
      "Epoch 015 | train RMSE 0.155744 | val RMSE 0.155833\n",
      "Epoch 016 | train RMSE 0.147340 | val RMSE 0.148873\n",
      "Epoch 017 | train RMSE 0.139638 | val RMSE 0.143390\n",
      "Epoch 018 | train RMSE 0.133551 | val RMSE 0.138599\n",
      "Epoch 019 | train RMSE 0.128696 | val RMSE 0.133348\n",
      "Epoch 020 | train RMSE 0.124020 | val RMSE 0.127438\n",
      "Epoch 021 | train RMSE 0.119052 | val RMSE 0.121674\n",
      "Epoch 022 | train RMSE 0.114385 | val RMSE 0.117787\n",
      "Epoch 023 | train RMSE 0.111397 | val RMSE 0.116275\n",
      "Epoch 024 | train RMSE 0.110225 | val RMSE 0.115359\n",
      "Epoch 025 | train RMSE 0.109303 | val RMSE 0.114106\n",
      "Epoch 001 | train RMSE 0.364075 | val RMSE 0.365024\n",
      "Epoch 002 | train RMSE 0.361250 | val RMSE 0.362170\n",
      "Epoch 003 | train RMSE 0.358444 | val RMSE 0.359339\n",
      "Epoch 004 | train RMSE 0.355658 | val RMSE 0.356526\n",
      "Epoch 005 | train RMSE 0.352892 | val RMSE 0.353730\n",
      "Epoch 006 | train RMSE 0.350144 | val RMSE 0.350955\n",
      "Epoch 007 | train RMSE 0.347416 | val RMSE 0.348207\n",
      "Epoch 008 | train RMSE 0.344711 | val RMSE 0.345485\n",
      "Epoch 009 | train RMSE 0.342030 | val RMSE 0.342783\n",
      "Epoch 010 | train RMSE 0.339366 | val RMSE 0.340102\n",
      "Epoch 011 | train RMSE 0.336721 | val RMSE 0.337442\n",
      "Epoch 012 | train RMSE 0.334095 | val RMSE 0.334808\n",
      "Epoch 013 | train RMSE 0.331491 | val RMSE 0.332207\n",
      "Epoch 014 | train RMSE 0.328915 | val RMSE 0.329637\n",
      "Epoch 015 | train RMSE 0.326366 | val RMSE 0.327092\n",
      "Epoch 016 | train RMSE 0.323841 | val RMSE 0.324567\n",
      "Epoch 017 | train RMSE 0.321336 | val RMSE 0.322065\n",
      "Epoch 018 | train RMSE 0.318852 | val RMSE 0.319592\n",
      "Epoch 019 | train RMSE 0.316390 | val RMSE 0.317143\n",
      "Epoch 020 | train RMSE 0.313946 | val RMSE 0.314723\n",
      "Epoch 021 | train RMSE 0.311526 | val RMSE 0.312321\n",
      "Epoch 022 | train RMSE 0.309126 | val RMSE 0.309941\n",
      "Epoch 023 | train RMSE 0.306746 | val RMSE 0.307582\n",
      "Epoch 024 | train RMSE 0.304386 | val RMSE 0.305245\n",
      "Epoch 025 | train RMSE 0.302045 | val RMSE 0.302931\n",
      "Epoch 001 | train RMSE 0.326496 | val RMSE 0.350984\n",
      "Epoch 002 | train RMSE 0.324727 | val RMSE 0.348986\n",
      "Epoch 003 | train RMSE 0.322966 | val RMSE 0.347013\n",
      "Epoch 004 | train RMSE 0.321215 | val RMSE 0.345064\n",
      "Epoch 005 | train RMSE 0.319473 | val RMSE 0.343131\n",
      "Epoch 006 | train RMSE 0.317741 | val RMSE 0.341209\n",
      "Epoch 007 | train RMSE 0.316020 | val RMSE 0.339293\n",
      "Epoch 008 | train RMSE 0.314308 | val RMSE 0.337379\n",
      "Epoch 009 | train RMSE 0.312607 | val RMSE 0.335465\n",
      "Epoch 010 | train RMSE 0.310916 | val RMSE 0.333549\n",
      "Epoch 011 | train RMSE 0.309235 | val RMSE 0.331635\n",
      "Epoch 012 | train RMSE 0.307565 | val RMSE 0.329723\n",
      "Epoch 013 | train RMSE 0.305906 | val RMSE 0.327819\n",
      "Epoch 014 | train RMSE 0.304258 | val RMSE 0.325925\n",
      "Epoch 015 | train RMSE 0.302621 | val RMSE 0.324043\n",
      "Epoch 016 | train RMSE 0.300995 | val RMSE 0.322177\n",
      "Epoch 017 | train RMSE 0.299381 | val RMSE 0.320326\n",
      "Epoch 018 | train RMSE 0.297779 | val RMSE 0.318490\n",
      "Epoch 019 | train RMSE 0.296189 | val RMSE 0.316669\n",
      "Epoch 020 | train RMSE 0.294612 | val RMSE 0.314862\n",
      "Epoch 021 | train RMSE 0.293047 | val RMSE 0.313067\n",
      "Epoch 022 | train RMSE 0.291494 | val RMSE 0.311285\n",
      "Epoch 023 | train RMSE 0.289955 | val RMSE 0.309515\n",
      "Epoch 024 | train RMSE 0.288430 | val RMSE 0.307757\n",
      "Epoch 025 | train RMSE 0.286917 | val RMSE 0.306014\n",
      "Epoch 001 | train RMSE 0.509494 | val RMSE 0.493869\n",
      "Epoch 002 | train RMSE 0.504802 | val RMSE 0.489153\n",
      "Epoch 003 | train RMSE 0.500153 | val RMSE 0.484489\n",
      "Epoch 004 | train RMSE 0.495545 | val RMSE 0.479888\n",
      "Epoch 005 | train RMSE 0.490976 | val RMSE 0.475342\n",
      "Epoch 006 | train RMSE 0.486442 | val RMSE 0.470843\n",
      "Epoch 007 | train RMSE 0.481945 | val RMSE 0.466389\n",
      "Epoch 008 | train RMSE 0.477484 | val RMSE 0.461979\n",
      "Epoch 009 | train RMSE 0.473062 | val RMSE 0.457613\n",
      "Epoch 010 | train RMSE 0.468680 | val RMSE 0.453293\n",
      "Epoch 011 | train RMSE 0.464338 | val RMSE 0.449021\n",
      "Epoch 012 | train RMSE 0.460038 | val RMSE 0.444796\n",
      "Epoch 013 | train RMSE 0.455780 | val RMSE 0.440621\n",
      "Epoch 014 | train RMSE 0.451566 | val RMSE 0.436498\n",
      "Epoch 015 | train RMSE 0.447395 | val RMSE 0.432426\n",
      "Epoch 016 | train RMSE 0.443268 | val RMSE 0.428408\n",
      "Epoch 017 | train RMSE 0.439186 | val RMSE 0.424445\n",
      "Epoch 018 | train RMSE 0.435148 | val RMSE 0.420537\n",
      "Epoch 019 | train RMSE 0.431156 | val RMSE 0.416686\n",
      "Epoch 020 | train RMSE 0.427209 | val RMSE 0.412891\n",
      "Epoch 021 | train RMSE 0.423308 | val RMSE 0.409153\n",
      "Epoch 022 | train RMSE 0.419452 | val RMSE 0.405472\n",
      "Epoch 023 | train RMSE 0.415642 | val RMSE 0.401847\n",
      "Epoch 024 | train RMSE 0.411877 | val RMSE 0.398278\n",
      "Epoch 025 | train RMSE 0.408158 | val RMSE 0.394764\n",
      "Epoch 001 | train RMSE 0.444493 | val RMSE 0.427206\n",
      "Epoch 002 | train RMSE 0.442422 | val RMSE 0.425251\n",
      "Epoch 003 | train RMSE 0.440372 | val RMSE 0.423323\n",
      "Epoch 004 | train RMSE 0.438344 | val RMSE 0.421410\n",
      "Epoch 005 | train RMSE 0.436331 | val RMSE 0.419507\n",
      "Epoch 006 | train RMSE 0.434334 | val RMSE 0.417617\n",
      "Epoch 007 | train RMSE 0.432355 | val RMSE 0.415731\n",
      "Epoch 008 | train RMSE 0.430383 | val RMSE 0.413849\n",
      "Epoch 009 | train RMSE 0.428430 | val RMSE 0.411966\n",
      "Epoch 010 | train RMSE 0.426483 | val RMSE 0.410080\n",
      "Epoch 011 | train RMSE 0.424535 | val RMSE 0.408199\n",
      "Epoch 012 | train RMSE 0.422591 | val RMSE 0.406331\n",
      "Epoch 013 | train RMSE 0.420654 | val RMSE 0.404475\n",
      "Epoch 014 | train RMSE 0.418720 | val RMSE 0.402634\n",
      "Epoch 015 | train RMSE 0.416794 | val RMSE 0.400809\n",
      "Epoch 016 | train RMSE 0.414878 | val RMSE 0.399003\n",
      "Epoch 017 | train RMSE 0.412975 | val RMSE 0.397211\n",
      "Epoch 018 | train RMSE 0.411081 | val RMSE 0.395434\n",
      "Epoch 019 | train RMSE 0.409200 | val RMSE 0.393668\n",
      "Epoch 020 | train RMSE 0.407326 | val RMSE 0.391913\n",
      "Epoch 021 | train RMSE 0.405475 | val RMSE 0.390173\n",
      "Epoch 022 | train RMSE 0.403639 | val RMSE 0.388444\n",
      "Epoch 023 | train RMSE 0.401812 | val RMSE 0.386727\n",
      "Epoch 024 | train RMSE 0.399994 | val RMSE 0.385021\n",
      "Epoch 025 | train RMSE 0.398186 | val RMSE 0.383326\n",
      "Epoch 001 | train RMSE 0.300470 | val RMSE 0.315311\n",
      "Epoch 002 | train RMSE 0.295383 | val RMSE 0.310127\n",
      "Epoch 003 | train RMSE 0.290428 | val RMSE 0.305103\n",
      "Epoch 004 | train RMSE 0.285619 | val RMSE 0.300175\n",
      "Epoch 005 | train RMSE 0.280919 | val RMSE 0.295369\n",
      "Epoch 006 | train RMSE 0.276349 | val RMSE 0.290736\n",
      "Epoch 007 | train RMSE 0.271944 | val RMSE 0.286274\n",
      "Epoch 008 | train RMSE 0.267703 | val RMSE 0.281942\n",
      "Epoch 009 | train RMSE 0.263597 | val RMSE 0.277749\n",
      "Epoch 010 | train RMSE 0.259628 | val RMSE 0.273725\n",
      "Epoch 011 | train RMSE 0.255828 | val RMSE 0.269844\n",
      "Epoch 012 | train RMSE 0.252172 | val RMSE 0.266086\n",
      "Epoch 013 | train RMSE 0.248651 | val RMSE 0.262464\n",
      "Epoch 014 | train RMSE 0.245259 | val RMSE 0.258983\n",
      "Epoch 015 | train RMSE 0.242003 | val RMSE 0.255626\n",
      "Epoch 016 | train RMSE 0.238871 | val RMSE 0.252370\n",
      "Epoch 017 | train RMSE 0.235847 | val RMSE 0.249233\n",
      "Epoch 018 | train RMSE 0.232952 | val RMSE 0.246192\n",
      "Epoch 019 | train RMSE 0.230155 | val RMSE 0.243238\n",
      "Epoch 020 | train RMSE 0.227447 | val RMSE 0.240387\n",
      "Epoch 021 | train RMSE 0.224842 | val RMSE 0.237613\n",
      "Epoch 022 | train RMSE 0.222314 | val RMSE 0.234902\n",
      "Epoch 023 | train RMSE 0.219852 | val RMSE 0.232276\n",
      "Epoch 024 | train RMSE 0.217472 | val RMSE 0.229707\n",
      "Epoch 025 | train RMSE 0.215157 | val RMSE 0.227196\n",
      "Saved test betas and descriptive stats\n"
     ]
    }
   ],
   "source": [
    "all_betas = []\n",
    "for market_assets in MARKET_CHOICES:\n",
    "    label = \"+\".join(market_assets)\n",
    "    cfg = best_map.get(\n",
    "        label,\n",
    "        dict(\n",
    "            w=BASELINE_WINDOW, hidden=BASELINE_HIDDEN, lr=BASELINE_LR, act=BASELINE_ACT\n",
    "        ),\n",
    "    )\n",
    "    w = int(cfg[\"w\"])\n",
    "    pnl = build_panel_for_market(data, market_assets, w)\n",
    "    if len(pnl[\"Xtr\"]) == 0 or len(pnl[\"Xval\"]) == 0 or len(pnl[\"Xte\"]) == 0:\n",
    "        p(f\"Skipping {label} stats due to empty split\")\n",
    "        continue\n",
    "\n",
    "    X_tv = np.vstack([pnl[\"Xtr\"], pnl[\"Xval\"]])\n",
    "    y_tv = np.hstack([pnl[\"ytr\"], pnl[\"yval\"]])\n",
    "    model_tv, _, _ = train_nn(\n",
    "        X_tv,\n",
    "        y_tv,\n",
    "        pnl[\"Xval\"],\n",
    "        pnl[\"yval\"],\n",
    "        hidden=int(cfg[\"hidden\"]),\n",
    "        lr=float(cfg[\"lr\"]),\n",
    "        act=str(cfg[\"act\"]),\n",
    "        epochs=BASELINE_EPOCHS,\n",
    "    )\n",
    "    df_b = predict_betas_df(model_tv, pnl[\"Xte\"], pnl[\"ids_te\"], label)\n",
    "    all_betas.append(df_b)\n",
    "\n",
    "if all_betas:\n",
    "    df_betas = pd.concat(all_betas, ignore_index=True)\n",
    "\n",
    "    df_betas = df_betas[\n",
    "        (df_betas[\"Date\"] >= \"2023-01-01\") & (df_betas[\"Date\"] <= \"2025-10-31\")\n",
    "    ]\n",
    "    df_betas.to_csv(\"outputs/step4_test_betas_panel.csv\", index=False)\n",
    "\n",
    "    rows = []\n",
    "    for (c, a), g in df_betas.groupby([\"Crypto\", \"Asset\"]):\n",
    "        b = g[\"Beta\"].values\n",
    "        d = compute_descriptive_stats(b)\n",
    "        d.update({\"Crypto\": c, \"Asset\": a})\n",
    "        rows.append(d)\n",
    "    stats_df = pd.DataFrame(rows)[\n",
    "        [\n",
    "            \"Crypto\",\n",
    "            \"Asset\",\n",
    "            \"N\",\n",
    "            \"Mean\",\n",
    "            \"Std\",\n",
    "            \"Skew\",\n",
    "            \"Kurtosis\",\n",
    "            \"Min\",\n",
    "            \"P1\",\n",
    "            \"P5\",\n",
    "            \"P25\",\n",
    "            \"P50\",\n",
    "            \"P75\",\n",
    "            \"P95\",\n",
    "            \"P99\",\n",
    "            \"Max\",\n",
    "        ]\n",
    "    ].sort_values([\"Asset\", \"Crypto\"])\n",
    "    stats_df.to_csv(\"outputs/step4_neural_beta_descriptives.csv\", index=False)\n",
    "    p(\"Saved test betas and descriptive stats\")\n",
    "else:\n",
    "    p(\"No betas computed. Check earlier steps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cb104b",
   "metadata": {},
   "source": [
    "### Step 5 – Dynamics of neural 𝛽"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "de07e0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beta dynamics plot\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"outputs/step4_test_betas_panel.csv\"):\n",
    "    df_betas = pd.read_csv(\"outputs/step4_test_betas_panel.csv\", parse_dates=[\"Date\"])\n",
    "    plot_annual_beta_dynamics(df_betas, \"outputs/step5_beta_dynamics.png\")\n",
    "    p(\"Saved beta dynamics plot\")\n",
    "else:\n",
    "    p(\"No betas panel found. Skipping..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ebe263",
   "metadata": {},
   "source": [
    "### Step 6 – Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf77545",
   "metadata": {},
   "source": [
    "Across the sample period, the neural betas (β) estimated for BTC, ETH, LTC, and BCH reveal a consistent pattern of weak or negative relationships with traditional market factors. On average, β values range between –0.05 and –0.07, indicating that cryptocurrencies exhibit limited sensitivity to conventional macroeconomic assets such as fiat currencies, equities, gold, and energy commodities. This overall independence supports the idea that crypto markets continue to operate largely as a separate asset class, driven by their own liquidity and sentiment cycles rather than traditional financial fundamentals.\n",
    "\n",
    "Among the asset classes, equity factors exerted the strongest and most variable influence on crypto returns. During months of heightened market activity, betas against equity markets tended to rise, suggesting that cryptos partially align with equity risk-on/risk-off dynamics during turbulent periods. By contrast, fiat betas remained close to zero and largely stable, implying minimal connection to broad currency fluctuations. Gold betas were small but occasionally positive, consistent with gold’s weakly diversifying relationship to risk assets. Energy betas showed higher volatility in the middle of the year, hinting at short-lived correlations between crypto and commodity price cycles.\n",
    "\n",
    "Across cryptocurrencies, BTC and ETH displayed the most stable and consistent β trajectories, reacting similarly to macroeconomic changes. LTC and BCH, however, exhibited more erratic movements and wider month-to-month variation, likely reflecting thinner market depth and greater exposure to idiosyncratic shocks. Temporally, neural betas were less negative in early 2023, dipped during mid-year, and recovered slightly toward year-end, broadly mirroring the rebound in overall crypto valuations. \n",
    "\n",
    "Overall, these findings suggest that while cryptos occasionally move in tandem with equities or commodities during high-volatility periods, their market dynamics remain distinct and largely insulated from traditional macroeconomic factors. The relationships identified are transient rather than structural, highlighting the evolving and independent nature of digital asset risk exposures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a423c191",
   "metadata": {},
   "source": [
    "### Step 7 – Including additional factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e35e3ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged table with FF factors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rx/4mtzy3y13t9f2njmm29j60pm0000gp/T/ipykernel_56309/3133147342.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ff_df[\"date\"] = pd.to_datetime(\n",
      "/var/folders/rx/4mtzy3y13t9f2njmm29j60pm0000gp/T/ipykernel_56309/3133147342.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ff_df[col] = pd.to_numeric(ff_df[col], errors=\"coerce\") / 100.0\n"
     ]
    }
   ],
   "source": [
    "FF_PATH = \"data/FamaFrench_factors.csv\"\n",
    "if os.path.exists(FF_PATH):\n",
    "    ff_df = pd.read_csv(FF_PATH)\n",
    "    merged = add_ff_factors(data.copy(), ff_df)\n",
    "    merged.to_csv(\"outputs/step7_data_with_ff.csv\", index=False)\n",
    "    p(\"Saved merged table with FF factors\")\n",
    "else:\n",
    "    p(\"No FF factors file found. Skipping join...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5bdda8",
   "metadata": {},
   "source": [
    "### Step 8 – Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fc1faa",
   "metadata": {},
   "source": [
    "After incorporating the Fama–French (FF) factors into the neural network model, the validation errors showed only marginal improvement relative to the baseline architecture. While the inclusion of FF features such as the market excess return (MKT–RF) and size factor (SMB) slightly reduced the RMSE, the overall gain in predictive accuracy was modest. This indicates that, although traditional equity risk factors do provide additional explanatory power, their relevance to cryptocurrency return dynamics remains limited.\n",
    "\n",
    "Among the FF factors, the market (MKT–RF) component emerged as the most influential, aligning with the observation that crypto assets occasionally move in tandem with broad equity market trends, particularly during high-volatility periods. The SMB (small minus big) and HML (high minus low) factors contributed little incremental explanatory power, suggesting that cross-sectional characteristics such as firm size and value premia—central to traditional equity markets—do not translate effectively to decentralized, non-fundamental assets like cryptocurrencies. The RMW (robust minus weak) and CMA (conservative minus aggressive) factors appeared largely noise-like in this context.\n",
    "\n",
    "While the augmented model captures a slightly richer view of systemic market exposure, the added complexity and dimensionality yield diminishing returns. Neural betas derived from the FF-augmented model remain broadly consistent with those estimated without factor augmentation, reinforcing the conclusion that cryptocurrencies are only weakly tied to equity-style risk premia. Thus, for practical purposes, the simpler architecture—using macro-asset returns alone—offers a more interpretable and computationally efficient framework without sacrificing predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9693e1c7",
   "metadata": {},
   "source": [
    "### Step 9 – Sorting on neural 𝛽 and portfolio returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "34e28207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved portfolio sorts\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"outputs/step4_test_betas_panel.csv\"):\n",
    "    df_betas = pd.read_csv(\"outputs/step4_test_betas_panel.csv\", parse_dates=[\"Date\"])\n",
    "\n",
    "    returns_df = data.copy()\n",
    "\n",
    "    returns_df = returns_df.rename_axis(\"Date\").reset_index()\n",
    "    returns_df[\"Date\"] = pd.to_datetime(returns_df[\"Date\"])\n",
    "    returns_df = returns_df.set_index(\"Date\")\n",
    "\n",
    "    keep_dates = sorted(df_betas[\"Date\"].unique())\n",
    "    returns_df = returns_df.loc[returns_df.index.isin(keep_dates)]\n",
    "    port = sort_and_portfolio(df_betas, returns_df)\n",
    "    port.to_csv(\"outputs/step9_portfolio_sorts.csv\", index=False)\n",
    "    p(\"Saved portfolio sorts\")\n",
    "else:\n",
    "    p(\"No betas panel found. Skipping..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44545da9",
   "metadata": {},
   "source": [
    "### HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6ae782e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML report created: outputs/outputs.html\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "OUT_DIR = Path(\"outputs\")\n",
    "REPORT_PATH = OUT_DIR / \"outputs.html\"\n",
    "\n",
    "\n",
    "def img_to_base64(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def preview_csv(path, n=8, wide=False):\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        html = df.head(n).to_html(\n",
    "            index=False, classes=f\"styled-table{' wide-table' if wide else ''}\"\n",
    "        )\n",
    "        return f'<div class=\"table-wrapper\">{html}</div>'\n",
    "    except Exception as e:\n",
    "        return f\"<p><em>Unable to preview table: {e}</em></p>\"\n",
    "\n",
    "\n",
    "def find_file(keyword, ext=\"png\"):\n",
    "    files = list(OUT_DIR.glob(f\"*{keyword}*.{ext}\"))\n",
    "    return files[0] if files else None\n",
    "\n",
    "\n",
    "def card(title, text, img=None, table=None):\n",
    "    img_html = f'<img src=\"data:image/png;base64,{img_to_base64(img)}\"/>' if img else \"\"\n",
    "    table_html = table if table else \"\"\n",
    "    return f\"\"\"\n",
    "    <section class=\"card\">\n",
    "        <h2>{title}</h2>\n",
    "        <p>{text}</p>\n",
    "        {img_html}\n",
    "        {table_html}\n",
    "    </section>\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "html = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "<meta charset=\"utf-8\">\n",
    "<title>Neural Beta Analysis Report</title>\n",
    "<style>\n",
    "body {{\n",
    "  font-family: 'Segoe UI', Roboto, Helvetica, Arial, sans-serif;\n",
    "  background: linear-gradient(180deg, #e6ebf2, #f5f7fa);\n",
    "  color: #222;\n",
    "  line-height: 1.6;\n",
    "  margin: 0;\n",
    "}}\n",
    "header {{\n",
    "  background: linear-gradient(135deg, #002a4e, #00558d);\n",
    "  color: #fff;\n",
    "  text-align: center;\n",
    "  padding: 50px 20px;\n",
    "  box-shadow: 0 3px 10px rgba(0,0,0,0.2);\n",
    "}}\n",
    "header h1 {{\n",
    "  font-size: 2.2rem;\n",
    "  margin: 0;\n",
    "}}\n",
    "header p {{\n",
    "  margin-top: 10px;\n",
    "  opacity: 0.9;\n",
    "}}\n",
    "main {{\n",
    "  max-width: 1100px;\n",
    "  margin: 40px auto;\n",
    "  padding: 0 25px 40px 25px;\n",
    "}}\n",
    ".card {{\n",
    "  background: linear-gradient(180deg, #ffffff, #f9fbff);\n",
    "  border-radius: 14px;\n",
    "  padding: 28px 35px;\n",
    "  margin-bottom: 35px;\n",
    "  box-shadow: 0 2px 10px rgba(0,0,0,0.08);\n",
    "  transition: transform 0.2s, box-shadow 0.2s;\n",
    "}}\n",
    ".card:hover {{\n",
    "  transform: translateY(-3px);\n",
    "  box-shadow: 0 5px 14px rgba(0,0,0,0.12);\n",
    "}}\n",
    ".card h2 {{\n",
    "  color: #003366;\n",
    "  margin-top: 0;\n",
    "}}\n",
    "img {{\n",
    "  display: block;\n",
    "  margin: 20px auto;\n",
    "  max-width: 65%;\n",
    "  border-radius: 8px;\n",
    "  box-shadow: 0 0 10px rgba(0,0,0,0.15);\n",
    "}}\n",
    ".table-wrapper {{\n",
    "  overflow-x: auto;\n",
    "  width: 100%;\n",
    "  text-align: center;\n",
    "}}\n",
    ".styled-table {{\n",
    "  border-collapse: collapse;\n",
    "  width: 90%;\n",
    "  margin: 20px auto;\n",
    "  font-size: 0.9em;\n",
    "  min-width: 400px;\n",
    "}}\n",
    ".wide-table {{\n",
    "  width: 85%;\n",
    "  font-size: 0.82em;\n",
    "}}\n",
    ".styled-table thead tr {{\n",
    "  background-color: #004c7a;\n",
    "  color: #fff;\n",
    "}}\n",
    ".styled-table th, .styled-table td {{\n",
    "  border: 1px solid #ddd;\n",
    "  padding: 6px 8px;\n",
    "  text-align: center;\n",
    "}}\n",
    ".styled-table tbody tr:nth-child(even) {{\n",
    "  background-color: #f2f6fb;\n",
    "}}\n",
    "footer {{\n",
    "  text-align: center;\n",
    "  color: #777;\n",
    "  font-size: 0.9em;\n",
    "  padding: 25px;\n",
    "  background: linear-gradient(135deg, #004c7a, #003366);\n",
    "  color: white;\n",
    "}}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "<header>\n",
    "  <h1>Neural Beta for Crypto and Cross-Asset Markets</h1>\n",
    "</header>\n",
    "<main>\n",
    "\"\"\"\n",
    "\n",
    "html += card(\n",
    "    \"Step 0 – Data Preparation\",\n",
    "    \"Crypto (BTC, ETH, LTC, BCH) and market (Fiat, Equity, Gold, Energy) data were merged, \"\n",
    "    \"resampled to monthly frequency, and transformed into log returns.\",\n",
    "    table=(\n",
    "        preview_csv(OUT_DIR / \"data_monthly_log_returns.csv\")\n",
    "        if (OUT_DIR / \"data_monthly_log_returns.csv\").exists()\n",
    "        else None\n",
    "    ),\n",
    ")\n",
    "\n",
    "html += card(\n",
    "    \"Step 1 – Baseline Neural Network\",\n",
    "    \"A baseline MLP using a 12-month look-back window was trained to predict β. \"\n",
    "    \"The learning curve shows stable convergence without overfitting.\",\n",
    "    img=find_file(\"step1_learning_curve\"),\n",
    ")\n",
    "\n",
    "html += card(\n",
    "    \"Step 2 – Hyperparameter Tuning\",\n",
    "    \"Grid search explored hidden units (4, 8, 16), learning rates (0.001 – 0.1), \"\n",
    "    \"and activations (linear, sigmoid, tanh, ReLU). Validation RMSE results are below.\",\n",
    "    table=preview_csv(OUT_DIR / \"step2_grid_results.csv\"),\n",
    ")\n",
    "if (OUT_DIR / \"step2_best_by_market.csv\").exists():\n",
    "    html += card(\n",
    "        \"Best Configurations by Market\",\n",
    "        \"Optimal hyperparameters for each market input choice based on validation RMSE.\",\n",
    "        table=preview_csv(OUT_DIR / \"step2_best_by_market.csv\"),\n",
    "    )\n",
    "\n",
    "for img in sorted(OUT_DIR.glob(\"step3_learning_curve_*.png\")):\n",
    "    html += card(\n",
    "        f\"Step 3 – Learning Curve ({img.stem.split('_')[-1]})\",\n",
    "        \"Training vs validation error across epochs for this market configuration.\",\n",
    "        img=img,\n",
    "    )\n",
    "\n",
    "if (OUT_DIR / \"step4_neural_beta_descriptives.csv\").exists():\n",
    "    html += card(\n",
    "        \"Step 4 – Descriptive Statistics of Neural β\",\n",
    "        \"Summary statistics for each crypto–asset β pair over the 2023–2025 test set.\",\n",
    "        table=preview_csv(OUT_DIR / \"step4_neural_beta_descriptives.csv\", wide=True),\n",
    "    )\n",
    "\n",
    "if (OUT_DIR / \"step5_beta_dynamics.png\").exists():\n",
    "    html += card(\n",
    "        \"Step 5 – Neural β Dynamics\",\n",
    "        \"Monthly mean β values for each cryptocurrency in 2023, illustrating volatility patterns.\",\n",
    "        img=OUT_DIR / \"step5_beta_dynamics.png\",\n",
    "    )\n",
    "\n",
    "if (OUT_DIR / \"step7_data_with_ff.csv\").exists():\n",
    "    html += card(\n",
    "        \"Step 7 – Incorporating Fama–French Factors\",\n",
    "        \"The Fama–French 5-Factor model was merged into the dataset to evaluate impact on predictive accuracy.\",\n",
    "        table=preview_csv(OUT_DIR / \"step7_data_with_ff.csv\"),\n",
    "    )\n",
    "\n",
    "if (OUT_DIR / \"step9_portfolio_sorts.csv\").exists():\n",
    "    html += card(\n",
    "        \"Step 9 – Portfolio Sorts\",\n",
    "        \"Portfolio-level β sorts summarizing how neural betas distribute across return quantiles.\",\n",
    "        table=preview_csv(OUT_DIR / \"step9_portfolio_sorts.csv\"),\n",
    "    )\n",
    "\n",
    "html += card(\n",
    "    \"Discussion & Findings\",\n",
    "    \"Neural β estimates show weak and often negative correlation between cryptocurrencies and traditional markets. \"\n",
    "    \"Equity factors show temporary influence, while Fama–French factors offer minor improvement in prediction accuracy. \"\n",
    "    \"Overall, cryptocurrencies remain largely independent from traditional risk premia.\",\n",
    ")\n",
    "\n",
    "html += \"\"\"\n",
    "</main>\n",
    "<footer>\n",
    "  Neural Beta Research Report\n",
    "</footer>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "with open(REPORT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html)\n",
    "\n",
    "print(f\"HTML report created: {REPORT_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
