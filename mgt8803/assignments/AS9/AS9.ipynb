{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DjLeO3PztrFJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Jcaay2xjvUSE"
      },
      "outputs": [],
      "source": [
        "loan = pd.read_csv(\"data/loan_pricing_dealscan.csv\", low_memory=False)\n",
        "msf = pd.read_csv(\"data/MSF_1996_2023.csv\", low_memory=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8ubO5h-vWvU"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "from tqdm import tqdm\n",
        "\n",
        "cols_needed = [\n",
        "    \"gvkey\", \"datadate\", \"fyear\",\n",
        "    \"at\", \"lt\", \"revt\", \"ni\", \"oancf\", \"act\", \"lct\",\n",
        "    \"ppent\", \"ceq\", \"dltt\", \"ch\", \"invt\", \"rect\", \"cogs\"\n",
        "]\n",
        "\n",
        "\n",
        "total_lines = int(subprocess.check_output(\n",
        "    [\"wc\", \"-l\", \"data/COMPUSTAT_funda_annual.csv\"]\n",
        ").split()[0])\n",
        "\n",
        "chunksize = 200_000\n",
        "\n",
        "chunks = []\n",
        "for chunk in tqdm(\n",
        "    pd.read_csv(\n",
        "        \"data/COMPUSTAT_funda_annual.csv\",\n",
        "        usecols=cols_needed,\n",
        "        chunksize=chunksize,\n",
        "        low_memory=False\n",
        "    ),\n",
        "    total=total_lines // chunksize\n",
        "):\n",
        "    chunks.append(chunk)\n",
        "\n",
        "df = pd.concat(chunks, ignore_index=True)\n",
        "df.to_pickle(\"data/COMPUSTAT_funda_annual.pkl\")\n",
        "comp = pd.read_pickle(\"data/COMPUSTAT_funda_annual.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_Sm559o3vX5Q"
      },
      "outputs": [],
      "source": [
        "loan[\"datadate\"] = pd.to_datetime(loan[\"datadate\"], errors=\"coerce\")\n",
        "loan[\"facilitystartdate\"] = pd.to_datetime(\n",
        "    loan[\"facilitystartdate\"], errors=\"coerce\")\n",
        "comp[\"datadate\"] = pd.to_datetime(comp[\"datadate\"], errors=\"coerce\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QOizOha-vZl2"
      },
      "outputs": [],
      "source": [
        "loan[\"year\"] = loan[\"datadate\"].dt.year\n",
        "comp[\"year\"] = comp[\"datadate\"].dt.year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWOecKUsvalq",
        "outputId": "0e87aa74-efd9-464a-a094-2fd1fcd3341b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_merge\n",
            "both          170007\n",
            "left_only       8045\n",
            "right_only         0\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "tmp = loan.merge(comp, on=[\"gvkey\",\"year\"], how=\"left\", indicator=True)\n",
        "print(tmp[\"_merge\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6jhTmZdvb4_",
        "outputId": "89c9d355-7ed8-41ac-91bc-e90d639e0eb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "comp rows per firm-year: count    494636.000000\n",
            "mean          1.090333\n",
            "std           0.287307\n",
            "min           1.000000\n",
            "25%           1.000000\n",
            "50%           1.000000\n",
            "75%           1.000000\n",
            "max           4.000000\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "g = comp.groupby([\"gvkey\",\"year\"]).size()\n",
        "print(\"comp rows per firm-year:\", g.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9mVAa-dQvdHX"
      },
      "outputs": [],
      "source": [
        "df = loan.merge(comp, on=[\"gvkey\", \"year\"], how=\"left\")\n",
        "\n",
        "df[\"secured\"] = df[\"secured\"].map({\"Yes\": 1, \"No\": 0})\n",
        "df[\"seniority\"] = df[\"seniority\"].replace({\n",
        "    \"Senior Secured\": 3,\n",
        "    \"Senior\": 2,\n",
        "    \"Senior Unsecured\": 1,\n",
        "    \"Subordinated\": 0\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ADxEKpsvebv",
        "outputId": "29a81203-1c2f-490c-d3ca-486c296e6570"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loan rows: 160041\n",
            "comp rows: 539318\n"
          ]
        }
      ],
      "source": [
        "print(\"loan rows:\", len(loan))\n",
        "print(\"comp rows:\", len(comp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LtHyYxtIvfWU"
      },
      "outputs": [],
      "source": [
        "def clean_crsp_ret(x):\n",
        "    if isinstance(x, str):\n",
        "        x = x.strip()\n",
        "\n",
        "    if x in [\"\", \".\", \"NA\", None]:\n",
        "        return np.nan\n",
        "\n",
        "    try:\n",
        "        return float(x)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    delist_map = {\n",
        "        \"A\": -0.30, \"B\": -0.30, \"C\": -0.30,\n",
        "        \"D\": -1.00, \"E\": -1.00, \"F\": -1.00, \"G\": -1.00\n",
        "    }\n",
        "    return delist_map.get(x, np.nan)\n",
        "\n",
        "\n",
        "def rolling_beta(ret, mkt, window=36):\n",
        "    betas = np.full(len(ret), np.nan)\n",
        "    for i in range(window, len(ret)):\n",
        "        y = ret[i-window:i]\n",
        "        x = mkt[i-window:i]\n",
        "        valid = np.isfinite(y) & np.isfinite(x)\n",
        "        if valid.sum() > 20:\n",
        "            cov = np.cov(y[valid], x[valid])[0, 1]\n",
        "            var = np.var(x[valid])\n",
        "            if var > 0:\n",
        "                betas[i] = cov / var\n",
        "    return betas\n",
        "\n",
        "\n",
        "def preprocess_msf(path):\n",
        "    print(\"Loading MSF file...\")\n",
        "    msf = pd.read_csv(path, low_memory=False)\n",
        "\n",
        "    print(\"Converting dates...\")\n",
        "    msf[\"date\"] = pd.to_datetime(msf[\"date\"], errors=\"coerce\")\n",
        "    msf = msf.sort_values([\"PERMNO\", \"date\"])\n",
        "\n",
        "    print(\"Cleaning CRSP returns (RET, vwretd)...\")\n",
        "    msf[\"RET\"] = msf[\"RET\"].apply(clean_crsp_ret).astype(float)\n",
        "    msf[\"vwretd\"] = msf[\"vwretd\"].apply(clean_crsp_ret).astype(float)\n",
        "\n",
        "    msf[\"ret_excess\"] = msf[\"RET\"]\n",
        "    msf[\"mkt_excess\"] = msf[\"vwretd\"]\n",
        "\n",
        "    print(\"Computing rolling 36-month CAPM beta...\")\n",
        "    betalist = []\n",
        "\n",
        "    for permno, grp in msf.groupby(\"PERMNO\"):\n",
        "        grp = grp.sort_values(\"date\")\n",
        "        grp[\"beta\"] = rolling_beta(\n",
        "            grp[\"ret_excess\"].values,\n",
        "            grp[\"mkt_excess\"].values\n",
        "        )\n",
        "        betalist.append(grp)\n",
        "\n",
        "    msf = pd.concat(betalist)\n",
        "\n",
        "    print(\"Computing systematic & idiosyncratic volatility...\")\n",
        "    msf[\"mkt_vol\"] = (\n",
        "        msf.groupby(\"PERMNO\")[\"mkt_excess\"]\n",
        "        .transform(lambda x: x.rolling(36).std())\n",
        "    )\n",
        "\n",
        "    msf[\"sys_vol\"] = msf[\"beta\"] * msf[\"mkt_vol\"]\n",
        "\n",
        "    msf[\"residual\"] = msf[\"ret_excess\"] - msf[\"beta\"] * msf[\"mkt_excess\"]\n",
        "\n",
        "    msf[\"idio_vol\"] = (\n",
        "        msf.groupby(\"PERMNO\")[\"residual\"]\n",
        "        .transform(lambda x: x.rolling(36).std())\n",
        "    )\n",
        "\n",
        "    print(\"Aggregating to annual level...\")\n",
        "    msf[\"year\"] = msf[\"date\"].dt.year\n",
        "\n",
        "    msf_agg = msf.groupby([\"PERMNO\", \"year\"]).agg({\n",
        "        \"RET\": \"mean\",\n",
        "        \"beta\": \"mean\",\n",
        "        \"sys_vol\": \"mean\",\n",
        "        \"idio_vol\": \"mean\"\n",
        "    }).reset_index()\n",
        "\n",
        "    print(\"Finished MSF preprocessing!\")\n",
        "    return msf_agg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sveSHr7TvgpJ",
        "outputId": "d5931fc3-e779-4479-f267-24fc4aae01a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading MSF file...\n",
            "Converting dates...\n",
            "Cleaning CRSP returns (RET, vwretd)...\n",
            "Computing rolling 36-month CAPM beta...\n",
            "Computing systematic & idiosyncratic volatility...\n",
            "Aggregating to annual level...\n",
            "Finished MSF preprocessing!\n"
          ]
        }
      ],
      "source": [
        "msf_agg = preprocess_msf(\"data/MSF_1996_2023.csv\")\n",
        "df = df.merge(msf_agg, on=[\"PERMNO\", \"year\"], how=\"left\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMhB11dovhly",
        "outputId": "6e3429a7-5a1d-4bc0-8c57-599cecb192e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "msf_agg rows: 145761\n",
            "df rows AFTER loan-comp merge: 178052\n",
            "df rows FINAL (after msf merge): 178052\n"
          ]
        }
      ],
      "source": [
        "print(\"msf_agg rows:\", len(msf_agg))\n",
        "print(\"df rows AFTER loan-comp merge:\", len(loan.merge(comp, on=[\"gvkey\",\"year\"], how=\"left\")))\n",
        "print(\"df rows FINAL (after msf merge):\", len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTCjQxKwvi9S",
        "outputId": "c9daa5f0-b472-49af-f76f-50d92d3e1410"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comp duplicates: 44682\n",
            "MSF duplicates: 0\n",
            "Loan duplicates: 136066\n"
          ]
        }
      ],
      "source": [
        "print(\"Comp duplicates:\", comp.duplicated(subset=[\"gvkey\", \"year\"]).sum())\n",
        "print(\"MSF duplicates:\", msf_agg.duplicated(subset=[\"PERMNO\", \"year\"]).sum())\n",
        "print(\"Loan duplicates:\", loan.duplicated(subset=[\"gvkey\", \"year\"]).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ja4yzxGZvj4s"
      },
      "outputs": [],
      "source": [
        "def industry_bucket(sic):\n",
        "    try:\n",
        "        sic = int(sic)\n",
        "        if 1 <= sic <= 999:\n",
        "            return \"Agriculture\"\n",
        "        if 1000 <= sic <= 1499:\n",
        "            return \"Mining\"\n",
        "        if 1500 <= sic <= 1799:\n",
        "            return \"Construction\"\n",
        "        if 2000 <= sic <= 3999:\n",
        "            return \"Manufacturing\"\n",
        "        if 4000 <= sic <= 4999:\n",
        "            return \"Transportation\"\n",
        "        if 5000 <= sic <= 5199:\n",
        "            return \"Wholesale\"\n",
        "        if 5200 <= sic <= 5999:\n",
        "            return \"Retail\"\n",
        "        if 6000 <= sic <= 6799:\n",
        "            return \"Finance\"\n",
        "        if 7000 <= sic <= 8999:\n",
        "            return \"Services\"\n",
        "        if 9000 <= sic <= 9999:\n",
        "            return \"Public\"\n",
        "        return \"Unknown\"\n",
        "    except:\n",
        "        return \"Unknown\"\n",
        "\n",
        "\n",
        "df[\"industry\"] = df[\"sic\"].apply(industry_bucket)\n",
        "df = pd.get_dummies(df, columns=[\"industry\"], drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "D2M5InHzvld_"
      },
      "outputs": [],
      "source": [
        "import pandas_datareader.data as fred\n",
        "from datetime import datetime\n",
        "\n",
        "start = datetime(1996, 1, 1)\n",
        "end = datetime(2023, 12, 31)\n",
        "\n",
        "macros = {\"FEDFUNDS\": \"FEDFUNDS\", \"GDP\": \"GDP\", \"UNRATE\": \"UNRATE\"}\n",
        "macro_df = pd.DataFrame()\n",
        "\n",
        "for col, series in macros.items():\n",
        "    macro_df[col] = fred.DataReader(series, \"fred\", start, end)\n",
        "\n",
        "macro_df.index = pd.to_datetime(macro_df.index)\n",
        "macro_df[\"year\"] = macro_df.index.year\n",
        "\n",
        "macro_agg = macro_df.groupby(\"year\").agg({\n",
        "    \"FEDFUNDS\": \"mean\",\n",
        "    \"GDP\": \"mean\",\n",
        "    \"UNRATE\": \"mean\"\n",
        "}).reset_index()\n",
        "\n",
        "macro_agg.to_csv(\"data/macro_fred_auto.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rpTWhXOKvnHc"
      },
      "outputs": [],
      "source": [
        "usrec = fred.DataReader(\"USREC\", \"fred\", start, end)\n",
        "usrec.index = pd.to_datetime(usrec.index)\n",
        "usrec[\"year\"] = usrec.index.year\n",
        "\n",
        "usrec_agg = usrec.groupby(\"year\").mean().reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9nG5d2povoUQ"
      },
      "outputs": [],
      "source": [
        "macro = pd.read_csv(\"data/macro_fred_auto.csv\")\n",
        "macro = macro.merge(usrec_agg, on=\"year\", how=\"left\")\n",
        "\n",
        "df = df.merge(macro, on=\"year\", how=\"left\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "D3_qVnEAvuJb"
      },
      "outputs": [],
      "source": [
        "loan_features = [\"facilityamt\", \"maturity\", \"secured\", \"seniority\", \"averagelife\"]\n",
        "\n",
        "ratio_features = [\n",
        "    \"at\", \"lt\", \"revt\", \"ni\", \"oancf\", \"act\", \"lct\", \"ppent\",\n",
        "    \"ceq\", \"dltt\", \"ch\", \"invt\", \"rect\", \"cogs\"\n",
        "]\n",
        "\n",
        "market_features = [\"beta\", \"idio_vol\", \"sys_vol\"]\n",
        "macro_features = [\"FEDFUNDS\", \"GDP\", \"UNRATE\", \"USREC\"]\n",
        "\n",
        "all_features = loan_features + ratio_features + market_features + macro_features\n",
        "\n",
        "target_main = \"allindrawn\"\n",
        "target_aux = \"allinundrawn\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "GGW6eF3mvvSF"
      },
      "outputs": [],
      "source": [
        "df = df[[\"year\"] + all_features + [target_main, target_aux]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1dw4QQUWvwSI"
      },
      "outputs": [],
      "source": [
        "full = df.dropna()\n",
        "\n",
        "X = full[all_features].values\n",
        "y_main = full[target_main].values\n",
        "y_aux = full[target_aux].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "QfNVCMORvxWn"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "GGgUCXybv6oG"
      },
      "outputs": [],
      "source": [
        "train_idx = full[\"year\"] <= 2017\n",
        "test_idx = full[\"year\"] >= 2018\n",
        "\n",
        "X_train = X_scaled[train_idx]\n",
        "X_test = X_scaled[test_idx]\n",
        "\n",
        "y_main_train = y_main[train_idx]\n",
        "y_main_test = y_main[test_idx]\n",
        "\n",
        "y_aux_train = y_aux[train_idx]\n",
        "y_aux_test = y_aux[test_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-iGn7I9v8IN",
        "outputId": "fa7aaa1e-83fd-4a0e-865d-f268e2561501"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best MLP Params: (32, 0.01, 'logistic')\n",
            "Best Test MSE: 2204.34063478547\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "hidden_options = [32, 64, 128]\n",
        "lr_options = [1e-4, 1e-3, 1e-2]\n",
        "activations = [\"relu\", \"tanh\", \"logistic\"]\n",
        "\n",
        "best_model = None\n",
        "best_mse = 1e18\n",
        "best_params = None\n",
        "\n",
        "for h in hidden_options:\n",
        "    for lr in lr_options:\n",
        "        for act in activations:\n",
        "            model = MLPRegressor(\n",
        "                hidden_layer_sizes=(h,),\n",
        "                activation=act,\n",
        "                learning_rate_init=lr,\n",
        "                max_iter=500,\n",
        "                random_state=0\n",
        "            )\n",
        "            model.fit(X_train, y_main_train)\n",
        "            pred = model.predict(X_test)\n",
        "            mse = mean_squared_error(y_main_test, pred)\n",
        "\n",
        "            if mse < best_mse:\n",
        "                best_mse = mse\n",
        "                best_params = (h, lr, act)\n",
        "                best_model = model\n",
        "\n",
        "print(\"Best MLP Params:\", best_params)\n",
        "print(\"Best Test MSE:\", best_mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "4H-R2njDv99u"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Gm2jPTfNv_Ks"
      },
      "outputs": [],
      "source": [
        "h, lr, _ = best_params\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "\n",
        "inp = layers.Input(shape=(input_dim,))\n",
        "h1 = layers.Dense(h, activation=\"relu\")(inp)\n",
        "\n",
        "out_main = layers.Dense(1, name=\"main_output\")(h1)\n",
        "out_aux = layers.Dense(1, name=\"aux_output\")(h1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Fxx_RMLxwAap"
      },
      "outputs": [],
      "source": [
        "model2 = models.Model(inputs=inp, outputs=[out_main, out_aux])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "dZsv3Xs2wBUN"
      },
      "outputs": [],
      "source": [
        "val_size = int(0.2 * X_train.shape[0])\n",
        "\n",
        "X_val_tf = X_train[-val_size:]\n",
        "X_train_tf = X_train[:-val_size]\n",
        "\n",
        "y_main_val = y_main_train[-val_size:]\n",
        "y_main_tf = y_main_train[:-val_size]\n",
        "\n",
        "y_aux_val = y_aux_train[-val_size:]\n",
        "y_aux_tf = y_aux_train[:-val_size]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "XyFxLAtewCwc"
      },
      "outputs": [],
      "source": [
        "X_train_tf = np.asarray(X_train_tf, dtype=np.float32)\n",
        "X_val_tf = np.asarray(X_val_tf, dtype=np.float32)\n",
        "\n",
        "y_main_tf = np.asarray(y_main_tf, dtype=np.float32)\n",
        "y_aux_tf = np.asarray(y_aux_tf, dtype=np.float32)\n",
        "\n",
        "y_main_val = np.asarray(y_main_val, dtype=np.float32)\n",
        "y_aux_val = np.asarray(y_aux_val, dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44O_gS9JwD2_",
        "outputId": "6832937c-0d95-400a-dc49-263c0f9efde2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: (603, 26)\n",
            "Val size: (150, 26)\n",
            "Test size: (469, 26)\n"
          ]
        }
      ],
      "source": [
        "print(\"Train size:\", X_train_tf.shape)\n",
        "print(\"Val size:\", X_val_tf.shape)\n",
        "print(\"Test size:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ZeA_NPpKwFBH"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (X_train_tf, (y_main_tf, y_aux_tf))\n",
        ").batch(32)\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (X_val_tf, (y_main_val, y_aux_val))\n",
        ").batch(32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Xr2iXO8wGVB",
        "outputId": "5c47a1e2-aa49-42ee-977e-5df787ca8f22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train_tf shape: (603, 26)\n",
            "y_main_tf shape: (603,)\n",
            "y_aux_tf shape: (603,)\n",
            "Unique lengths: 603 603 603\n"
          ]
        }
      ],
      "source": [
        "print(\"X_train_tf shape:\", X_train_tf.shape)\n",
        "print(\"y_main_tf shape:\", y_main_tf.shape)\n",
        "print(\"y_aux_tf shape:\", y_aux_tf.shape)\n",
        "\n",
        "print(\"Unique lengths:\",\n",
        "      len(X_train_tf),\n",
        "      len(y_main_tf),\n",
        "      len(y_aux_tf))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cecRRITywHYM",
        "outputId": "38ba2e6e-9057-4a00-e83f-5e6e73913fe3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF TRAIN batches: 19\n",
            "TF VAL batches: 5\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "print(\"TF TRAIN batches:\", math.ceil(len(X_train_tf) / 32))\n",
        "print(\"TF VAL batches:\", math.ceil(len(X_val_tf) / 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "RorHg4RWwInP"
      },
      "outputs": [],
      "source": [
        "model2.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "    loss={\"main_output\": \"mse\", \"aux_output\": \"mse\"},\n",
        "    loss_weights={\"main_output\": 1.0, \"aux_output\": 0.3},\n",
        "    run_eagerly=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "P9AHHBnlwJ6-"
      },
      "outputs": [],
      "source": [
        "hist = model2.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=20,\n",
        "    verbose=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVxvSVO-wLIl",
        "outputId": "da95a232-624c-4c53-ed7f-25a3ee35dced"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Aux MLP Main MSE: 5500.273787436264\n",
            "Aux MLP Aux MSE: 255.0631983125803\n"
          ]
        }
      ],
      "source": [
        "pred_main, pred_aux = model2.predict(X_test)\n",
        "\n",
        "print(\"Aux MLP Main MSE:\", mean_squared_error(y_main_test, pred_main))\n",
        "print(\"Aux MLP Aux MSE:\", mean_squared_error(y_aux_test, pred_aux))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "KZebBVedwMbX"
      },
      "outputs": [],
      "source": [
        "results = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNifICZEwNf3",
        "outputId": "b0cf4654-3c17-4ea2-8870-a9e6bb594a52"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.308e+06, tolerance: 5.746e+02\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "lasso = Lasso(alpha=0.01)\n",
        "lasso.fit(X_train, y_main_train)\n",
        "pred = lasso.predict(X_test)\n",
        "results[\"LASSO\"] = mean_squared_error(y_main_test, pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Orx_1YDmwOpl"
      },
      "outputs": [],
      "source": [
        "xg = xgb.XGBRegressor(\n",
        "    n_estimators=300, learning_rate=0.05, max_depth=4\n",
        ")\n",
        "xg.fit(X_train, y_main_train)\n",
        "pred = xg.predict(X_test)\n",
        "results[\"XGBoost\"] = mean_squared_error(y_main_test, pred)\n",
        "results[\"XGBoost_pred\"] = pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEYoJBpCwP3K",
        "outputId": "ad6ff46b-ca63-4872-d32e-3eab4e072156"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000348 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2854\n",
            "[LightGBM] [Info] Number of data points in the train set: 753, number of used features: 25\n",
            "[LightGBM] [Info] Start training from score 185.717131\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        }
      ],
      "source": [
        "train_ds = lgb.Dataset(X_train, y_main_train)\n",
        "params = {\"objective\": \"regression\", \"learning_rate\": 0.05}\n",
        "lgb_model = lgb.train(params, train_ds, 300)\n",
        "pred = lgb_model.predict(X_test)\n",
        "results[\"LightGBM\"] = mean_squared_error(y_main_test, pred)\n",
        "results[\"LightGBM_pred\"] = pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "rBLkxORMwQ4Q"
      },
      "outputs": [],
      "source": [
        "knn = KNeighborsRegressor(n_neighbors=5)\n",
        "knn.fit(X_train, y_main_train)\n",
        "pred = knn.predict(X_test)\n",
        "results[\"KNN\"] = mean_squared_error(y_main_test, pred)\n",
        "results[\"KNN_pred\"] = pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ydyRur3ewR9Q"
      },
      "outputs": [],
      "source": [
        "pred = best_model.predict(X_test)\n",
        "results[\"MLP Baseline\"] = mean_squared_error(y_main_test, pred)\n",
        "results[\"MLP Baseline_pred\"] = pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "MmWmkg4_wTMN"
      },
      "outputs": [],
      "source": [
        "results[\"MLP+Aux\"] = mean_squared_error(y_main_test, pred_main)\n",
        "results[\"MLP+Aux_pred\"] = pred_main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVhE11G_wUR9",
        "outputId": "34174553-c62c-4fa5-be43-3d86a44ce060"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model Comparison MSE:\n",
            "\n",
            "LASSO          : 245867.7859\n",
            "XGBoost        : 4689.1856\n",
            "LightGBM       : 2377.3736\n",
            "KNN            : 2870.6434\n",
            "MLP Baseline   : 2204.3406\n",
            "MLP+Aux        : 5500.2738\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nModel Comparison MSE:\\n\")\n",
        "for k, v in results.items():\n",
        "    if isinstance(v, (int, float, np.floating)):\n",
        "      print(f\"{k:15s}: {v:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "d4y5WoOu0K_U"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from io import BytesIO\n",
        "import base64\n",
        "\n",
        "def plot_pred_vs_actual_img(y_true, y_pred, title):\n",
        "    plt.figure(figsize=(7,6))\n",
        "    sns.scatterplot(x=y_true, y=y_pred, alpha=0.5, s=30)\n",
        "    plt.plot([y_true.min(), y_true.max()],\n",
        "             [y_true.min(), y_true.max()],\n",
        "             color=\"red\", linewidth=2)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Actual\")\n",
        "    plt.ylabel(\"Predicted\")\n",
        "    return fig_to_base64_and_close()\n",
        "\n",
        "def plot_residuals_img(y_true, y_pred, title):\n",
        "    residuals = y_true - y_pred\n",
        "    plt.figure(figsize=(7,6))\n",
        "    sns.histplot(residuals, kde=True)\n",
        "    plt.title(f\"{title} Residual Distribution\")\n",
        "    plt.xlabel(\"Residual\")\n",
        "    return fig_to_base64_and_close()\n",
        "\n",
        "def fig_to_base64_and_close():\n",
        "    buf = BytesIO()\n",
        "    plt.savefig(buf, format=\"png\", bbox_inches=\"tight\")\n",
        "    buf.seek(0)\n",
        "    img = base64.b64encode(buf.getvalue()).decode()\n",
        "    plt.close()\n",
        "    return img\n",
        "\n",
        "def to_1d(x):\n",
        "    x = np.array(x)\n",
        "    return x.ravel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "AByTfXvt5jd1"
      },
      "outputs": [],
      "source": [
        "plots = {}\n",
        "\n",
        "pairs = {\n",
        "    \"MLP Baseline\": (y_main_test, pred),\n",
        "    \"MLP+Aux\": (y_main_test, pred_main),\n",
        "    \"XGBoost\": (y_main_test, results[\"XGBoost_pred\"]),\n",
        "    \"LightGBM\": (y_main_test, results[\"LightGBM_pred\"]),\n",
        "    \"KNN\": (y_main_test, results[\"KNN_pred\"])\n",
        "}\n",
        "\n",
        "for name, (yt, yp) in pairs.items():\n",
        "    plots[name + \"_pred\"] = plot_pred_vs_actual_img(\n",
        "        np.array(yt).ravel(),\n",
        "        np.array(yp).ravel(),\n",
        "        f\"{name}: Prediction vs Actual\"\n",
        "    )\n",
        "\n",
        "for name, (yt, yp) in pairs.items():\n",
        "    plots[name + \"_resid\"] = plot_residuals_img(\n",
        "        np.array(yt).ravel(),\n",
        "        np.array(yp).ravel(),\n",
        "        name\n",
        "    )\n",
        "\n",
        "xgb.plot_importance(xg, max_num_features=15, height=0.5)\n",
        "plt.title(\"XGBoost Feature Importance\")\n",
        "plots[\"xgb_importance\"] = fig_to_base64_and_close()\n",
        "\n",
        "lgb.plot_importance(lgb_model, max_num_features=15)\n",
        "plt.title(\"LightGBM Feature Importance\")\n",
        "plots[\"lgb_importance\"] = fig_to_base64_and_close()\n",
        "\n",
        "plt.figure(figsize=(14, 10))\n",
        "corr = full[all_features].corr()\n",
        "sns.heatmap(corr, cmap=\"coolwarm\", center=0)\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "plots[\"corr_heatmap\"] = fig_to_base64_and_close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q68BxBad02fs",
        "outputId": "9c4e5329-7cce-4e0a-c770-5f1af0e6257f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved loan_pricing_report.html\n"
          ]
        }
      ],
      "source": [
        "html = \"\"\"\n",
        "<html>\n",
        "<head>\n",
        "<title>Loan Pricing ML Report</title>\n",
        "<style>\n",
        "\n",
        "body {\n",
        "    font-family: Arial, sans-serif;\n",
        "    margin: 20px 60px;\n",
        "    background: #fafbfc;\n",
        "    color: #333;\n",
        "}\n",
        "\n",
        "h1 {\n",
        "    font-size: 40px;\n",
        "    font-weight: 700;\n",
        "    text-align: center;\n",
        "    margin-bottom: 40px;\n",
        "    color: #1d3fa6;\n",
        "}\n",
        "\n",
        "h2 {\n",
        "    margin-top: 50px;\n",
        "    font-size: 28px;\n",
        "    color: #1d3fa6;\n",
        "}\n",
        "\n",
        "h3 {\n",
        "    margin-top: 30px;\n",
        "    font-size: 20px;\n",
        "    color: #444;\n",
        "}\n",
        "\n",
        ".section {\n",
        "    margin-top: 40px;\n",
        "}\n",
        "\n",
        ".table-container {\n",
        "    margin-top: 20px;\n",
        "    width: 60%;\n",
        "    margin-left: auto;\n",
        "    margin-right: auto;\n",
        "}\n",
        "\n",
        "table {\n",
        "    border-collapse: collapse;\n",
        "    width: 100%;\n",
        "    background: white;\n",
        "    font-size: 16px;\n",
        "    border-radius: 10px;\n",
        "    overflow: hidden;\n",
        "    box-shadow: 0 0 10px rgba(0,0,0,0.1);\n",
        "}\n",
        "\n",
        "table th {\n",
        "    background: #1d3fa6;\n",
        "    color: white;\n",
        "    padding: 12px;\n",
        "}\n",
        "\n",
        "table td {\n",
        "    padding: 12px;\n",
        "    border-bottom: 1px solid #eee;\n",
        "}\n",
        "\n",
        "img {\n",
        "    width: 700px;\n",
        "    display: block;\n",
        "    margin: 25px auto;\n",
        "    padding: 6px;\n",
        "    background: white;\n",
        "    border-radius: 8px;\n",
        "    border: 1px solid #ccc;\n",
        "}\n",
        "\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<h1>Loan Pricing Machine Learning Report</h1>\n",
        "\n",
        "<h2>Model Performance (Test MSE)</h2>\n",
        "\n",
        "<div class='table-container'>\n",
        "<table>\n",
        "<tr><th>Model</th><th>MSE</th></tr>\n",
        "\"\"\"\n",
        "\n",
        "for k, v in results.items():\n",
        "    if not k.endswith(\"_pred\"):\n",
        "        html += f\"<tr><td>{k}</td><td>{v:.4f}</td></tr>\"\n",
        "\n",
        "html += \"</table></div>\"\n",
        "\n",
        "html += \"<h2>Prediction vs Actual</h2>\"\n",
        "for k, img in plots.items():\n",
        "    if k.endswith(\"_pred\"):\n",
        "        label = k.replace(\"_pred\", \"\")\n",
        "        html += f\"<h3>{label}</h3>\"\n",
        "        html += f\"<img src='data:image/png;base64,{img}'/>\"\n",
        "\n",
        "html += \"<h2>Residual Distributions</h2>\"\n",
        "for k, img in plots.items():\n",
        "    if k.endswith(\"_resid\"):\n",
        "        label = k.replace(\"_resid\", \"\")\n",
        "        html += f\"<h3>{label}</h3>\"\n",
        "        html += f\"<img src='data:image/png;base64,{img}'/>\"\n",
        "\n",
        "html += \"<h2>Feature Importance</h2>\"\n",
        "html += \"<h3>XGBoost</h3>\"\n",
        "html += f\"<img src='data:image/png;base64,{plots['xgb_importance']}'/>\"\n",
        "html += \"<h3>LightGBM</h3>\"\n",
        "html += f\"<img src='data:image/png;base64,{plots['lgb_importance']}'/>\"\n",
        "\n",
        "html += \"<h2>Correlation Heatmap</h2>\"\n",
        "html += f\"<img src='data:image/png;base64,{plots['corr_heatmap']}'/>\"\n",
        "\n",
        "html += \"</body></html>\"\n",
        "\n",
        "with open(\"loan_pricing_report.html\", \"w\") as f:\n",
        "    f.write(html)\n",
        "\n",
        "print(\"Saved loan_pricing_report.html\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
